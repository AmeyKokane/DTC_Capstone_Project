{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('test') \\\n",
    "    .set(\"spark.jars\", \"/usr/local/Cellar/apache-spark/3.2.1/libexec/jars/gcs-connector-hadoop3-latest.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"/Users/amey/google/credentials/google_credentials.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.json.keyfile\", \"/Users/amey/google/credentials/google_credentials.json\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing in only necessary fields for Crashes dataset\n",
    "crashes_columns = ['CRASH_RECORD_ID','RD_NO','CRASH_DATE','POSTED_SPEED_LIMIT','WEATHER_CONDITION','LIGHTING_CONDITION','FIRST_CRASH_TYPE','STREET_NO','STREET_DIRECTION','STREET_NAME','INJURIES_TOTAL','INJURIES_FATAL']\n",
    "df_crashes = spark.read.parquet('gs://dtc_capstone_data_quiet-rigging-347402/raw/crash/*.parquet').select(crashes_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(CRASH_RECORD_ID='000cd9ff5c7aa5448f9ed6058c7b3f6b8504d234fa5cb7c93e0da7d408536077785beffa17785adc270a477de2f8bad33427895b27e7e22f3c537f290c9195eb', RD_NO='JF153597', CRASH_DATE='02/23/2022 12:15:00 PM', POSTED_SPEED_LIMIT=30, WEATHER_CONDITION='CLEAR', LIGHTING_CONDITION='DAYLIGHT', FIRST_CRASH_TYPE='TURNING', INJURIES_TOTAL=0, INJURIES_FATAL=0, LATITUDE=41.876038171, LONGITUDE=-87.701103023, LOCATION='POINT (-87.701103023191 41.876038171488)')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_people = spark.read.parquet('gs://dtc_capstone_data_quiet-rigging-347402/raw/people/*.parquet') \\\n",
    "\n",
    "vehicles_columns = ['CRASH_UNIT_ID','CRASH_RECORD_ID','RD_NO','CRASH_DATE','UNIT_NO','UNIT_TYPE','NUM_PASSENGERS','VEHICLE_ID','CMRC_VEH_I','MAKE','MODEL']\n",
    "df_vehicles_parquet = spark.read.parquet('gs://dtc_capstone_data_quiet-rigging-347402/raw/vehicles/*.parquet').select(vehicles_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(CRASH_UNIT_ID=829999, CRASH_RECORD_ID='24ddf9fd8542199d832e1c223cc474e5601b356f1d77a648bb792285d3438a8d5bd177787c5cc51d347da7b1effd5920cb5ff39ce97615a184266b0a7cb615ce', RD_NO='JD124535', CRASH_DATE='01/22/2020 06:25:00 AM', UNIT_NO=1, UNIT_TYPE='DRIVER', NUM_PASSENGERS=None, VEHICLE_ID=796949, CMRC_VEH_I='', MAKE='INFINITI', MODEL='UNKNOWN')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vehicles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": " Column name \"BAC_RESULT VALUE\" contains invalid character(s). Please use alias to rename it.        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7bfa8ad71f2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpeople_cloumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'PERSON_ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PERSON_TYPE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CRASH_RECORD_ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RD_NO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'VEHICLE_ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CRASH_DATE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SEX'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AGE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BAC_RESULT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_people_parquet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gs://dtc_capstone_data_quiet-rigging-347402/raw/people/*.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeople_cloumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_people_parquet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    299\u001b[0m                        int96RebaseMode=int96RebaseMode)\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     def text(self, paths, wholetext=False, lineSep=None, pathGlobFilter=None,\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.1/libexec/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m:  Column name \"BAC_RESULT VALUE\" contains invalid character(s). Please use alias to rename it.        "
     ]
    }
   ],
   "source": [
    "people_cloumns = ['PERSON_ID','PERSON_TYPE','CRASH_RECORD_ID','RD_NO','VEHICLE_ID','CRASH_DATE','SEX','AGE','BAC_RESULT']\n",
    "df_people_parquet = spark.read.parquet('gs://dtc_capstone_data_quiet-rigging-347402/raw/people/*.parquet').select(people_cloumns)\n",
    "df_people_parquet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "windowSpec  = Window.partitionBy(\"CRASH_RECORD_ID\").orderBy(\"CRASH_UNIT_ID\")\n",
    "\n",
    "df_vehicles_parquet= df_vehicles_parquet.withColumn(\"veh_seq_nbr\",row_number().over(windowSpec))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": " Column name \"BAC_RESULT VALUE\" contains invalid character(s). Please use alias to rename it.        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-b55b18ab4625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gs://dtc_capstone_data_quiet-rigging-347402/raw/people/*.parquet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_people_parquet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_people_parquet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf_people_parquet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_people_parquet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    299\u001b[0m                        int96RebaseMode=int96RebaseMode)\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     def text(self, paths, wholetext=False, lineSep=None, pathGlobFilter=None,\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.1/libexec/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/3.2.1/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m:  Column name \"BAC_RESULT VALUE\" contains invalid character(s). Please use alias to rename it.        "
     ]
    }
   ],
   "source": [
    "file = \"gs://dtc_capstone_data_quiet-rigging-347402/raw/people/*.parquet\"\n",
    "df_people_parquet = spark.read.parquet(file)\n",
    "for c in df_people_parquet.columns:\n",
    "    df_people_parquet = df_people_parquet.withColumnRenamed(c, c.replace(\" \", \"_\"))\n",
    "\n",
    "df_people_parquetfin = spark.read.schema(df_people_parquet.schema).parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehiclesCustomSchema = types.StructType([\n",
    "    types.StructField(\"CRASH_UNIT_ID\", types.IntegerType(), True),\n",
    "    types.StructField(\"CRASH_RECORD_ID\", types.StringType(), True),\n",
    "    types.StructField(\"RD_NO\", types.StringType(), True),\n",
    "    types.StructField(\"CRASH_DATE\", types.TimestampType(), True),\n",
    "    types.StructField(\"UNIT_NO\", types.StringType(), True),\n",
    "    types.StructField(\"UNIT_TYPE\", types.StringType(), True),\n",
    "    types.StructField(\"NUM_PASSENGERS\", types.StringType(), True),\n",
    "    types.StructField(\"VEHICLE_ID\", types.IntegerType(), True),\n",
    "    types.StructField(\"CMRC_VEH_I\", types.StringType(), True),\n",
    "    types.StructField(\"MAKE\", types.StringType(), True),\n",
    "    types.StructField(\"MODEL\", types.IntegerType(), True)  \n",
    "    ])\n",
    "\n",
    "def read_parquet_(path, schema) : \n",
    "    return spark.read.format(\"parquet\")\\\n",
    "                             .schema(schema)\\\n",
    "                             .option(\"timestampFormat\", \"yyyy/MM/dd HH:mm:ss\")\\\n",
    "                             .load(path)\n",
    "\n",
    "vehicles_path = 'gs://dtc_capstone_data_quiet-rigging-347402/raw/vehicles/*.parquet'\n",
    "df_vehicles = read_parquet_(vehicles_path, vehiclesCustomSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(CRASH_UNIT_ID=829999, CRASH_RECORD_ID='24ddf9fd8542199d832e1c223cc474e5601b356f1d77a648bb792285d3438a8d5bd177787c5cc51d347da7b1effd5920cb5ff39ce97615a184266b0a7cb615ce', RD_NO='JD124535', CRASH_DATE='01/22/2020 06:25:00 AM', UNIT_NO=1, UNIT_TYPE='DRIVER', NUM_PASSENGERS=None, VEHICLE_ID=796949, CMRC_VEH_I='', MAKE='INFINITI', MODEL='UNKNOWN', veh_seq_nbr=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vehicles_parquet.registerTempTable('vehicles')\n",
    "df_vehicle_raw = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CRASH_UNIT_ID, \n",
    "    CRASH_RECORD_ID,\n",
    "    RD_NO,\n",
    "    CRASH_DATE, \n",
    "    UNIT_NO, \n",
    "    UNIT_TYPE,\n",
    "    NUM_PASSENGERS,\n",
    "    -- Revenue calculation \n",
    "    VEHICLE_ID,\n",
    "    CMRC_VEH_I,\n",
    "    MAKE,\n",
    "    MODEL,\n",
    "    veh_seq_nbr\n",
    "FROM\n",
    "    vehicles\n",
    "    where CRASH_RECORD_ID = '24ddf9fd8542199d832e1c223cc474e5601b356f1d77a648bb792285d3438a8d5bd177787c5cc51d347da7b1effd5920cb5ff39ce97615a184266b0a7cb615ce'\n",
    "\"\"\")\n",
    "\n",
    "df_vehicle_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehicle_1 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CRASH_RECORD_ID,\n",
    "    count(CRASH_UNIT_ID) as num_vehicles\n",
    "FROM\n",
    "    vehicles\n",
    "    group by 1\n",
    "    having num_vehicles >=2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CRASH_RECORD_ID='26201e24dadcfecc3cfe69f10b7224a4df15f0baecf2e955ef8f8a161eedf196888c395ce9dd5fac43cd1d06f2111cd516400b90912744bd7bfaa0cb67ae3641', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='cb4362a84a3105a0b6b758fb5272e58c85a58f01ee2e180765100255ca8f845e36f024605e97ab9dd35c7bd6b53169f48b2702da1c62289aa5cf047a507428e0', num_vehicles=4),\n",
       " Row(CRASH_RECORD_ID='dddf911ff30ead410b91b853eeea6950051afad37014ac3ea029729b6e8af868b904db194c3fa16a1a918b882772e60166d5c26196211597b006bcc9fb7d67a4', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='c3b6d574ef99fd6240597d05f803a89dc0b202619d5b788ddf99eed81073ca2f6cada9d8359efacaac664afcd11598339ddd7b134e7cadb0c5810f826ae5f740', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='07cf72f5dc21e8251606dcebc1fd7ff511d6a1808f97f9d260203c2fe4428ec0c27e73cafb17c2addd3b35af40129524d046d71754c1ecab7318746841f56667', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='71cf510bf81b49034a82a35b8156c79afbbc2011a1233f334ac71456d57767bd424f1ae151f6121edf164223c55b8c06829d52417bd8feca0985bfcaa40de680', num_vehicles=3),\n",
       " Row(CRASH_RECORD_ID='d7c04bf62dc063491f94f13526526c4538010391187a88b4e930a3183da5176a4edaaa95456d62916a9cd5defa69336795ea1f0e07d99a74c28a3a648baa22fe', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='67af5dca6e15f9973be0ada5b3e1c8c3916b15f2426b982123f1f9d9f63fbbb30004260b0a37d0711fb182fe8db27a4de06d357671a67c076e3e86e1093d9161', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='5ed057d6ba2c2ef05d0f3323387e2c08e8fdfbd120cfcb3e36e9ddff85e14bd0e5600a55d1d5d802cea20dbd38433372c8a354095ae1b31671a27dee00cd2445', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='ff86f588ed3a0a52c5eb74e9826cada3cf91dd927eef6c763cb7916054e515337103fe843b0d41e2ae57684072a28c9edd1aa4a933aeb737f3ae5155908cd016', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='51d92121fdc7e5f7f9cf0a7588eeeef3e61ac8719100e2cad8d5e8a3edd36d4bfc580d6618c646d19d9b02056583f4e720fa13e2de03d79df06796723065ba38', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='1db886b8cc889662a10b4e549cf507d60b1fdded173d5ac11f949d01ee66b940797030770a8a793bc99018eca42d1d36223f27a119766f85222361f3c476c8db', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='97ce8f031140a9cc29dd84ca993fea5ef9dad1dad784217eddeeb992b394d543a488b9d4a62058f2cd4e6b202045cc64ff2b23cd8c6be305e7177d0cb9c5e16c', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='66ca4f07453be1dae3c1ff7a9db7edd7c15ed3cb6b5c63e3910eda33d28b9a0ec12d52bef6b9ccf65e44aedef199b651852b743acf8fd56780a471b399b69dfb', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='2e8330074204dbde1a70bb18ff1cf677075514a2a55c344573b7d0cbe377ee3537a550e59987cae1d8377bec1e4888045c21537c607926fb87332d7c3de1dd62', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='b66c9d2cd484403c1cb55e5025edc983a0468c920eae78b87e29a0e0b9338fc8a3b90dc89b81a8f361d9bc42d6558abce3d4b3c3a51b6891c465caa36e9be1d1', num_vehicles=2),\n",
       " Row(CRASH_RECORD_ID='69d5e713f8c50ec36a2db9a8bbc7e411f0262cbdae1f7cb3b8e6df660ebbdbb5c72ac7dcd371e4e681ad7c6421e8f3b5a9dcdac7e14922c9eb217d1ba397bf70', num_vehicles=3),\n",
       " Row(CRASH_RECORD_ID='921dc4b90d4fc241fc405cce7d3af309a144b5c6f8f6dc35511c2c846768322b21645f9c7102a8c92326e192c94e6d9a41d0f7d7166e769d3d4e50562060f4c3', num_vehicles=3),\n",
       " Row(CRASH_RECORD_ID='6b9a79504958399479d05c8078659474ad166e043e813fe3c834a377b99cfdb9297a7110c1ca020533c2f0e9e54d931632fd7e2a747c5afe0010c833340cf004', num_vehicles=3),\n",
       " Row(CRASH_RECORD_ID='a4a607ffdea122ea8a9406c3b6c3feb786cb9b4baf828a767561692032f64e26ad3a95db5848b4aa4d909b371bf268a8f67313516626ddcc5e4b037caffba4ef', num_vehicles=2)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vehicle_1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CRASH_UNIT_ID=940084, CRASH_RECORD_ID='cb4362a84a3105a0b6b758fb5272e58c85a58f01ee2e180765100255ca8f845e36f024605e97ab9dd35c7bd6b53169f48b2702da1c62289aa5cf047a507428e0', RD_NO='JD334931', CRASH_DATE='08/16/2020 06:30:00 PM', UNIT_NO=1, UNIT_TYPE='BICYCLE', NUM_PASSENGERS=None, VEHICLE_ID=None, CMRC_VEH_I='', MAKE='', MODEL='', veh_seq_nbr=1),\n",
       " Row(CRASH_UNIT_ID=940086, CRASH_RECORD_ID='cb4362a84a3105a0b6b758fb5272e58c85a58f01ee2e180765100255ca8f845e36f024605e97ab9dd35c7bd6b53169f48b2702da1c62289aa5cf047a507428e0', RD_NO='JD334931', CRASH_DATE='08/16/2020 06:30:00 PM', UNIT_NO=2, UNIT_TYPE='DRIVER', NUM_PASSENGERS=None, VEHICLE_ID=891177, CMRC_VEH_I='', MAKE='FORD', MODEL='MUSTANG', veh_seq_nbr=2),\n",
       " Row(CRASH_UNIT_ID=957468, CRASH_RECORD_ID='cb4362a84a3105a0b6b758fb5272e58c85a58f01ee2e180765100255ca8f845e36f024605e97ab9dd35c7bd6b53169f48b2702da1c62289aa5cf047a507428e0', RD_NO='JD334931', CRASH_DATE='08/16/2020 06:30:00 PM', UNIT_NO=2, UNIT_TYPE='BICYCLE', NUM_PASSENGERS=None, VEHICLE_ID=None, CMRC_VEH_I='', MAKE='', MODEL='', veh_seq_nbr=3),\n",
       " Row(CRASH_UNIT_ID=957469, CRASH_RECORD_ID='cb4362a84a3105a0b6b758fb5272e58c85a58f01ee2e180765100255ca8f845e36f024605e97ab9dd35c7bd6b53169f48b2702da1c62289aa5cf047a507428e0', RD_NO='JD334931', CRASH_DATE='08/16/2020 06:30:00 PM', UNIT_NO=1, UNIT_TYPE='DRIVER', NUM_PASSENGERS=None, VEHICLE_ID=907513, CMRC_VEH_I='', MAKE='FORD', MODEL='MUSTANG', veh_seq_nbr=4)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vehicle_2 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CRASH_UNIT_ID, \n",
    "    CRASH_RECORD_ID,\n",
    "    RD_NO,\n",
    "    CRASH_DATE, \n",
    "    UNIT_NO, \n",
    "    UNIT_TYPE,\n",
    "    NUM_PASSENGERS,\n",
    "    -- Revenue calculation \n",
    "    VEHICLE_ID,\n",
    "    CMRC_VEH_I,\n",
    "    MAKE,\n",
    "    MODEL,\n",
    "    veh_seq_nbr\n",
    "FROM\n",
    "    vehicles\n",
    "    where CRASH_RECORD_ID = 'cb4362a84a3105a0b6b758fb5272e58c85a58f01ee2e180765100255ca8f845e36f024605e97ab9dd35c7bd6b53169f48b2702da1c62289aa5cf047a507428e0'\n",
    "\"\"\")\n",
    "\n",
    "df_vehicle_2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehicle_summ = spark.sql(\"\"\"\n",
    "SELECT B.CRASH_RECORD_ID,\n",
    "    B.RD_NO,\n",
    "    B.CRASH_DATE, \n",
    "    \n",
    "    max(VEHICLE1_ID) as VEHICLE1_ID,\n",
    "    max(VEHICLE1_MAKE) as VEHICLE1_MAKE,\n",
    "    max(VEHICLE1_MODEL) as VEHICLE1_MODEL,\n",
    "    \n",
    "    max(VEHICLE2_ID) as VEHICLE2_ID,\n",
    "    max(VEHICLE2_MAKE) as VEHICLE2_MAKE,\n",
    "    max(VEHICLE2_MODEL) as VEHICLE2_MODEL,\n",
    "    \n",
    "    max(VEHICLE3_ID) as VEHICLE3_ID ,\n",
    "    max(VEHICLE3_MAKE) as VEHICLE3_MAKE,\n",
    "    max(VEHICLE3_MODEL) as VEHICLE3_MODEL ,\n",
    "    \n",
    "    max(VEHICLE4_ID) as VEHICLE4_ID ,\n",
    "    max(VEHICLE4_MAKE) as VEHICLE4_MAKE,\n",
    "    max(VEHICLE4_MODEL) as VEHICLE4_MODEL\n",
    "    FROM \n",
    "(SELECT \n",
    "    a.CRASH_RECORD_ID,\n",
    "    a.RD_NO,\n",
    "    a.CRASH_DATE, \n",
    "    \n",
    "    b1.CRASH_UNIT_ID as VEHICLE1_ID,\n",
    "    case when b1.MAKE is null then b1.UNIT_TYPE else b1.MAKE end as VEHICLE1_MAKE,\n",
    "    case when b1.MODEL is null then b1.UNIT_TYPE else b1.MODEL end as VEHICLE1_MODEL,\n",
    "    \n",
    "    b2.CRASH_UNIT_ID as VEHICLE2_ID,\n",
    "    case when b2.MAKE is null then b2.UNIT_TYPE else b2.MAKE end as VEHICLE2_MAKE,\n",
    "    case when b2.MODEL is null then b2.UNIT_TYPE else b2.MODEL end as VEHICLE2_MODEL,\n",
    "    \n",
    "    b3.CRASH_UNIT_ID as VEHICLE3_ID,\n",
    "    case when b3.MAKE is null then b3.UNIT_TYPE else b3.MAKE end as VEHICLE3_MAKE,\n",
    "    case when b3.MODEL is null then b3.UNIT_TYPE else b3.MODEL end as VEHICLE3_MODEL,\n",
    "    \n",
    "    b4.CRASH_UNIT_ID as VEHICLE4_ID,\n",
    "    case when b4.MAKE is null then b4.UNIT_TYPE else b4.MAKE end as VEHICLE4_MAKE,\n",
    "    case when b4.MODEL is null then b4.UNIT_TYPE else b4.MODEL end as VEHICLE4_MODEL\n",
    "    \n",
    "FROM\n",
    "    vehicles a\n",
    "    \n",
    "    left join (select CRASH_RECORD_ID, CRASH_DATE, CRASH_UNIT_ID,VEHICLE_ID,MAKE,MODEL,UNIT_TYPE\n",
    "                from vehicles where veh_seq_nbr = 1 ) b1\n",
    "    on a.CRASH_RECORD_ID = b1.CRASH_RECORD_ID\n",
    "    and a.CRASH_DATE = b1.CRASH_DATE\n",
    "    and a.CRASH_UNIT_ID = b1.CRASH_UNIT_ID\n",
    "    and a.VEHICLE_ID = b1.VEHICLE_ID\n",
    "    \n",
    "    \n",
    "    left join (select CRASH_RECORD_ID, CRASH_DATE, CRASH_UNIT_ID,VEHICLE_ID,MAKE,MODEL,UNIT_TYPE\n",
    "                from vehicles where  veh_seq_nbr = 2) b2\n",
    "    on a.CRASH_RECORD_ID = b2.CRASH_RECORD_ID\n",
    "    and a.CRASH_DATE = b2.CRASH_DATE\n",
    "    and a.CRASH_UNIT_ID = b2.CRASH_UNIT_ID\n",
    "    and a.VEHICLE_ID = b2.VEHICLE_ID\n",
    "    \n",
    "    left join (select CRASH_RECORD_ID, CRASH_DATE, CRASH_UNIT_ID,VEHICLE_ID,MAKE,MODEL,UNIT_TYPE\n",
    "                from vehicles where  veh_seq_nbr = 3) b3\n",
    "    on a.CRASH_RECORD_ID = b3.CRASH_RECORD_ID\n",
    "    and a.CRASH_DATE = b3.CRASH_DATE\n",
    "    and a.CRASH_UNIT_ID = b3.CRASH_UNIT_ID\n",
    "    and a.VEHICLE_ID = b3.VEHICLE_ID\n",
    "    \n",
    "    left join (select CRASH_RECORD_ID, CRASH_DATE, CRASH_UNIT_ID,VEHICLE_ID,MAKE,MODEL ,UNIT_TYPE\n",
    "                from vehicles where  veh_seq_nbr = 4) b4\n",
    "    on a.CRASH_RECORD_ID = b4.CRASH_RECORD_ID\n",
    "    and a.CRASH_DATE = b4.CRASH_DATE\n",
    "    and a.CRASH_UNIT_ID = b4.CRASH_UNIT_ID\n",
    "    and a.VEHICLE_ID = b4.VEHICLE_ID\n",
    "    \n",
    "--where a.CRASH_RECORD_ID = 'cb4362a84a3105a0b6b758fb5272e58c85a58f01ee2e180765100255ca8f845e36f024605e97ab9dd35c7bd6b53169f48b2702da1c62289aa5cf047a507428e0'\n",
    "group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15) B\n",
    "group by 1,2,3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CRASH_RECORD_ID='cb4362a84a3105a0b6b758fb5272e58c85a58f01ee2e180765100255ca8f845e36f024605e97ab9dd35c7bd6b53169f48b2702da1c62289aa5cf047a507428e0', RD_NO='JD334931', CRASH_DATE='08/16/2020 06:30:00 PM', VEHICLE1_ID=None, VEHICLE1_MAKE=None, VEHICLE1_MODEL=None, VEHICLE2_ID=940086, VEHICLE2_MAKE='FORD', VEHICLE2_MODEL='MUSTANG', VEHICLE3_ID=None, VEHICLE3_MAKE=None, VEHICLE3_MODEL=None, VEHICLE4_ID=957469, VEHICLE4_MAKE='FORD', VEHICLE4_MODEL='MUSTANG')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vehicle_2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
