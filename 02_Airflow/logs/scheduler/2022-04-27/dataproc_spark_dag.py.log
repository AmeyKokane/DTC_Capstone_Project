[2022-04-27 04:31:33,374] {processor.py:163} INFO - Started process (PID=162) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:31:33,387] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:31:33,428] {logging_mixin.py:109} INFO - [2022-04-27 04:31:33,428] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:31:44,540] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:31:44,566] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:31:44,605] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:31:44,646] {logging_mixin.py:109} INFO - [2022-04-27 04:31:44,607] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 75, in <module>
    zone=f"{REGION}-f",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 57, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 569, in __init__
    cluster_config = ClusterGenerator(**kwargs).make()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 444, in make
    return self._build_cluster_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 412, in _build_cluster_data
    cluster_data = self._build_gce_cluster_config(cluster_data)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 311, in _build_gce_cluster_config
    raise AirflowException("Set internal_ip_only to true only when you pass a subnetwork_uri.")
airflow.exceptions.AirflowException: Set internal_ip_only to true only when you pass a subnetwork_uri.
[2022-04-27 04:31:44,795] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:31:44,880] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 11.659 seconds
[2022-04-27 04:32:15,780] {processor.py:163} INFO - Started process (PID=189) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:32:15,804] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:32:15,809] {logging_mixin.py:109} INFO - [2022-04-27 04:32:15,808] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:32:18,949] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:32:18,973] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:32:18,995] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:32:19,028] {logging_mixin.py:109} INFO - [2022-04-27 04:32:19,001] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 75, in <module>
    zone=f"{REGION}-f",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 57, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 569, in __init__
    cluster_config = ClusterGenerator(**kwargs).make()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 444, in make
    return self._build_cluster_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 412, in _build_cluster_data
    cluster_data = self._build_gce_cluster_config(cluster_data)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 311, in _build_gce_cluster_config
    raise AirflowException("Set internal_ip_only to true only when you pass a subnetwork_uri.")
airflow.exceptions.AirflowException: Set internal_ip_only to true only when you pass a subnetwork_uri.
[2022-04-27 04:32:19,092] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:32:19,139] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.391 seconds
[2022-04-27 04:32:49,601] {processor.py:163} INFO - Started process (PID=216) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:32:49,604] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:32:49,606] {logging_mixin.py:109} INFO - [2022-04-27 04:32:49,606] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:32:50,369] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:32:50,373] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:32:50,376] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:32:50,382] {logging_mixin.py:109} INFO - [2022-04-27 04:32:50,378] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 75, in <module>
    zone=f"{REGION}-f",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 57, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 569, in __init__
    cluster_config = ClusterGenerator(**kwargs).make()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 444, in make
    return self._build_cluster_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 412, in _build_cluster_data
    cluster_data = self._build_gce_cluster_config(cluster_data)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 311, in _build_gce_cluster_config
    raise AirflowException("Set internal_ip_only to true only when you pass a subnetwork_uri.")
airflow.exceptions.AirflowException: Set internal_ip_only to true only when you pass a subnetwork_uri.
[2022-04-27 04:32:50,402] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:32:50,415] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.819 seconds
[2022-04-27 04:33:20,799] {processor.py:163} INFO - Started process (PID=242) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:33:20,803] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:33:20,808] {logging_mixin.py:109} INFO - [2022-04-27 04:33:20,808] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:33:21,310] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:33:21,319] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:33:21,323] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:33:21,334] {logging_mixin.py:109} INFO - [2022-04-27 04:33:21,325] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 75, in <module>
    zone=f"{REGION}-f",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 57, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 569, in __init__
    cluster_config = ClusterGenerator(**kwargs).make()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 444, in make
    return self._build_cluster_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 412, in _build_cluster_data
    cluster_data = self._build_gce_cluster_config(cluster_data)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 311, in _build_gce_cluster_config
    raise AirflowException("Set internal_ip_only to true only when you pass a subnetwork_uri.")
airflow.exceptions.AirflowException: Set internal_ip_only to true only when you pass a subnetwork_uri.
[2022-04-27 04:33:21,374] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:33:21,399] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.605 seconds
[2022-04-27 04:33:51,700] {processor.py:163} INFO - Started process (PID=258) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:33:51,711] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:33:51,719] {logging_mixin.py:109} INFO - [2022-04-27 04:33:51,719] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:33:52,424] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:33:52,430] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:33:52,433] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:33:52,438] {logging_mixin.py:109} INFO - [2022-04-27 04:33:52,435] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 75, in <module>
    zone=f"{REGION}-f",
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 57, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 569, in __init__
    cluster_config = ClusterGenerator(**kwargs).make()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 444, in make
    return self._build_cluster_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 412, in _build_cluster_data
    cluster_data = self._build_gce_cluster_config(cluster_data)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 311, in _build_gce_cluster_config
    raise AirflowException("Set internal_ip_only to true only when you pass a subnetwork_uri.")
airflow.exceptions.AirflowException: Set internal_ip_only to true only when you pass a subnetwork_uri.
[2022-04-27 04:33:52,463] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:33:52,482] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.804 seconds
[2022-04-27 04:34:21,622] {processor.py:163} INFO - Started process (PID=298) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:34:21,626] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:34:21,635] {logging_mixin.py:109} INFO - [2022-04-27 04:34:21,633] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:34:22,406] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:34:22,411] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:34:22,415] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:34:22,420] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:34:22,428] {logging_mixin.py:109} INFO - [2022-04-27 04:34:22,422] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=["gs://spark-lib/bigquery/spark-bigquery-latest.jar"]
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:34:22,452] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:34:22,468] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.865 seconds
[2022-04-27 04:34:52,636] {processor.py:163} INFO - Started process (PID=323) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:34:52,640] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:34:52,642] {logging_mixin.py:109} INFO - [2022-04-27 04:34:52,642] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:34:53,338] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:34:53,345] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:34:53,350] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:34:53,355] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:34:53,364] {logging_mixin.py:109} INFO - [2022-04-27 04:34:53,359] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=["gs://spark-lib/bigquery/spark-bigquery-latest.jar"]
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:34:53,387] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:34:53,400] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.797 seconds
[2022-04-27 04:35:26,080] {processor.py:163} INFO - Started process (PID=350) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:35:26,092] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:35:26,101] {logging_mixin.py:109} INFO - [2022-04-27 04:35:26,100] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:35:27,275] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:35:27,280] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:35:27,282] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:35:27,286] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:35:27,292] {logging_mixin.py:109} INFO - [2022-04-27 04:35:27,288] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=["gs://spark-lib/bigquery/spark-bigquery-latest.jar"]
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:35:27,311] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:35:27,324] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.289 seconds
[2022-04-27 04:35:58,455] {processor.py:163} INFO - Started process (PID=375) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:35:58,460] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:35:58,464] {logging_mixin.py:109} INFO - [2022-04-27 04:35:58,464] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:35:59,233] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:35:59,250] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:35:59,253] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:35:59,271] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:35:59,288] {logging_mixin.py:109} INFO - [2022-04-27 04:35:59,281] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=["gs://spark-lib/bigquery/spark-bigquery-latest.jar"]
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:35:59,381] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:35:59,413] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.968 seconds
[2022-04-27 04:36:11,611] {processor.py:163} INFO - Started process (PID=385) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:36:11,621] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:36:11,625] {logging_mixin.py:109} INFO - [2022-04-27 04:36:11,624] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:36:12,456] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:36:12,463] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:36:12,468] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:36:12,478] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:36:12,485] {logging_mixin.py:109} INFO - [2022-04-27 04:36:12,480] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:36:12,511] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:36:12,526] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.927 seconds
[2022-04-27 04:36:43,080] {processor.py:163} INFO - Started process (PID=410) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:36:43,085] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:36:43,089] {logging_mixin.py:109} INFO - [2022-04-27 04:36:43,089] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:36:43,898] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:36:43,909] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:36:43,913] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:36:43,925] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:36:43,938] {logging_mixin.py:109} INFO - [2022-04-27 04:36:43,928] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:36:43,976] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:36:43,996] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.924 seconds
[2022-04-27 04:37:14,632] {processor.py:163} INFO - Started process (PID=435) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:37:14,636] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:37:14,639] {logging_mixin.py:109} INFO - [2022-04-27 04:37:14,639] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:37:15,218] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:37:15,226] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:37:15,232] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:37:15,239] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:37:15,264] {logging_mixin.py:109} INFO - [2022-04-27 04:37:15,242] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:37:15,365] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:37:15,400] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.774 seconds
[2022-04-27 04:37:45,953] {processor.py:163} INFO - Started process (PID=461) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:37:45,957] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:37:45,960] {logging_mixin.py:109} INFO - [2022-04-27 04:37:45,960] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:37:46,437] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:37:46,441] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:37:46,445] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:37:46,449] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:37:46,456] {logging_mixin.py:109} INFO - [2022-04-27 04:37:46,450] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:37:46,474] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:37:46,485] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.540 seconds
[2022-04-27 04:38:16,785] {processor.py:163} INFO - Started process (PID=489) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:38:16,790] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:38:16,793] {logging_mixin.py:109} INFO - [2022-04-27 04:38:16,793] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:38:17,281] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:38:17,285] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:38:17,287] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:38:17,292] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:38:17,298] {logging_mixin.py:109} INFO - [2022-04-27 04:38:17,294] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:38:17,321] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:38:17,336] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.559 seconds
[2022-04-27 04:38:47,670] {processor.py:163} INFO - Started process (PID=526) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:38:47,674] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:38:47,677] {logging_mixin.py:109} INFO - [2022-04-27 04:38:47,677] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:38:48,264] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:38:48,268] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:38:48,271] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:38:48,278] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:38:48,285] {logging_mixin.py:109} INFO - [2022-04-27 04:38:48,280] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:38:48,311] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:38:48,324] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.661 seconds
[2022-04-27 04:39:18,623] {processor.py:163} INFO - Started process (PID=553) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:39:18,630] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:39:18,639] {logging_mixin.py:109} INFO - [2022-04-27 04:39:18,639] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:39:19,222] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:39:19,227] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:39:19,234] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:39:19,241] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:39:19,248] {logging_mixin.py:109} INFO - [2022-04-27 04:39:19,243] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:39:19,279] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:39:19,295] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.692 seconds
[2022-04-27 04:39:49,423] {processor.py:163} INFO - Started process (PID=577) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:39:49,428] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:39:49,430] {logging_mixin.py:109} INFO - [2022-04-27 04:39:49,430] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:39:50,040] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:39:50,047] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:39:50,051] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:39:50,058] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:39:50,068] {logging_mixin.py:109} INFO - [2022-04-27 04:39:50,061] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:39:50,093] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:39:50,105] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.688 seconds
[2022-04-27 04:40:21,245] {processor.py:163} INFO - Started process (PID=605) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:40:21,252] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:40:21,255] {logging_mixin.py:109} INFO - [2022-04-27 04:40:21,255] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:40:21,755] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:40:21,760] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:40:21,765] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:40:21,772] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:40:21,781] {logging_mixin.py:109} INFO - [2022-04-27 04:40:21,775] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:40:21,803] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:40:21,819] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.584 seconds
[2022-04-27 04:40:55,385] {processor.py:163} INFO - Started process (PID=631) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:40:55,389] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:40:55,400] {logging_mixin.py:109} INFO - [2022-04-27 04:40:55,400] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:40:56,257] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:40:56,262] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:40:56,269] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:40:56,274] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:40:56,282] {logging_mixin.py:109} INFO - [2022-04-27 04:40:56,276] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:40:56,316] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:40:56,338] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.968 seconds
[2022-04-27 04:41:26,579] {processor.py:163} INFO - Started process (PID=653) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:41:26,584] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:41:26,586] {logging_mixin.py:109} INFO - [2022-04-27 04:41:26,586] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:41:27,269] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:41:27,294] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:41:27,298] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:41:27,303] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:41:27,310] {logging_mixin.py:109} INFO - [2022-04-27 04:41:27,304] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:41:27,384] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:41:27,451] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.883 seconds
[2022-04-27 04:41:57,945] {processor.py:163} INFO - Started process (PID=675) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:41:57,958] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:41:57,967] {logging_mixin.py:109} INFO - [2022-04-27 04:41:57,965] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:42:00,544] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:42:00,553] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:42:00,559] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:42:00,565] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:42:00,574] {logging_mixin.py:109} INFO - [2022-04-27 04:42:00,569] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:42:00,605] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:42:00,625] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.704 seconds
[2022-04-27 04:42:31,212] {processor.py:163} INFO - Started process (PID=703) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:42:31,221] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:42:31,228] {logging_mixin.py:109} INFO - [2022-04-27 04:42:31,228] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:42:31,863] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:42:31,870] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:42:31,875] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:42:31,883] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:42:31,891] {logging_mixin.py:109} INFO - [2022-04-27 04:42:31,885] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:42:31,914] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:42:31,929] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.722 seconds
[2022-04-27 04:43:02,167] {processor.py:163} INFO - Started process (PID=738) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:43:02,178] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:43:02,184] {logging_mixin.py:109} INFO - [2022-04-27 04:43:02,184] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:43:03,508] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:43:03,516] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:43:03,529] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:43:03,539] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:43:03,549] {logging_mixin.py:109} INFO - [2022-04-27 04:43:03,542] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:43:03,576] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:43:03,593] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.440 seconds
[2022-04-27 04:43:34,314] {processor.py:163} INFO - Started process (PID=758) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:43:34,319] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:43:34,322] {logging_mixin.py:109} INFO - [2022-04-27 04:43:34,321] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:43:34,813] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:43:34,818] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:43:34,823] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:43:34,831] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:43:34,840] {logging_mixin.py:109} INFO - [2022-04-27 04:43:34,834] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:43:34,870] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:43:34,888] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.580 seconds
[2022-04-27 04:44:04,984] {processor.py:163} INFO - Started process (PID=784) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:44:04,988] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:44:04,990] {logging_mixin.py:109} INFO - [2022-04-27 04:44:04,990] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:44:05,467] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:44:05,474] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:44:05,477] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:44:05,486] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:44:05,494] {logging_mixin.py:109} INFO - [2022-04-27 04:44:05,488] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:44:05,529] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:44:05,567] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.590 seconds
[2022-04-27 04:44:36,169] {processor.py:163} INFO - Started process (PID=820) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:44:36,177] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:44:36,181] {logging_mixin.py:109} INFO - [2022-04-27 04:44:36,180] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:44:37,162] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:44:37,170] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:44:37,179] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:44:37,189] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:44:37,201] {logging_mixin.py:109} INFO - [2022-04-27 04:44:37,192] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:44:37,238] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:44:37,265] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.110 seconds
[2022-04-27 04:45:08,105] {processor.py:163} INFO - Started process (PID=843) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:45:08,114] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:45:08,125] {logging_mixin.py:109} INFO - [2022-04-27 04:45:08,124] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:45:11,194] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:45:11,199] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:45:11,204] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:45:11,208] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:45:11,216] {logging_mixin.py:109} INFO - [2022-04-27 04:45:11,211] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:45:11,238] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:45:11,262] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.192 seconds
[2022-04-27 04:45:41,774] {processor.py:163} INFO - Started process (PID=871) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:45:41,801] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:45:41,810] {logging_mixin.py:109} INFO - [2022-04-27 04:45:41,809] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:45:43,907] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:45:43,915] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:45:43,925] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:45:43,949] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:45:43,965] {logging_mixin.py:109} INFO - [2022-04-27 04:45:43,952] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:45:43,992] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:45:44,018] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.269 seconds
[2022-04-27 04:46:14,421] {processor.py:163} INFO - Started process (PID=896) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:46:14,435] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:46:14,446] {logging_mixin.py:109} INFO - [2022-04-27 04:46:14,445] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:46:15,498] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:46:15,505] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:46:15,508] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:46:15,513] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:46:15,525] {logging_mixin.py:109} INFO - [2022-04-27 04:46:15,518] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:46:15,567] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:46:15,600] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.192 seconds
[2022-04-27 04:46:45,951] {processor.py:163} INFO - Started process (PID=921) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:46:45,961] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:46:45,965] {logging_mixin.py:109} INFO - [2022-04-27 04:46:45,965] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:46:46,942] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:46:46,948] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:46:46,956] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:46:46,966] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:46:46,978] {logging_mixin.py:109} INFO - [2022-04-27 04:46:46,968] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:46:47,016] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:46:47,044] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.105 seconds
[2022-04-27 04:47:17,360] {processor.py:163} INFO - Started process (PID=947) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:47:17,365] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:47:17,372] {logging_mixin.py:109} INFO - [2022-04-27 04:47:17,369] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:47:18,413] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:47:18,420] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:47:18,440] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:47:18,454] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:47:18,470] {logging_mixin.py:109} INFO - [2022-04-27 04:47:18,458] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:47:18,504] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:47:18,518] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.181 seconds
[2022-04-27 04:47:48,760] {processor.py:163} INFO - Started process (PID=964) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:47:48,765] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:47:48,769] {logging_mixin.py:109} INFO - [2022-04-27 04:47:48,769] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:47:50,289] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:47:50,304] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:47:50,312] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:47:50,323] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:47:50,337] {logging_mixin.py:109} INFO - [2022-04-27 04:47:50,326] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:47:50,370] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:47:50,395] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.646 seconds
[2022-04-27 04:48:20,765] {processor.py:163} INFO - Started process (PID=991) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:48:20,776] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:48:20,781] {logging_mixin.py:109} INFO - [2022-04-27 04:48:20,780] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:48:21,394] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:48:21,399] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:48:21,403] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:48:21,410] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:48:21,417] {logging_mixin.py:109} INFO - [2022-04-27 04:48:21,412] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:48:21,442] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:48:21,456] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.709 seconds
[2022-04-27 04:48:51,532] {processor.py:163} INFO - Started process (PID=1016) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:48:51,536] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:48:51,540] {logging_mixin.py:109} INFO - [2022-04-27 04:48:51,539] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:48:52,187] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:48:52,191] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:48:52,194] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:48:52,200] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:48:52,205] {logging_mixin.py:109} INFO - [2022-04-27 04:48:52,201] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:48:52,222] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:48:52,234] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.713 seconds
[2022-04-27 04:49:22,737] {processor.py:163} INFO - Started process (PID=1043) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:49:22,740] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:49:22,744] {logging_mixin.py:109} INFO - [2022-04-27 04:49:22,743] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:49:23,969] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:49:23,976] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:49:23,980] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:49:23,990] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:49:23,999] {logging_mixin.py:109} INFO - [2022-04-27 04:49:23,992] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:49:24,025] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:49:24,049] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.326 seconds
[2022-04-27 04:49:54,282] {processor.py:163} INFO - Started process (PID=1069) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:49:54,286] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:49:54,288] {logging_mixin.py:109} INFO - [2022-04-27 04:49:54,288] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:49:55,106] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:49:55,118] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:49:55,124] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:49:55,133] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:49:55,143] {logging_mixin.py:109} INFO - [2022-04-27 04:49:55,137] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:49:55,171] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:49:55,188] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.916 seconds
[2022-04-27 04:50:25,555] {processor.py:163} INFO - Started process (PID=1092) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:50:25,559] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:50:25,562] {logging_mixin.py:109} INFO - [2022-04-27 04:50:25,562] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:50:29,389] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:50:29,400] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:50:29,411] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:50:29,422] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:50:29,448] {logging_mixin.py:109} INFO - [2022-04-27 04:50:29,428] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:50:29,502] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:50:29,538] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.001 seconds
[2022-04-27 04:51:00,299] {processor.py:163} INFO - Started process (PID=1107) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:51:00,302] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:51:00,308] {logging_mixin.py:109} INFO - [2022-04-27 04:51:00,308] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:51:01,269] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:51:01,281] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:51:01,291] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:51:01,303] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:51:01,318] {logging_mixin.py:109} INFO - [2022-04-27 04:51:01,307] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:51:01,348] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:51:01,364] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.073 seconds
[2022-04-27 04:51:31,743] {processor.py:163} INFO - Started process (PID=1133) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:51:31,747] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:51:31,749] {logging_mixin.py:109} INFO - [2022-04-27 04:51:31,749] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:51:32,400] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:51:32,426] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:51:32,436] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:51:32,449] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:51:32,463] {logging_mixin.py:109} INFO - [2022-04-27 04:51:32,451] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:51:32,514] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:51:32,538] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.802 seconds
[2022-04-27 04:52:03,150] {processor.py:163} INFO - Started process (PID=1159) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:52:03,160] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:52:03,168] {logging_mixin.py:109} INFO - [2022-04-27 04:52:03,168] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:52:06,187] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:52:06,207] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:52:06,217] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:52:06,240] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:52:06,272] {logging_mixin.py:109} INFO - [2022-04-27 04:52:06,249] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:52:06,383] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:52:06,455] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.343 seconds
[2022-04-27 04:52:37,350] {processor.py:163} INFO - Started process (PID=1197) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:52:37,355] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:52:37,359] {logging_mixin.py:109} INFO - [2022-04-27 04:52:37,358] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:52:37,906] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:52:37,914] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:52:37,920] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:52:37,929] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:52:37,938] {logging_mixin.py:109} INFO - [2022-04-27 04:52:37,931] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:52:37,962] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:52:37,979] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.643 seconds
[2022-04-27 04:53:08,732] {processor.py:163} INFO - Started process (PID=1223) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:53:08,735] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:53:08,737] {logging_mixin.py:109} INFO - [2022-04-27 04:53:08,737] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:53:09,226] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:53:09,233] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:53:09,238] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:53:09,247] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:53:09,255] {logging_mixin.py:109} INFO - [2022-04-27 04:53:09,249] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:53:09,286] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:53:09,306] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.585 seconds
[2022-04-27 04:53:39,455] {processor.py:163} INFO - Started process (PID=1250) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:53:39,461] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:53:39,468] {logging_mixin.py:109} INFO - [2022-04-27 04:53:39,467] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:53:40,110] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:53:40,129] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:53:40,139] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:53:40,146] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:53:40,155] {logging_mixin.py:109} INFO - [2022-04-27 04:53:40,149] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:53:40,179] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:53:40,192] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.746 seconds
[2022-04-27 04:54:10,587] {processor.py:163} INFO - Started process (PID=1275) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:54:10,594] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:54:10,598] {logging_mixin.py:109} INFO - [2022-04-27 04:54:10,598] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:54:11,775] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:54:11,779] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:54:11,783] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:54:11,787] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:54:11,792] {logging_mixin.py:109} INFO - [2022-04-27 04:54:11,788] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:54:11,811] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:54:11,824] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.266 seconds
[2022-04-27 04:54:41,937] {processor.py:163} INFO - Started process (PID=1302) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:54:41,948] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:54:41,953] {logging_mixin.py:109} INFO - [2022-04-27 04:54:41,953] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:54:43,706] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:54:43,713] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:54:43,728] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:54:43,753] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:54:43,779] {logging_mixin.py:109} INFO - [2022-04-27 04:54:43,757] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:54:43,848] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:54:43,877] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.965 seconds
[2022-04-27 04:55:14,079] {processor.py:163} INFO - Started process (PID=1327) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:55:14,083] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:55:14,085] {logging_mixin.py:109} INFO - [2022-04-27 04:55:14,085] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:55:14,875] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:55:14,881] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:55:14,887] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:55:14,894] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:55:14,904] {logging_mixin.py:109} INFO - [2022-04-27 04:55:14,896] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:55:14,927] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:55:14,952] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.880 seconds
[2022-04-27 04:55:45,104] {processor.py:163} INFO - Started process (PID=1352) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:55:45,107] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:55:45,110] {logging_mixin.py:109} INFO - [2022-04-27 04:55:45,110] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:55:45,954] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:55:45,961] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:55:45,968] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:55:45,974] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:55:45,982] {logging_mixin.py:109} INFO - [2022-04-27 04:55:45,976] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:55:46,023] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:55:46,042] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.948 seconds
[2022-04-27 04:56:16,342] {processor.py:163} INFO - Started process (PID=1379) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:56:16,345] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:56:16,348] {logging_mixin.py:109} INFO - [2022-04-27 04:56:16,347] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:56:16,898] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:56:16,903] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:56:16,906] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:56:16,913] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:56:16,921] {logging_mixin.py:109} INFO - [2022-04-27 04:56:16,915] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:56:16,943] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:56:16,959] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.623 seconds
[2022-04-27 04:56:47,499] {processor.py:163} INFO - Started process (PID=1406) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:56:47,503] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:56:47,505] {logging_mixin.py:109} INFO - [2022-04-27 04:56:47,505] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:56:48,088] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:56:48,094] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:56:48,099] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:56:48,106] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:56:48,114] {logging_mixin.py:109} INFO - [2022-04-27 04:56:48,108] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:56:48,140] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:56:48,153] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.661 seconds
[2022-04-27 04:57:18,276] {processor.py:163} INFO - Started process (PID=1435) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:57:18,280] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:57:18,283] {logging_mixin.py:109} INFO - [2022-04-27 04:57:18,283] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:57:18,872] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:57:18,880] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:57:18,884] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:57:18,891] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:57:18,898] {logging_mixin.py:109} INFO - [2022-04-27 04:57:18,893] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:57:18,922] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:57:18,941] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.677 seconds
[2022-04-27 04:57:49,111] {processor.py:163} INFO - Started process (PID=1463) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:57:49,122] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:57:49,135] {logging_mixin.py:109} INFO - [2022-04-27 04:57:49,133] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:57:51,849] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:57:51,862] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:57:51,879] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:57:51,888] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:57:51,924] {logging_mixin.py:109} INFO - [2022-04-27 04:57:51,901] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:57:51,996] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:57:52,062] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.984 seconds
[2022-04-27 04:58:22,985] {processor.py:163} INFO - Started process (PID=1480) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:58:22,992] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:58:23,003] {logging_mixin.py:109} INFO - [2022-04-27 04:58:23,003] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:58:24,702] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:58:24,714] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:58:24,718] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:58:24,728] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:58:24,740] {logging_mixin.py:109} INFO - [2022-04-27 04:58:24,730] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:58:24,785] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:58:24,817] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.837 seconds
[2022-04-27 04:58:55,327] {processor.py:163} INFO - Started process (PID=1516) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:58:55,332] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:58:55,336] {logging_mixin.py:109} INFO - [2022-04-27 04:58:55,336] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:58:55,883] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:58:55,893] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:58:55,900] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:58:55,913] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:58:55,928] {logging_mixin.py:109} INFO - [2022-04-27 04:58:55,915] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:58:56,012] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:58:56,034] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.714 seconds
[2022-04-27 04:59:26,544] {processor.py:163} INFO - Started process (PID=1543) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:59:26,559] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:59:26,562] {logging_mixin.py:109} INFO - [2022-04-27 04:59:26,562] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:59:27,660] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 04:59:27,673] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 04:59:27,686] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 04:59:27,705] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 04:59:27,716] {logging_mixin.py:109} INFO - [2022-04-27 04:59:27,708] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 04:59:27,840] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:59:27,882] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.350 seconds
[2022-04-27 04:59:58,614] {processor.py:163} INFO - Started process (PID=1570) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 04:59:58,632] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 04:59:58,645] {logging_mixin.py:109} INFO - [2022-04-27 04:59:58,645] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:00:02,083] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:00:02,111] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:00:02,138] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:00:02,149] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:00:02,166] {logging_mixin.py:109} INFO - [2022-04-27 05:00:02,156] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:00:02,198] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:00:02,216] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.654 seconds
[2022-04-27 05:00:32,969] {processor.py:163} INFO - Started process (PID=1598) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:00:32,974] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:00:32,977] {logging_mixin.py:109} INFO - [2022-04-27 05:00:32,976] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:00:33,493] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:00:33,499] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:00:33,502] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:00:33,509] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:00:33,514] {logging_mixin.py:109} INFO - [2022-04-27 05:00:33,510] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:00:33,540] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:00:33,554] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.592 seconds
[2022-04-27 05:01:04,584] {processor.py:163} INFO - Started process (PID=1624) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:01:04,589] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:01:04,592] {logging_mixin.py:109} INFO - [2022-04-27 05:01:04,592] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:01:05,043] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:01:05,049] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:01:05,053] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:01:05,059] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:01:05,065] {logging_mixin.py:109} INFO - [2022-04-27 05:01:05,061] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:01:05,086] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:01:05,099] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.521 seconds
[2022-04-27 05:01:35,229] {processor.py:163} INFO - Started process (PID=1651) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:01:35,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:01:35,237] {logging_mixin.py:109} INFO - [2022-04-27 05:01:35,237] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:01:36,112] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:01:36,116] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:01:36,119] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:01:36,125] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:01:36,131] {logging_mixin.py:109} INFO - [2022-04-27 05:01:36,127] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:01:36,152] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:01:36,179] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.963 seconds
[2022-04-27 05:02:06,730] {processor.py:163} INFO - Started process (PID=1678) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:02:06,749] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:02:06,758] {logging_mixin.py:109} INFO - [2022-04-27 05:02:06,755] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:02:08,297] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:02:08,311] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:02:08,316] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:02:08,330] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:02:08,345] {logging_mixin.py:109} INFO - [2022-04-27 05:02:08,332] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:02:08,377] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:02:08,404] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.696 seconds
[2022-04-27 05:02:39,052] {processor.py:163} INFO - Started process (PID=1705) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:02:39,059] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:02:39,069] {logging_mixin.py:109} INFO - [2022-04-27 05:02:39,068] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:02:40,600] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:02:40,615] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:02:40,629] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:02:40,645] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:02:40,666] {logging_mixin.py:109} INFO - [2022-04-27 05:02:40,649] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:02:40,726] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:02:40,767] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.730 seconds
[2022-04-27 05:03:10,921] {processor.py:163} INFO - Started process (PID=1722) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:03:10,925] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:03:10,928] {logging_mixin.py:109} INFO - [2022-04-27 05:03:10,927] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:03:11,486] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:03:11,490] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:03:11,494] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:03:11,498] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:03:11,515] {logging_mixin.py:109} INFO - [2022-04-27 05:03:11,499] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:03:11,557] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:03:11,575] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.659 seconds
[2022-04-27 05:03:41,876] {processor.py:163} INFO - Started process (PID=1748) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:03:41,882] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:03:41,884] {logging_mixin.py:109} INFO - [2022-04-27 05:03:41,884] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:03:43,443] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:03:43,448] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:03:43,454] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:03:43,460] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:03:43,470] {logging_mixin.py:109} INFO - [2022-04-27 05:03:43,465] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:03:43,497] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:03:43,519] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.657 seconds
[2022-04-27 05:04:14,297] {processor.py:163} INFO - Started process (PID=1775) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:04:14,308] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:04:14,314] {logging_mixin.py:109} INFO - [2022-04-27 05:04:14,314] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:04:17,420] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:04:17,445] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:04:17,455] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:04:17,472] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:04:17,493] {logging_mixin.py:109} INFO - [2022-04-27 05:04:17,474] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:04:17,735] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:04:17,843] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.558 seconds
[2022-04-27 05:04:48,542] {processor.py:163} INFO - Started process (PID=1803) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:04:48,548] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:04:48,551] {logging_mixin.py:109} INFO - [2022-04-27 05:04:48,551] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:04:48,962] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:04:48,969] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:04:48,974] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:04:48,979] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:04:48,990] {logging_mixin.py:109} INFO - [2022-04-27 05:04:48,983] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:04:49,014] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:04:49,035] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.502 seconds
[2022-04-27 05:05:19,397] {processor.py:163} INFO - Started process (PID=1829) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:05:19,402] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:05:19,405] {logging_mixin.py:109} INFO - [2022-04-27 05:05:19,404] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:05:19,852] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:05:19,859] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:05:19,864] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:05:19,871] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:05:19,879] {logging_mixin.py:109} INFO - [2022-04-27 05:05:19,873] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:05:19,920] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:05:19,942] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.554 seconds
[2022-04-27 05:05:50,586] {processor.py:163} INFO - Started process (PID=1856) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:05:50,590] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:05:50,592] {logging_mixin.py:109} INFO - [2022-04-27 05:05:50,592] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:05:51,085] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:05:51,095] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:05:51,105] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:05:51,113] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:05:51,121] {logging_mixin.py:109} INFO - [2022-04-27 05:05:51,114] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:05:51,160] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:05:51,181] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.602 seconds
[2022-04-27 05:06:21,784] {processor.py:163} INFO - Started process (PID=1885) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:06:21,805] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:06:21,858] {logging_mixin.py:109} INFO - [2022-04-27 05:06:21,858] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:06:23,289] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:06:23,299] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:06:23,303] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:06:23,323] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:06:23,348] {logging_mixin.py:109} INFO - [2022-04-27 05:06:23,328] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:06:23,552] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:06:23,606] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.868 seconds
[2022-04-27 05:06:54,154] {processor.py:163} INFO - Started process (PID=1912) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:06:54,160] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:06:54,167] {logging_mixin.py:109} INFO - [2022-04-27 05:06:54,166] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:06:54,706] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:06:54,714] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:06:54,719] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:06:54,726] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:06:54,735] {logging_mixin.py:109} INFO - [2022-04-27 05:06:54,728] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:06:54,761] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:06:54,776] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.631 seconds
[2022-04-27 05:07:25,562] {processor.py:163} INFO - Started process (PID=1941) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:07:25,570] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:07:25,574] {logging_mixin.py:109} INFO - [2022-04-27 05:07:25,574] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:07:26,131] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:07:26,136] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:07:26,143] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:07:26,157] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:07:26,171] {logging_mixin.py:109} INFO - [2022-04-27 05:07:26,160] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:07:26,213] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:07:26,232] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.680 seconds
[2022-04-27 05:07:56,576] {processor.py:163} INFO - Started process (PID=1969) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:07:56,595] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 05:07:56,601] {logging_mixin.py:109} INFO - [2022-04-27 05:07:56,600] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:07:57,840] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 05:07:57,861] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 05:07:57,874] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 05:07:57,892] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 05:07:57,916] {logging_mixin.py:109} INFO - [2022-04-27 05:07:57,898] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 05:07:58,084] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 05:07:58,137] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.572 seconds
[2022-04-27 16:19:06,083] {processor.py:163} INFO - Started process (PID=59) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:19:06,097] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:19:06,121] {logging_mixin.py:109} INFO - [2022-04-27 16:19:06,121] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:19:12,931] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:19:12,937] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:19:12,959] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:19:13,000] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:19:13,035] {logging_mixin.py:109} INFO - [2022-04-27 16:19:13,004] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:19:13,181] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:19:13,285] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 7.312 seconds
[2022-04-27 16:19:44,455] {processor.py:163} INFO - Started process (PID=85) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:19:44,464] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:19:44,466] {logging_mixin.py:109} INFO - [2022-04-27 16:19:44,466] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:19:46,413] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:19:46,417] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:19:46,426] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:19:46,437] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:19:46,452] {logging_mixin.py:109} INFO - [2022-04-27 16:19:46,446] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:19:46,510] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:19:46,573] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.144 seconds
[2022-04-27 16:20:16,786] {processor.py:163} INFO - Started process (PID=111) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:20:16,789] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:20:16,791] {logging_mixin.py:109} INFO - [2022-04-27 16:20:16,791] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:20:17,284] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:20:17,289] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:20:17,292] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:20:17,295] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:20:17,302] {logging_mixin.py:109} INFO - [2022-04-27 16:20:17,298] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:20:17,331] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:20:17,348] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.567 seconds
[2022-04-27 16:20:47,669] {processor.py:163} INFO - Started process (PID=139) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:20:47,673] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:20:47,675] {logging_mixin.py:109} INFO - [2022-04-27 16:20:47,675] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:20:48,215] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:20:48,219] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:20:48,222] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:20:48,227] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:20:48,234] {logging_mixin.py:109} INFO - [2022-04-27 16:20:48,229] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:20:48,252] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:20:48,262] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.600 seconds
[2022-04-27 16:21:18,729] {processor.py:163} INFO - Started process (PID=165) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:21:18,733] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:21:18,750] {logging_mixin.py:109} INFO - [2022-04-27 16:21:18,750] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:21:23,806] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:21:23,832] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:21:23,848] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:21:23,867] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:21:23,888] {logging_mixin.py:109} INFO - [2022-04-27 16:21:23,871] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:21:23,952] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:21:23,979] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 5.350 seconds
[2022-04-27 16:21:54,523] {processor.py:163} INFO - Started process (PID=192) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:21:54,529] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:21:54,537] {logging_mixin.py:109} INFO - [2022-04-27 16:21:54,536] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:21:56,248] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:21:56,255] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:21:56,269] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:21:56,274] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:21:56,296] {logging_mixin.py:109} INFO - [2022-04-27 16:21:56,279] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:21:56,338] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:21:56,360] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.908 seconds
[2022-04-27 16:22:26,981] {processor.py:163} INFO - Started process (PID=220) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:22:27,011] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:22:27,018] {logging_mixin.py:109} INFO - [2022-04-27 16:22:27,018] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:22:28,124] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:22:28,144] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:22:28,157] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:22:28,171] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:22:28,214] {logging_mixin.py:109} INFO - [2022-04-27 16:22:28,191] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:22:28,266] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:22:28,295] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.364 seconds
[2022-04-27 16:22:58,620] {processor.py:163} INFO - Started process (PID=249) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:22:58,633] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:22:58,636] {logging_mixin.py:109} INFO - [2022-04-27 16:22:58,635] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:22:59,908] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:22:59,914] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:22:59,925] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:22:59,930] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:22:59,944] {logging_mixin.py:109} INFO - [2022-04-27 16:22:59,939] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:22:59,972] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:23:00,000] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.430 seconds
[2022-04-27 16:23:30,103] {processor.py:163} INFO - Started process (PID=276) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:23:30,108] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:23:30,110] {logging_mixin.py:109} INFO - [2022-04-27 16:23:30,110] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:23:30,715] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:23:30,721] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:23:30,725] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:23:30,732] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:23:30,743] {logging_mixin.py:109} INFO - [2022-04-27 16:23:30,734] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:23:30,771] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:23:30,805] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.707 seconds
[2022-04-27 16:24:01,618] {processor.py:163} INFO - Started process (PID=313) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:24:01,669] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:24:01,678] {logging_mixin.py:109} INFO - [2022-04-27 16:24:01,678] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:24:05,955] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:24:06,000] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:24:06,028] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:24:06,072] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:24:06,121] {logging_mixin.py:109} INFO - [2022-04-27 16:24:06,088] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:24:06,310] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:24:06,446] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.862 seconds
[2022-04-27 16:24:36,844] {processor.py:163} INFO - Started process (PID=336) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:24:36,853] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:24:36,867] {logging_mixin.py:109} INFO - [2022-04-27 16:24:36,866] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:24:41,210] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:24:41,224] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:24:41,248] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:24:41,280] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:24:41,305] {logging_mixin.py:109} INFO - [2022-04-27 16:24:41,289] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:24:41,365] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:24:41,403] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.618 seconds
[2022-04-27 16:25:12,023] {processor.py:163} INFO - Started process (PID=360) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:25:12,047] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:25:12,062] {logging_mixin.py:109} INFO - [2022-04-27 16:25:12,058] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:25:13,373] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:25:13,380] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:25:13,387] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:25:13,416] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:25:13,443] {logging_mixin.py:109} INFO - [2022-04-27 16:25:13,427] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:25:13,475] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:25:13,494] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.533 seconds
[2022-04-27 16:25:43,953] {processor.py:163} INFO - Started process (PID=381) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:25:43,961] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:25:43,986] {logging_mixin.py:109} INFO - [2022-04-27 16:25:43,968] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:25:44,874] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:25:44,892] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:25:44,897] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:25:44,916] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:25:44,934] {logging_mixin.py:109} INFO - [2022-04-27 16:25:44,925] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:25:44,993] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:25:45,017] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.081 seconds
[2022-04-27 16:26:15,350] {processor.py:163} INFO - Started process (PID=408) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:26:15,355] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:26:15,358] {logging_mixin.py:109} INFO - [2022-04-27 16:26:15,358] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:26:16,098] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:26:16,110] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:26:16,119] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:26:16,134] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:26:16,156] {logging_mixin.py:109} INFO - [2022-04-27 16:26:16,141] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:26:16,187] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:26:16,211] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.866 seconds
[2022-04-27 16:26:46,983] {processor.py:163} INFO - Started process (PID=436) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:26:47,050] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:26:47,057] {logging_mixin.py:109} INFO - [2022-04-27 16:26:47,057] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:26:48,624] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:26:48,636] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:26:48,647] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:26:48,663] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:26:48,679] {logging_mixin.py:109} INFO - [2022-04-27 16:26:48,671] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:26:48,719] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:26:48,749] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.796 seconds
[2022-04-27 16:27:19,011] {processor.py:163} INFO - Started process (PID=465) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:27:19,019] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:27:19,022] {logging_mixin.py:109} INFO - [2022-04-27 16:27:19,022] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:27:19,671] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:27:19,680] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:27:19,687] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:27:19,697] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:27:19,710] {logging_mixin.py:109} INFO - [2022-04-27 16:27:19,701] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:27:19,746] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:27:19,767] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.785 seconds
[2022-04-27 16:27:50,102] {processor.py:163} INFO - Started process (PID=491) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:27:50,106] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:27:50,126] {logging_mixin.py:109} INFO - [2022-04-27 16:27:50,123] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:27:51,907] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:27:51,912] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:27:51,921] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:27:51,934] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:27:51,951] {logging_mixin.py:109} INFO - [2022-04-27 16:27:51,936] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:27:52,013] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:27:52,052] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.966 seconds
[2022-04-27 16:28:22,882] {processor.py:163} INFO - Started process (PID=517) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:28:22,898] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:28:22,905] {logging_mixin.py:109} INFO - [2022-04-27 16:28:22,904] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:28:24,328] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:28:24,337] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:28:24,345] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:28:24,358] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:28:24,370] {logging_mixin.py:109} INFO - [2022-04-27 16:28:24,361] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:28:24,400] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:28:24,427] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.606 seconds
[2022-04-27 16:28:54,680] {processor.py:163} INFO - Started process (PID=543) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:28:54,684] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:28:54,691] {logging_mixin.py:109} INFO - [2022-04-27 16:28:54,690] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:28:55,524] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:28:55,533] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:28:55,538] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:28:55,547] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:28:55,559] {logging_mixin.py:109} INFO - [2022-04-27 16:28:55,549] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:28:55,612] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:28:55,657] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.988 seconds
[2022-04-27 16:29:26,317] {processor.py:163} INFO - Started process (PID=570) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:29:26,323] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:29:26,327] {logging_mixin.py:109} INFO - [2022-04-27 16:29:26,327] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:29:29,106] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:29:29,129] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:29:29,145] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:29:29,164] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:29:29,188] {logging_mixin.py:109} INFO - [2022-04-27 16:29:29,177] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:29:29,276] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:29:29,340] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.042 seconds
[2022-04-27 16:29:59,698] {processor.py:163} INFO - Started process (PID=587) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:29:59,706] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:29:59,713] {logging_mixin.py:109} INFO - [2022-04-27 16:29:59,713] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:30:02,542] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:30:02,558] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:30:02,572] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:30:02,588] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:30:02,625] {logging_mixin.py:109} INFO - [2022-04-27 16:30:02,602] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:30:02,685] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:30:02,733] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.046 seconds
[2022-04-27 16:30:33,732] {processor.py:163} INFO - Started process (PID=624) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:30:33,747] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:30:33,756] {logging_mixin.py:109} INFO - [2022-04-27 16:30:33,755] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:30:34,810] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:30:34,817] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:30:34,822] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:30:34,835] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:30:34,844] {logging_mixin.py:109} INFO - [2022-04-27 16:30:34,839] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:30:34,877] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:30:34,897] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.185 seconds
[2022-04-27 16:31:05,285] {processor.py:163} INFO - Started process (PID=650) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:31:05,289] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:31:05,300] {logging_mixin.py:109} INFO - [2022-04-27 16:31:05,299] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:31:06,275] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:31:06,286] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:31:06,299] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:31:06,337] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:31:06,375] {logging_mixin.py:109} INFO - [2022-04-27 16:31:06,350] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:31:06,423] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:31:06,448] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.180 seconds
[2022-04-27 16:31:36,825] {processor.py:163} INFO - Started process (PID=679) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:31:36,834] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:31:36,842] {logging_mixin.py:109} INFO - [2022-04-27 16:31:36,841] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:31:38,486] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:31:38,505] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:31:38,523] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:31:38,548] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:31:38,579] {logging_mixin.py:109} INFO - [2022-04-27 16:31:38,551] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:31:38,633] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:31:38,684] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.879 seconds
[2022-04-27 16:32:09,745] {processor.py:163} INFO - Started process (PID=706) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:32:09,753] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:32:09,766] {logging_mixin.py:109} INFO - [2022-04-27 16:32:09,765] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:32:11,038] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:32:11,042] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:32:11,045] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:32:11,051] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:32:11,057] {logging_mixin.py:109} INFO - [2022-04-27 16:32:11,053] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:32:11,082] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:32:11,104] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.383 seconds
[2022-04-27 16:32:41,535] {processor.py:163} INFO - Started process (PID=737) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:32:41,563] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:32:41,577] {logging_mixin.py:109} INFO - [2022-04-27 16:32:41,576] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:32:43,222] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:32:43,236] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:32:43,343] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:32:43,373] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:32:43,429] {logging_mixin.py:109} INFO - [2022-04-27 16:32:43,390] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:32:43,485] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:32:43,511] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.996 seconds
[2022-04-27 16:33:13,867] {processor.py:163} INFO - Started process (PID=763) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:33:13,877] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:33:13,879] {logging_mixin.py:109} INFO - [2022-04-27 16:33:13,879] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:33:15,831] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:33:15,870] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:33:15,903] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:33:15,938] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:33:16,045] {logging_mixin.py:109} INFO - [2022-04-27 16:33:15,943] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:33:16,192] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:33:16,318] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.465 seconds
[2022-04-27 16:33:47,160] {processor.py:163} INFO - Started process (PID=791) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:33:47,171] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:33:47,175] {logging_mixin.py:109} INFO - [2022-04-27 16:33:47,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:33:48,588] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:33:48,604] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:33:48,616] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:33:48,634] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:33:48,643] {logging_mixin.py:109} INFO - [2022-04-27 16:33:48,636] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:33:48,715] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:33:48,755] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.603 seconds
[2022-04-27 16:34:19,800] {processor.py:163} INFO - Started process (PID=818) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:34:19,803] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:34:19,808] {logging_mixin.py:109} INFO - [2022-04-27 16:34:19,808] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:34:20,430] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:34:20,437] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:34:20,443] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:34:20,453] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:34:20,467] {logging_mixin.py:109} INFO - [2022-04-27 16:34:20,457] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:34:20,532] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:34:20,555] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.760 seconds
[2022-04-27 16:34:50,744] {processor.py:163} INFO - Started process (PID=844) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:34:50,758] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:34:50,762] {logging_mixin.py:109} INFO - [2022-04-27 16:34:50,761] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:34:52,859] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:34:52,867] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:34:52,870] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:34:52,882] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:34:52,892] {logging_mixin.py:109} INFO - [2022-04-27 16:34:52,884] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:34:52,925] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:34:52,962] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.267 seconds
[2022-04-27 16:35:23,286] {processor.py:163} INFO - Started process (PID=871) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:35:23,292] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:35:23,296] {logging_mixin.py:109} INFO - [2022-04-27 16:35:23,295] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:35:24,000] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:35:24,005] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:35:24,008] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:35:24,012] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:35:24,020] {logging_mixin.py:109} INFO - [2022-04-27 16:35:24,015] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:35:24,043] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:35:24,063] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.833 seconds
[2022-04-27 16:35:54,324] {processor.py:163} INFO - Started process (PID=898) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:35:54,327] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:35:54,331] {logging_mixin.py:109} INFO - [2022-04-27 16:35:54,331] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:35:55,359] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:35:55,368] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:35:55,373] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:35:55,391] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:35:55,404] {logging_mixin.py:109} INFO - [2022-04-27 16:35:55,394] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:35:55,441] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:35:55,466] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.149 seconds
[2022-04-27 16:36:26,115] {processor.py:163} INFO - Started process (PID=925) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:36:26,124] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:36:26,129] {logging_mixin.py:109} INFO - [2022-04-27 16:36:26,128] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:36:26,848] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:36:26,853] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:36:26,857] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:36:26,862] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:36:26,868] {logging_mixin.py:109} INFO - [2022-04-27 16:36:26,864] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:36:26,894] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:36:26,915] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.821 seconds
[2022-04-27 16:36:57,302] {processor.py:163} INFO - Started process (PID=953) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:36:57,322] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:36:57,330] {logging_mixin.py:109} INFO - [2022-04-27 16:36:57,330] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:37:00,704] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:37:00,714] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:37:00,726] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:37:00,742] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:37:00,758] {logging_mixin.py:109} INFO - [2022-04-27 16:37:00,746] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:37:00,808] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:37:00,829] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.595 seconds
[2022-04-27 16:37:31,672] {processor.py:163} INFO - Started process (PID=980) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:37:31,709] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:37:31,732] {logging_mixin.py:109} INFO - [2022-04-27 16:37:31,724] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:37:32,655] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:37:32,669] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:37:32,673] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:37:32,678] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:37:32,691] {logging_mixin.py:109} INFO - [2022-04-27 16:37:32,686] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:37:32,719] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:37:32,736] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.086 seconds
[2022-04-27 16:38:03,261] {processor.py:163} INFO - Started process (PID=1005) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:38:03,266] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:38:03,269] {logging_mixin.py:109} INFO - [2022-04-27 16:38:03,269] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:38:03,784] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:38:03,791] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:38:03,798] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:38:03,806] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:38:03,817] {logging_mixin.py:109} INFO - [2022-04-27 16:38:03,809] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:38:03,853] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:38:03,868] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.618 seconds
[2022-04-27 16:38:34,730] {processor.py:163} INFO - Started process (PID=1031) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:38:34,733] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:38:34,735] {logging_mixin.py:109} INFO - [2022-04-27 16:38:34,735] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:38:35,298] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:38:35,309] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:38:35,313] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:38:35,318] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:38:35,327] {logging_mixin.py:109} INFO - [2022-04-27 16:38:35,319] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:38:35,370] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:38:35,442] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.718 seconds
[2022-04-27 16:39:05,818] {processor.py:163} INFO - Started process (PID=1057) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:39:05,859] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:39:05,866] {logging_mixin.py:109} INFO - [2022-04-27 16:39:05,865] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:39:08,007] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:39:08,015] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:39:08,025] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:39:08,032] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:39:08,054] {logging_mixin.py:109} INFO - [2022-04-27 16:39:08,037] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:39:08,105] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:39:08,153] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.345 seconds
[2022-04-27 16:39:38,596] {processor.py:163} INFO - Started process (PID=1073) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:39:38,601] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:39:38,605] {logging_mixin.py:109} INFO - [2022-04-27 16:39:38,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:39:40,171] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:39:40,176] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:39:40,190] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:39:40,205] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:39:40,213] {logging_mixin.py:109} INFO - [2022-04-27 16:39:40,207] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:39:40,259] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:39:40,304] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.715 seconds
[2022-04-27 16:40:10,805] {processor.py:163} INFO - Started process (PID=1111) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:40:10,810] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:40:10,813] {logging_mixin.py:109} INFO - [2022-04-27 16:40:10,812] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:40:11,436] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:40:11,442] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:40:11,446] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:40:11,467] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:40:11,475] {logging_mixin.py:109} INFO - [2022-04-27 16:40:11,469] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:40:11,506] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:40:11,522] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.729 seconds
[2022-04-27 16:40:42,402] {processor.py:163} INFO - Started process (PID=1140) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:40:42,405] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:40:42,408] {logging_mixin.py:109} INFO - [2022-04-27 16:40:42,408] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:40:43,015] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:40:43,019] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:40:43,022] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:40:43,026] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:40:43,033] {logging_mixin.py:109} INFO - [2022-04-27 16:40:43,028] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:40:43,054] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:40:43,067] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.677 seconds
[2022-04-27 16:41:13,234] {processor.py:163} INFO - Started process (PID=1168) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:41:13,237] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:41:13,240] {logging_mixin.py:109} INFO - [2022-04-27 16:41:13,239] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:41:13,799] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:41:13,806] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:41:13,814] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:41:13,822] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:41:13,829] {logging_mixin.py:109} INFO - [2022-04-27 16:41:13,824] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:41:13,847] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:41:13,859] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.630 seconds
[2022-04-27 16:41:43,978] {processor.py:163} INFO - Started process (PID=1194) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:41:43,985] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:41:43,990] {logging_mixin.py:109} INFO - [2022-04-27 16:41:43,989] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:41:44,698] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:41:44,704] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:41:44,709] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:41:44,720] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:41:44,727] {logging_mixin.py:109} INFO - [2022-04-27 16:41:44,721] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:41:44,751] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:41:44,768] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.801 seconds
[2022-04-27 16:42:14,935] {processor.py:163} INFO - Started process (PID=1219) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:42:14,978] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:42:14,988] {logging_mixin.py:109} INFO - [2022-04-27 16:42:14,988] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:42:15,476] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:42:15,483] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:42:15,490] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:42:15,497] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:42:15,508] {logging_mixin.py:109} INFO - [2022-04-27 16:42:15,499] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:42:15,538] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:42:15,550] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.635 seconds
[2022-04-27 16:42:45,649] {processor.py:163} INFO - Started process (PID=1246) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:42:45,656] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:42:45,659] {logging_mixin.py:109} INFO - [2022-04-27 16:42:45,659] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:42:46,180] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:42:46,185] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:42:46,188] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:42:46,192] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:42:46,199] {logging_mixin.py:109} INFO - [2022-04-27 16:42:46,194] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:42:46,224] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:42:46,239] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.600 seconds
[2022-04-27 16:43:16,432] {processor.py:163} INFO - Started process (PID=1275) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:43:16,442] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:43:16,450] {logging_mixin.py:109} INFO - [2022-04-27 16:43:16,450] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:43:17,527] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:43:17,551] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:43:17,558] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:43:17,565] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:43:17,598] {logging_mixin.py:109} INFO - [2022-04-27 16:43:17,581] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:43:17,684] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:43:17,735] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.322 seconds
[2022-04-27 16:43:48,453] {processor.py:163} INFO - Started process (PID=1302) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:43:48,474] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:43:48,498] {logging_mixin.py:109} INFO - [2022-04-27 16:43:48,498] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:43:49,307] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:43:49,323] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:43:49,349] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:43:49,363] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:43:49,382] {logging_mixin.py:109} INFO - [2022-04-27 16:43:49,366] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:43:49,459] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:43:49,526] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.111 seconds
[2022-04-27 16:44:19,674] {processor.py:163} INFO - Started process (PID=1330) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:44:19,678] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:44:19,691] {logging_mixin.py:109} INFO - [2022-04-27 16:44:19,684] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:44:20,170] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:44:20,174] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:44:20,178] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:44:20,182] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:44:20,188] {logging_mixin.py:109} INFO - [2022-04-27 16:44:20,184] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:44:20,217] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:44:20,239] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.576 seconds
[2022-04-27 16:44:50,414] {processor.py:163} INFO - Started process (PID=1357) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:44:50,418] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:44:50,421] {logging_mixin.py:109} INFO - [2022-04-27 16:44:50,421] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:44:51,030] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:44:51,041] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:44:51,045] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:44:51,050] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:44:51,058] {logging_mixin.py:109} INFO - [2022-04-27 16:44:51,051] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:44:51,096] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:44:51,122] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.719 seconds
[2022-04-27 16:45:21,681] {processor.py:163} INFO - Started process (PID=1394) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:45:21,691] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:45:21,694] {logging_mixin.py:109} INFO - [2022-04-27 16:45:21,694] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:45:22,754] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:45:22,759] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:45:22,764] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:45:22,799] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:45:22,824] {logging_mixin.py:109} INFO - [2022-04-27 16:45:22,809] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:45:22,856] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:45:22,915] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.239 seconds
[2022-04-27 16:45:54,607] {processor.py:163} INFO - Started process (PID=1421) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:45:54,612] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:45:54,616] {logging_mixin.py:109} INFO - [2022-04-27 16:45:54,615] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:45:55,073] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:45:55,077] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:45:55,080] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:45:55,085] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:45:55,091] {logging_mixin.py:109} INFO - [2022-04-27 16:45:55,087] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:45:55,111] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:45:55,123] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.533 seconds
[2022-04-27 16:46:25,682] {processor.py:163} INFO - Started process (PID=1449) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:46:25,685] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:46:25,689] {logging_mixin.py:109} INFO - [2022-04-27 16:46:25,688] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:46:26,364] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:46:26,381] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:46:26,385] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:46:26,390] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:46:26,400] {logging_mixin.py:109} INFO - [2022-04-27 16:46:26,392] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:46:26,437] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:46:26,470] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.797 seconds
[2022-04-27 16:46:56,657] {processor.py:163} INFO - Started process (PID=1472) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:46:56,661] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:46:56,677] {logging_mixin.py:109} INFO - [2022-04-27 16:46:56,677] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:46:57,821] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:46:57,830] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:46:57,837] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:46:57,851] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:46:57,859] {logging_mixin.py:109} INFO - [2022-04-27 16:46:57,853] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:46:57,908] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:46:57,930] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.287 seconds
[2022-04-27 16:47:28,202] {processor.py:163} INFO - Started process (PID=1501) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:47:28,205] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:47:28,208] {logging_mixin.py:109} INFO - [2022-04-27 16:47:28,208] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:47:28,664] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:47:28,671] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:47:28,677] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:47:28,686] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:47:28,693] {logging_mixin.py:109} INFO - [2022-04-27 16:47:28,688] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:47:28,712] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:47:28,729] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.536 seconds
[2022-04-27 16:47:59,220] {processor.py:163} INFO - Started process (PID=1538) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:47:59,233] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:47:59,243] {logging_mixin.py:109} INFO - [2022-04-27 16:47:59,241] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:48:00,129] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:48:00,143] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:48:00,159] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:48:00,172] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:48:00,184] {logging_mixin.py:109} INFO - [2022-04-27 16:48:00,180] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:48:00,213] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:48:00,229] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.023 seconds
[2022-04-27 16:48:30,562] {processor.py:163} INFO - Started process (PID=1564) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:48:30,569] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:48:30,571] {logging_mixin.py:109} INFO - [2022-04-27 16:48:30,571] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:48:31,131] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:48:31,151] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:48:31,160] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:48:31,166] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:48:31,176] {logging_mixin.py:109} INFO - [2022-04-27 16:48:31,169] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:48:31,229] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:48:31,247] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.695 seconds
[2022-04-27 16:49:01,759] {processor.py:163} INFO - Started process (PID=1594) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:49:01,765] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:49:01,777] {logging_mixin.py:109} INFO - [2022-04-27 16:49:01,775] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:49:02,423] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:49:02,433] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:49:02,440] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:49:02,450] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:49:02,461] {logging_mixin.py:109} INFO - [2022-04-27 16:49:02,453] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:49:02,496] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:49:02,519] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.781 seconds
[2022-04-27 16:49:32,748] {processor.py:163} INFO - Started process (PID=1620) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:49:32,757] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:49:32,765] {logging_mixin.py:109} INFO - [2022-04-27 16:49:32,764] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:49:33,324] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:49:33,333] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:49:33,340] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:49:33,350] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:49:33,363] {logging_mixin.py:109} INFO - [2022-04-27 16:49:33,353] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:49:33,397] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:49:33,420] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.685 seconds
[2022-04-27 16:50:03,853] {processor.py:163} INFO - Started process (PID=1647) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:50:03,863] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:50:03,872] {logging_mixin.py:109} INFO - [2022-04-27 16:50:03,872] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:50:05,092] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:50:05,105] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:50:05,114] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:50:05,128] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:50:05,148] {logging_mixin.py:109} INFO - [2022-04-27 16:50:05,133] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:50:05,193] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:50:05,268] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.452 seconds
[2022-04-27 16:50:36,788] {processor.py:163} INFO - Started process (PID=1676) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:50:36,796] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:50:36,802] {logging_mixin.py:109} INFO - [2022-04-27 16:50:36,802] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:50:37,415] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:50:37,419] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:50:37,422] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:50:37,429] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:50:37,435] {logging_mixin.py:109} INFO - [2022-04-27 16:50:37,431] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:50:37,456] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:50:37,470] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.698 seconds
[2022-04-27 16:51:08,934] {processor.py:163} INFO - Started process (PID=1701) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:51:08,941] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:51:08,945] {logging_mixin.py:109} INFO - [2022-04-27 16:51:08,944] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:51:10,183] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:51:10,188] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:51:10,198] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:51:10,204] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:51:10,213] {logging_mixin.py:109} INFO - [2022-04-27 16:51:10,206] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:51:10,242] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:51:10,260] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.338 seconds
[2022-04-27 16:51:40,663] {processor.py:163} INFO - Started process (PID=1724) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:51:40,677] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:51:40,690] {logging_mixin.py:109} INFO - [2022-04-27 16:51:40,690] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:51:41,249] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:51:41,254] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:51:41,261] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:51:41,274] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:51:41,289] {logging_mixin.py:109} INFO - [2022-04-27 16:51:41,277] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:51:41,329] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:51:41,351] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.712 seconds
[2022-04-27 16:52:11,577] {processor.py:163} INFO - Started process (PID=1749) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:52:11,580] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:52:11,583] {logging_mixin.py:109} INFO - [2022-04-27 16:52:11,583] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:52:12,030] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:52:12,036] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:52:12,040] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:52:12,058] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:52:12,076] {logging_mixin.py:109} INFO - [2022-04-27 16:52:12,064] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:52:12,109] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:52:12,130] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.559 seconds
[2022-04-27 16:52:42,221] {processor.py:163} INFO - Started process (PID=1779) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:52:42,232] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:52:42,241] {logging_mixin.py:109} INFO - [2022-04-27 16:52:42,240] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:52:43,038] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:52:43,048] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:52:43,055] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:52:43,066] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:52:43,080] {logging_mixin.py:109} INFO - [2022-04-27 16:52:43,069] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:52:43,159] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:52:43,176] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.965 seconds
[2022-04-27 16:53:13,387] {processor.py:163} INFO - Started process (PID=1807) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:53:13,392] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:53:13,396] {logging_mixin.py:109} INFO - [2022-04-27 16:53:13,396] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:53:13,744] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:53:13,748] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:53:13,751] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:53:13,755] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:53:13,763] {logging_mixin.py:109} INFO - [2022-04-27 16:53:13,756] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:53:13,797] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:53:13,818] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.437 seconds
[2022-04-27 16:53:44,081] {processor.py:163} INFO - Started process (PID=1834) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:53:44,084] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:53:44,087] {logging_mixin.py:109} INFO - [2022-04-27 16:53:44,086] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:53:44,496] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:53:44,504] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:53:44,511] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:53:44,517] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:53:44,526] {logging_mixin.py:109} INFO - [2022-04-27 16:53:44,519] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:53:44,556] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:53:44,571] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.497 seconds
[2022-04-27 16:54:15,162] {processor.py:163} INFO - Started process (PID=1861) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:54:15,165] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:54:15,167] {logging_mixin.py:109} INFO - [2022-04-27 16:54:15,167] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:54:15,516] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:54:15,524] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:54:15,529] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:54:15,538] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:54:15,550] {logging_mixin.py:109} INFO - [2022-04-27 16:54:15,541] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:54:15,581] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:54:15,601] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.444 seconds
[2022-04-27 16:54:46,250] {processor.py:163} INFO - Started process (PID=1886) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:54:46,256] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:54:46,259] {logging_mixin.py:109} INFO - [2022-04-27 16:54:46,259] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:54:46,644] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:54:46,656] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:54:46,664] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:54:46,676] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:54:46,684] {logging_mixin.py:109} INFO - [2022-04-27 16:54:46,679] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:54:46,725] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:54:46,744] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.521 seconds
[2022-04-27 16:55:16,994] {processor.py:163} INFO - Started process (PID=1916) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:55:17,002] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:55:17,006] {logging_mixin.py:109} INFO - [2022-04-27 16:55:17,006] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:55:17,430] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:55:17,437] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:55:17,440] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:55:17,445] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:55:17,455] {logging_mixin.py:109} INFO - [2022-04-27 16:55:17,448] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:55:17,488] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:55:17,507] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.518 seconds
[2022-04-27 16:55:47,733] {processor.py:163} INFO - Started process (PID=1941) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:55:47,736] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:55:47,740] {logging_mixin.py:109} INFO - [2022-04-27 16:55:47,739] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:55:48,119] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:55:48,123] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:55:48,129] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:55:48,139] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:55:48,148] {logging_mixin.py:109} INFO - [2022-04-27 16:55:48,142] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:55:48,180] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:55:48,203] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.482 seconds
[2022-04-27 16:56:18,359] {processor.py:163} INFO - Started process (PID=1968) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:56:18,362] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:56:18,365] {logging_mixin.py:109} INFO - [2022-04-27 16:56:18,364] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:56:18,711] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:56:18,719] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:56:18,726] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:56:18,734] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:56:18,745] {logging_mixin.py:109} INFO - [2022-04-27 16:56:18,737] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:56:18,783] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:56:18,812] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.459 seconds
[2022-04-27 16:56:49,046] {processor.py:163} INFO - Started process (PID=1997) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:56:49,061] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:56:49,064] {logging_mixin.py:109} INFO - [2022-04-27 16:56:49,064] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:56:49,473] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:56:49,480] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:56:49,488] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:56:49,499] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:56:49,511] {logging_mixin.py:109} INFO - [2022-04-27 16:56:49,502] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:56:49,548] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:56:49,563] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.532 seconds
[2022-04-27 16:57:19,945] {processor.py:163} INFO - Started process (PID=2026) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:57:19,956] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:57:19,958] {logging_mixin.py:109} INFO - [2022-04-27 16:57:19,958] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:57:20,997] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:57:21,005] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:57:21,009] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:57:21,014] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:57:21,025] {logging_mixin.py:109} INFO - [2022-04-27 16:57:21,016] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:57:21,075] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:57:21,097] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.166 seconds
[2022-04-27 16:57:51,603] {processor.py:163} INFO - Started process (PID=2062) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:57:51,607] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:57:51,609] {logging_mixin.py:109} INFO - [2022-04-27 16:57:51,609] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:57:52,323] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:57:52,334] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:57:52,341] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:57:52,353] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:57:52,368] {logging_mixin.py:109} INFO - [2022-04-27 16:57:52,356] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:57:52,400] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:57:52,425] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.898 seconds
[2022-04-27 16:58:22,983] {processor.py:163} INFO - Started process (PID=2090) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:58:23,008] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:58:23,013] {logging_mixin.py:109} INFO - [2022-04-27 16:58:23,012] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:58:23,902] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:58:23,915] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:58:23,929] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:58:23,949] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:58:23,972] {logging_mixin.py:109} INFO - [2022-04-27 16:58:23,953] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:58:24,026] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:58:24,068] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.108 seconds
[2022-04-27 16:58:54,373] {processor.py:163} INFO - Started process (PID=2116) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:58:54,386] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:58:54,395] {logging_mixin.py:109} INFO - [2022-04-27 16:58:54,394] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:58:55,211] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:58:55,216] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:58:55,227] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:58:55,233] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:58:55,247] {logging_mixin.py:109} INFO - [2022-04-27 16:58:55,242] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:58:55,294] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:58:55,333] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.013 seconds
[2022-04-27 16:59:26,569] {processor.py:163} INFO - Started process (PID=2143) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:59:26,582] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 16:59:26,592] {logging_mixin.py:109} INFO - [2022-04-27 16:59:26,592] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:59:28,200] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 16:59:28,204] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 16:59:28,207] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 16:59:28,213] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 16:59:28,220] {logging_mixin.py:109} INFO - [2022-04-27 16:59:28,215] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 16:59:28,247] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 16:59:28,266] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.716 seconds
[2022-04-27 17:00:01,407] {processor.py:163} INFO - Started process (PID=2169) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:00:01,424] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:00:01,446] {logging_mixin.py:109} INFO - [2022-04-27 17:00:01,437] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:00:01,961] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:00:01,968] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:00:01,971] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:00:01,977] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:00:01,984] {logging_mixin.py:109} INFO - [2022-04-27 17:00:01,979] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:00:02,021] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:00:02,045] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.662 seconds
[2022-04-27 17:00:32,909] {processor.py:163} INFO - Started process (PID=2197) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:00:32,912] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:00:32,915] {logging_mixin.py:109} INFO - [2022-04-27 17:00:32,914] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:00:33,605] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:00:33,610] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:00:33,614] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:00:33,620] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:00:33,628] {logging_mixin.py:109} INFO - [2022-04-27 17:00:33,623] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:00:33,657] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:00:33,681] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.779 seconds
[2022-04-27 17:01:03,864] {processor.py:163} INFO - Started process (PID=2220) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:01:03,868] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:01:03,873] {logging_mixin.py:109} INFO - [2022-04-27 17:01:03,873] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:01:04,370] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:01:04,383] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:01:04,392] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:01:04,403] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:01:04,415] {logging_mixin.py:109} INFO - [2022-04-27 17:01:04,405] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:01:04,446] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:01:04,467] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.610 seconds
[2022-04-27 17:01:35,110] {processor.py:163} INFO - Started process (PID=2246) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:01:35,116] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:01:35,120] {logging_mixin.py:109} INFO - [2022-04-27 17:01:35,119] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:01:35,555] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:01:35,559] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:01:35,562] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:01:35,567] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:01:35,579] {logging_mixin.py:109} INFO - [2022-04-27 17:01:35,569] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:01:35,614] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:01:35,629] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.531 seconds
[2022-04-27 17:02:06,155] {processor.py:163} INFO - Started process (PID=2272) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:02:06,158] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:02:06,161] {logging_mixin.py:109} INFO - [2022-04-27 17:02:06,161] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:02:06,752] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:02:06,766] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:02:06,771] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:02:06,776] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:02:06,787] {logging_mixin.py:109} INFO - [2022-04-27 17:02:06,780] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:02:06,822] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:02:06,846] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.698 seconds
[2022-04-27 17:02:37,217] {processor.py:163} INFO - Started process (PID=2300) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:02:37,221] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:02:37,223] {logging_mixin.py:109} INFO - [2022-04-27 17:02:37,223] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:02:37,629] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:02:37,633] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:02:37,636] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:02:37,640] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:02:37,646] {logging_mixin.py:109} INFO - [2022-04-27 17:02:37,641] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:02:37,676] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:02:37,696] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.484 seconds
[2022-04-27 17:03:08,170] {processor.py:163} INFO - Started process (PID=2326) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:03:08,180] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:03:08,193] {logging_mixin.py:109} INFO - [2022-04-27 17:03:08,193] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:03:10,117] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:03:10,138] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:03:10,148] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:03:10,163] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:03:10,189] {logging_mixin.py:109} INFO - [2022-04-27 17:03:10,170] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:03:10,342] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:03:10,378] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.245 seconds
[2022-04-27 17:03:41,231] {processor.py:163} INFO - Started process (PID=2343) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:03:41,245] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:03:41,259] {logging_mixin.py:109} INFO - [2022-04-27 17:03:41,259] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:03:42,891] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:03:42,921] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:03:42,941] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:03:42,971] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:03:43,027] {logging_mixin.py:109} INFO - [2022-04-27 17:03:42,985] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:03:43,170] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:03:43,267] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.060 seconds
[2022-04-27 17:04:13,783] {processor.py:163} INFO - Started process (PID=2370) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:04:13,787] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:04:13,792] {logging_mixin.py:109} INFO - [2022-04-27 17:04:13,791] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:04:14,243] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:04:14,258] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:04:14,268] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:04:14,284] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:04:14,311] {logging_mixin.py:109} INFO - [2022-04-27 17:04:14,289] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:04:14,368] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:04:14,397] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.625 seconds
[2022-04-27 17:04:44,719] {processor.py:163} INFO - Started process (PID=2400) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:04:44,722] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:04:44,724] {logging_mixin.py:109} INFO - [2022-04-27 17:04:44,724] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:04:45,121] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:04:45,125] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:04:45,128] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:04:45,131] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:04:45,140] {logging_mixin.py:109} INFO - [2022-04-27 17:04:45,135] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:04:45,162] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:04:45,175] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.463 seconds
[2022-04-27 17:05:15,432] {processor.py:163} INFO - Started process (PID=2427) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:05:15,437] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:05:15,440] {logging_mixin.py:109} INFO - [2022-04-27 17:05:15,440] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:05:16,223] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:05:16,244] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:05:16,252] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:05:16,273] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:05:16,287] {logging_mixin.py:109} INFO - [2022-04-27 17:05:16,276] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:05:16,342] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:05:16,368] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.947 seconds
[2022-04-27 17:05:46,696] {processor.py:163} INFO - Started process (PID=2467) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:05:46,709] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:05:46,713] {logging_mixin.py:109} INFO - [2022-04-27 17:05:46,713] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:05:47,490] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:05:47,502] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:05:47,505] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:05:47,520] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:05:47,543] {logging_mixin.py:109} INFO - [2022-04-27 17:05:47,526] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:05:47,586] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:05:47,614] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.930 seconds
[2022-04-27 17:06:18,505] {processor.py:163} INFO - Started process (PID=2496) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:06:18,517] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:06:18,531] {logging_mixin.py:109} INFO - [2022-04-27 17:06:18,530] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:06:19,872] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:06:19,895] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:06:19,906] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:06:19,912] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:06:19,929] {logging_mixin.py:109} INFO - [2022-04-27 17:06:19,921] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:06:19,973] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:06:20,003] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.502 seconds
[2022-04-27 17:06:50,664] {processor.py:163} INFO - Started process (PID=2524) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:06:50,669] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:06:50,672] {logging_mixin.py:109} INFO - [2022-04-27 17:06:50,672] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:06:51,195] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:06:51,205] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:06:51,213] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:06:51,223] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:06:51,236] {logging_mixin.py:109} INFO - [2022-04-27 17:06:51,227] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:06:51,268] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:06:51,283] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.629 seconds
[2022-04-27 17:07:21,392] {processor.py:163} INFO - Started process (PID=2550) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:07:21,396] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:07:21,398] {logging_mixin.py:109} INFO - [2022-04-27 17:07:21,398] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:07:21,717] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:07:21,722] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:07:21,725] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:07:21,728] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:07:21,735] {logging_mixin.py:109} INFO - [2022-04-27 17:07:21,730] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:07:21,758] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:07:21,784] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.441 seconds
[2022-04-27 17:07:52,112] {processor.py:163} INFO - Started process (PID=2587) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:07:52,118] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:07:52,121] {logging_mixin.py:109} INFO - [2022-04-27 17:07:52,121] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:07:52,459] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:07:52,463] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:07:52,467] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:07:52,471] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:07:52,477] {logging_mixin.py:109} INFO - [2022-04-27 17:07:52,473] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:07:52,506] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:07:52,526] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.443 seconds
[2022-04-27 17:08:22,856] {processor.py:163} INFO - Started process (PID=2621) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:08:22,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:08:22,867] {logging_mixin.py:109} INFO - [2022-04-27 17:08:22,867] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:08:23,420] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:08:23,428] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:08:23,449] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:08:23,471] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:08:23,479] {logging_mixin.py:109} INFO - [2022-04-27 17:08:23,474] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:08:23,507] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:08:23,525] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.677 seconds
[2022-04-27 17:08:53,948] {processor.py:163} INFO - Started process (PID=2648) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:08:53,952] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:08:53,954] {logging_mixin.py:109} INFO - [2022-04-27 17:08:53,954] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:08:54,294] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:08:54,300] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:08:54,304] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:08:54,308] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:08:54,320] {logging_mixin.py:109} INFO - [2022-04-27 17:08:54,312] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:08:54,347] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:08:54,361] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.425 seconds
[2022-04-27 17:09:24,475] {processor.py:163} INFO - Started process (PID=2681) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:09:24,483] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:09:24,486] {logging_mixin.py:109} INFO - [2022-04-27 17:09:24,486] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:09:24,877] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:09:24,888] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:09:24,894] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:09:24,904] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:09:24,919] {logging_mixin.py:109} INFO - [2022-04-27 17:09:24,910] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:09:24,968] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:09:25,002] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.535 seconds
[2022-04-27 17:09:55,867] {processor.py:163} INFO - Started process (PID=2717) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:09:55,889] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:09:55,891] {logging_mixin.py:109} INFO - [2022-04-27 17:09:55,891] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:09:57,366] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:09:57,375] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:09:57,381] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:09:57,391] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:09:57,407] {logging_mixin.py:109} INFO - [2022-04-27 17:09:57,393] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:09:57,435] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:09:57,454] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.632 seconds
[2022-04-27 17:10:28,312] {processor.py:163} INFO - Started process (PID=2743) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:10:28,316] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:10:28,327] {logging_mixin.py:109} INFO - [2022-04-27 17:10:28,326] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:10:29,491] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:10:29,508] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:10:29,514] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:10:29,540] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:10:29,574] {logging_mixin.py:109} INFO - [2022-04-27 17:10:29,545] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:10:29,623] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:10:29,650] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.352 seconds
[2022-04-27 17:11:00,144] {processor.py:163} INFO - Started process (PID=2769) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:11:00,150] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:11:00,154] {logging_mixin.py:109} INFO - [2022-04-27 17:11:00,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:11:00,588] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:11:00,592] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:11:00,595] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:11:00,599] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:11:00,606] {logging_mixin.py:109} INFO - [2022-04-27 17:11:00,601] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:11:00,637] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:11:00,655] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.517 seconds
[2022-04-27 17:11:30,846] {processor.py:163} INFO - Started process (PID=2800) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:11:30,850] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:11:30,855] {logging_mixin.py:109} INFO - [2022-04-27 17:11:30,853] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:11:31,225] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:11:31,234] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:11:31,240] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:11:31,249] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:11:31,260] {logging_mixin.py:109} INFO - [2022-04-27 17:11:31,252] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:11:31,285] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:11:31,301] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.463 seconds
[2022-04-27 17:12:01,637] {processor.py:163} INFO - Started process (PID=2827) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:12:01,641] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:12:01,646] {logging_mixin.py:109} INFO - [2022-04-27 17:12:01,645] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:12:02,126] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:12:02,133] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:12:02,139] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:12:02,151] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:12:02,164] {logging_mixin.py:109} INFO - [2022-04-27 17:12:02,154] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:12:02,199] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:12:02,220] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.588 seconds
[2022-04-27 17:12:32,892] {processor.py:163} INFO - Started process (PID=2854) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:12:32,907] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:12:32,920] {logging_mixin.py:109} INFO - [2022-04-27 17:12:32,919] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:12:34,332] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:12:34,336] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:12:34,341] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:12:34,346] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:12:34,361] {logging_mixin.py:109} INFO - [2022-04-27 17:12:34,355] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:12:34,393] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:12:34,411] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.575 seconds
[2022-04-27 17:13:04,602] {processor.py:163} INFO - Started process (PID=2878) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:13:04,605] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:13:04,609] {logging_mixin.py:109} INFO - [2022-04-27 17:13:04,607] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:13:05,210] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:13:05,214] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:13:05,218] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:13:05,224] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:13:05,233] {logging_mixin.py:109} INFO - [2022-04-27 17:13:05,227] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:13:05,264] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:13:05,283] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.687 seconds
[2022-04-27 17:13:35,731] {processor.py:163} INFO - Started process (PID=2903) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:13:35,735] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:13:35,739] {logging_mixin.py:109} INFO - [2022-04-27 17:13:35,738] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:13:36,294] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:13:36,307] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:13:36,319] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:13:36,332] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:13:36,350] {logging_mixin.py:109} INFO - [2022-04-27 17:13:36,337] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:13:36,398] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:13:36,424] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.698 seconds
[2022-04-27 17:14:06,740] {processor.py:163} INFO - Started process (PID=2930) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:14:06,752] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:14:06,758] {logging_mixin.py:109} INFO - [2022-04-27 17:14:06,757] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:14:07,556] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:14:07,566] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:14:07,582] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:14:07,594] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:14:07,613] {logging_mixin.py:109} INFO - [2022-04-27 17:14:07,599] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:14:07,651] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:14:07,682] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.957 seconds
[2022-04-27 17:14:38,275] {processor.py:163} INFO - Started process (PID=2957) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:14:38,279] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:14:38,282] {logging_mixin.py:109} INFO - [2022-04-27 17:14:38,281] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:14:38,786] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:14:38,810] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:14:38,818] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:14:38,837] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:14:38,845] {logging_mixin.py:109} INFO - [2022-04-27 17:14:38,840] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:14:38,887] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:14:38,903] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.633 seconds
[2022-04-27 17:15:09,008] {processor.py:163} INFO - Started process (PID=2995) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:15:09,013] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:15:09,017] {logging_mixin.py:109} INFO - [2022-04-27 17:15:09,017] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:15:09,443] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:15:09,447] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:15:09,451] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:15:09,455] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:15:09,463] {logging_mixin.py:109} INFO - [2022-04-27 17:15:09,457] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:15:09,488] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:15:09,505] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.517 seconds
[2022-04-27 17:15:39,998] {processor.py:163} INFO - Started process (PID=3023) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:15:40,003] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:15:40,008] {logging_mixin.py:109} INFO - [2022-04-27 17:15:40,008] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:15:40,674] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:15:40,680] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:15:40,686] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:15:40,697] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:15:40,710] {logging_mixin.py:109} INFO - [2022-04-27 17:15:40,700] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:15:40,742] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:15:40,773] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.781 seconds
[2022-04-27 17:16:11,647] {processor.py:163} INFO - Started process (PID=3052) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:16:11,652] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:16:11,655] {logging_mixin.py:109} INFO - [2022-04-27 17:16:11,655] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:16:12,253] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:16:12,265] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:16:12,273] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:16:12,283] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:16:12,297] {logging_mixin.py:109} INFO - [2022-04-27 17:16:12,286] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:16:12,351] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:16:12,385] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.753 seconds
[2022-04-27 17:16:42,926] {processor.py:163} INFO - Started process (PID=3086) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:16:42,974] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:16:42,981] {logging_mixin.py:109} INFO - [2022-04-27 17:16:42,981] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:16:44,945] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:16:44,954] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:16:44,961] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:16:44,974] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:16:44,984] {logging_mixin.py:109} INFO - [2022-04-27 17:16:44,976] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:16:45,053] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:16:45,089] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.258 seconds
[2022-04-27 17:17:15,199] {processor.py:163} INFO - Started process (PID=3104) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:17:15,202] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:17:15,204] {logging_mixin.py:109} INFO - [2022-04-27 17:17:15,204] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:17:16,373] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:17:16,391] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:17:16,401] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:17:16,414] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:17:16,447] {logging_mixin.py:109} INFO - [2022-04-27 17:17:16,421] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:17:16,507] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:17:16,547] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.355 seconds
[2022-04-27 17:17:47,287] {processor.py:163} INFO - Started process (PID=3129) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:17:47,290] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:17:47,294] {logging_mixin.py:109} INFO - [2022-04-27 17:17:47,293] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:17:47,782] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:17:47,785] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:17:47,788] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:17:47,793] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:17:47,799] {logging_mixin.py:109} INFO - [2022-04-27 17:17:47,795] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:17:47,822] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:17:47,835] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.559 seconds
[2022-04-27 17:18:18,840] {processor.py:163} INFO - Started process (PID=3154) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:18:18,852] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:18:18,861] {logging_mixin.py:109} INFO - [2022-04-27 17:18:18,858] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:18:19,467] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:18:19,473] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:18:19,477] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:18:19,485] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:18:19,492] {logging_mixin.py:109} INFO - [2022-04-27 17:18:19,487] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:18:19,520] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:18:19,541] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.722 seconds
[2022-04-27 17:18:49,866] {processor.py:163} INFO - Started process (PID=3181) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:18:49,871] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:18:49,876] {logging_mixin.py:109} INFO - [2022-04-27 17:18:49,875] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:18:50,279] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:18:50,294] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:18:50,297] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:18:50,301] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:18:50,314] {logging_mixin.py:109} INFO - [2022-04-27 17:18:50,304] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:18:50,346] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:18:50,369] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.513 seconds
[2022-04-27 17:19:20,761] {processor.py:163} INFO - Started process (PID=3218) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:19:20,766] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:19:20,769] {logging_mixin.py:109} INFO - [2022-04-27 17:19:20,768] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:19:21,440] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:19:21,445] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:19:21,450] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:19:21,459] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:19:21,470] {logging_mixin.py:109} INFO - [2022-04-27 17:19:21,462] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:19:21,507] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:19:21,527] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.807 seconds
[2022-04-27 17:19:51,767] {processor.py:163} INFO - Started process (PID=3241) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:19:51,770] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:19:51,773] {logging_mixin.py:109} INFO - [2022-04-27 17:19:51,773] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:19:52,495] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:19:52,502] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:19:52,511] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:19:52,524] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:19:52,537] {logging_mixin.py:109} INFO - [2022-04-27 17:19:52,526] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:19:52,579] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:19:52,606] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.846 seconds
[2022-04-27 17:20:22,825] {processor.py:163} INFO - Started process (PID=3268) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:20:22,833] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:20:22,846] {logging_mixin.py:109} INFO - [2022-04-27 17:20:22,844] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:20:23,507] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:20:23,520] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:20:23,523] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:20:23,528] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:20:23,537] {logging_mixin.py:109} INFO - [2022-04-27 17:20:23,531] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:20:23,575] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:20:23,602] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.798 seconds
[2022-04-27 17:20:53,882] {processor.py:163} INFO - Started process (PID=3294) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:20:53,885] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:20:53,889] {logging_mixin.py:109} INFO - [2022-04-27 17:20:53,888] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:20:54,667] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:20:54,679] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:20:54,684] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:20:54,701] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:20:54,724] {logging_mixin.py:109} INFO - [2022-04-27 17:20:54,706] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:20:54,805] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:20:54,843] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.968 seconds
[2022-04-27 17:21:25,255] {processor.py:163} INFO - Started process (PID=3319) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:21:25,275] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:21:25,298] {logging_mixin.py:109} INFO - [2022-04-27 17:21:25,296] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:21:26,632] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:21:26,643] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:21:26,648] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:21:26,660] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:21:26,674] {logging_mixin.py:109} INFO - [2022-04-27 17:21:26,663] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:21:26,736] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:21:26,766] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.578 seconds
[2022-04-27 17:21:56,978] {processor.py:163} INFO - Started process (PID=3346) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:21:56,982] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:21:57,005] {logging_mixin.py:109} INFO - [2022-04-27 17:21:56,994] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:21:57,959] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:21:57,974] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:21:57,995] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:21:58,015] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:21:58,046] {logging_mixin.py:109} INFO - [2022-04-27 17:21:58,020] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:21:58,091] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:21:58,128] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.203 seconds
[2022-04-27 17:22:28,255] {processor.py:163} INFO - Started process (PID=3375) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:22:28,260] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:22:28,264] {logging_mixin.py:109} INFO - [2022-04-27 17:22:28,263] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:22:28,622] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:22:28,626] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:22:28,629] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:22:28,632] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:22:28,639] {logging_mixin.py:109} INFO - [2022-04-27 17:22:28,634] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:22:28,673] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:22:28,693] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.462 seconds
[2022-04-27 17:22:59,068] {processor.py:163} INFO - Started process (PID=3404) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:22:59,082] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:22:59,099] {logging_mixin.py:109} INFO - [2022-04-27 17:22:59,089] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:23:00,467] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:23:00,471] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:23:00,474] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:23:00,479] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:23:00,487] {logging_mixin.py:109} INFO - [2022-04-27 17:23:00,482] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:23:00,517] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:23:00,535] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.480 seconds
[2022-04-27 17:23:30,945] {processor.py:163} INFO - Started process (PID=3430) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:23:30,950] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:23:30,961] {logging_mixin.py:109} INFO - [2022-04-27 17:23:30,961] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:23:32,660] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:23:32,673] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:23:32,677] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:23:32,689] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:23:32,719] {logging_mixin.py:109} INFO - [2022-04-27 17:23:32,702] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:23:32,823] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:23:32,917] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.989 seconds
[2022-04-27 17:24:03,625] {processor.py:163} INFO - Started process (PID=3448) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:24:03,629] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:24:03,632] {logging_mixin.py:109} INFO - [2022-04-27 17:24:03,631] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:24:03,970] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:24:03,973] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:24:03,976] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:24:03,981] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:24:03,989] {logging_mixin.py:109} INFO - [2022-04-27 17:24:03,984] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:24:04,035] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:24:04,056] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.437 seconds
[2022-04-27 17:24:34,283] {processor.py:163} INFO - Started process (PID=3474) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:24:34,285] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:24:34,288] {logging_mixin.py:109} INFO - [2022-04-27 17:24:34,287] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:24:34,733] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:24:34,742] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:24:34,751] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:24:34,759] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:24:34,776] {logging_mixin.py:109} INFO - [2022-04-27 17:24:34,763] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:24:34,811] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:24:34,827] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.594 seconds
[2022-04-27 17:25:05,460] {processor.py:163} INFO - Started process (PID=3501) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:25:05,465] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:25:05,472] {logging_mixin.py:109} INFO - [2022-04-27 17:25:05,472] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:25:06,759] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:25:06,764] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:25:06,769] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:25:06,775] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:25:06,783] {logging_mixin.py:109} INFO - [2022-04-27 17:25:06,777] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:25:06,815] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:25:06,839] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.389 seconds
[2022-04-27 17:25:37,516] {processor.py:163} INFO - Started process (PID=3528) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:25:37,520] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:25:37,522] {logging_mixin.py:109} INFO - [2022-04-27 17:25:37,522] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:25:37,842] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:25:37,849] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:25:37,852] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:25:37,858] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:25:37,868] {logging_mixin.py:109} INFO - [2022-04-27 17:25:37,861] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:25:37,900] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:25:37,918] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.413 seconds
[2022-04-27 17:26:08,127] {processor.py:163} INFO - Started process (PID=3558) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:26:08,136] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:26:08,138] {logging_mixin.py:109} INFO - [2022-04-27 17:26:08,138] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:26:08,847] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:26:08,855] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:26:08,860] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:26:08,869] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:26:08,883] {logging_mixin.py:109} INFO - [2022-04-27 17:26:08,871] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:26:08,936] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:26:08,954] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.832 seconds
[2022-04-27 17:26:39,321] {processor.py:163} INFO - Started process (PID=3589) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:26:39,328] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:26:39,332] {logging_mixin.py:109} INFO - [2022-04-27 17:26:39,331] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:26:39,733] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:26:39,741] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:26:39,748] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:26:39,752] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:26:39,758] {logging_mixin.py:109} INFO - [2022-04-27 17:26:39,753] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:26:39,791] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:26:39,817] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.511 seconds
[2022-04-27 17:27:09,902] {processor.py:163} INFO - Started process (PID=3622) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:27:09,905] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:27:09,908] {logging_mixin.py:109} INFO - [2022-04-27 17:27:09,907] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:27:10,304] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:27:10,309] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:27:10,314] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:27:10,319] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:27:10,327] {logging_mixin.py:109} INFO - [2022-04-27 17:27:10,321] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:27:10,366] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:27:10,388] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.491 seconds
[2022-04-27 17:27:41,130] {processor.py:163} INFO - Started process (PID=3648) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:27:41,146] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:27:41,157] {logging_mixin.py:109} INFO - [2022-04-27 17:27:41,157] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:27:47,489] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:27:47,526] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:27:47,562] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:27:47,604] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:27:47,677] {logging_mixin.py:109} INFO - [2022-04-27 17:27:47,615] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:27:47,940] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:27:48,147] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 7.071 seconds
[2022-04-27 17:28:19,164] {processor.py:163} INFO - Started process (PID=3669) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:28:19,213] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:28:19,222] {logging_mixin.py:109} INFO - [2022-04-27 17:28:19,220] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:28:25,107] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:28:25,153] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:28:25,187] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:28:25,243] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:28:25,340] {logging_mixin.py:109} INFO - [2022-04-27 17:28:25,259] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:28:25,617] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:28:25,692] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 6.626 seconds
[2022-04-27 17:28:56,267] {processor.py:163} INFO - Started process (PID=3689) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:28:56,285] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:28:56,293] {logging_mixin.py:109} INFO - [2022-04-27 17:28:56,293] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:29:00,071] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:29:00,110] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:29:00,129] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:29:00,146] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:29:00,174] {logging_mixin.py:109} INFO - [2022-04-27 17:29:00,157] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:29:00,295] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:29:00,341] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.100 seconds
[2022-04-27 17:29:30,868] {processor.py:163} INFO - Started process (PID=3714) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:29:30,878] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:29:30,884] {logging_mixin.py:109} INFO - [2022-04-27 17:29:30,883] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:29:31,698] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:29:31,709] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:29:31,719] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:29:31,733] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:29:31,754] {logging_mixin.py:109} INFO - [2022-04-27 17:29:31,736] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:29:31,811] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:29:31,842] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.006 seconds
[2022-04-27 17:30:02,234] {processor.py:163} INFO - Started process (PID=3740) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:30:02,246] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:30:02,249] {logging_mixin.py:109} INFO - [2022-04-27 17:30:02,249] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:30:05,603] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:30:05,616] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:30:05,631] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:30:05,649] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:30:05,679] {logging_mixin.py:109} INFO - [2022-04-27 17:30:05,654] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:30:05,737] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:30:05,779] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.596 seconds
[2022-04-27 17:30:36,599] {processor.py:163} INFO - Started process (PID=3757) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:30:36,636] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:30:36,668] {logging_mixin.py:109} INFO - [2022-04-27 17:30:36,668] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:30:39,153] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:30:39,174] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:30:39,190] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:30:39,218] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:30:39,261] {logging_mixin.py:109} INFO - [2022-04-27 17:30:39,233] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:30:39,333] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:30:39,400] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.851 seconds
[2022-04-27 17:31:09,899] {processor.py:163} INFO - Started process (PID=3780) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:31:09,902] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:31:09,904] {logging_mixin.py:109} INFO - [2022-04-27 17:31:09,904] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:31:10,258] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:31:10,263] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:31:10,266] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:31:10,270] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:31:10,278] {logging_mixin.py:109} INFO - [2022-04-27 17:31:10,272] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:31:10,304] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:31:10,320] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.432 seconds
[2022-04-27 17:31:41,324] {processor.py:163} INFO - Started process (PID=3806) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:31:41,327] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:31:41,332] {logging_mixin.py:109} INFO - [2022-04-27 17:31:41,331] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:31:41,648] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:31:41,652] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:31:41,655] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:31:41,660] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:31:41,666] {logging_mixin.py:109} INFO - [2022-04-27 17:31:41,662] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:31:41,696] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:31:41,711] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.392 seconds
[2022-04-27 17:32:12,351] {processor.py:163} INFO - Started process (PID=3834) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:32:12,357] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:32:12,359] {logging_mixin.py:109} INFO - [2022-04-27 17:32:12,359] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:32:12,823] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:32:12,828] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:32:12,831] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:32:12,835] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:32:12,846] {logging_mixin.py:109} INFO - [2022-04-27 17:32:12,837] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:32:12,873] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:32:12,886] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.541 seconds
[2022-04-27 17:32:42,950] {processor.py:163} INFO - Started process (PID=3864) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:32:42,958] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:32:42,962] {logging_mixin.py:109} INFO - [2022-04-27 17:32:42,961] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:32:43,410] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:32:43,419] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:32:43,424] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:32:43,432] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:32:43,440] {logging_mixin.py:109} INFO - [2022-04-27 17:32:43,435] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:32:43,470] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:32:43,485] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.541 seconds
[2022-04-27 17:33:14,024] {processor.py:163} INFO - Started process (PID=3891) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:33:14,027] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:33:14,030] {logging_mixin.py:109} INFO - [2022-04-27 17:33:14,029] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:33:14,446] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:33:14,460] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:33:14,473] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:33:14,482] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:33:14,503] {logging_mixin.py:109} INFO - [2022-04-27 17:33:14,487] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:33:14,544] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:33:14,584] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.565 seconds
[2022-04-27 17:33:44,822] {processor.py:163} INFO - Started process (PID=3928) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:33:44,826] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:33:44,829] {logging_mixin.py:109} INFO - [2022-04-27 17:33:44,828] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:33:45,168] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:33:45,172] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:33:45,174] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:33:45,183] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:33:45,194] {logging_mixin.py:109} INFO - [2022-04-27 17:33:45,185] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:33:45,226] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:33:45,243] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.427 seconds
[2022-04-27 17:34:15,381] {processor.py:163} INFO - Started process (PID=3955) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:34:15,386] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:34:15,391] {logging_mixin.py:109} INFO - [2022-04-27 17:34:15,390] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:34:16,056] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:34:16,065] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:34:16,071] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:34:16,081] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:34:16,088] {logging_mixin.py:109} INFO - [2022-04-27 17:34:16,084] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:34:16,114] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:34:16,135] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.765 seconds
[2022-04-27 17:34:46,360] {processor.py:163} INFO - Started process (PID=3981) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:34:46,363] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:34:46,365] {logging_mixin.py:109} INFO - [2022-04-27 17:34:46,365] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:34:46,688] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:34:46,692] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:34:46,695] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:34:46,704] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:34:46,712] {logging_mixin.py:109} INFO - [2022-04-27 17:34:46,707] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:34:46,738] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:34:46,758] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.410 seconds
[2022-04-27 17:35:17,244] {processor.py:163} INFO - Started process (PID=4009) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:35:17,247] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:35:17,250] {logging_mixin.py:109} INFO - [2022-04-27 17:35:17,249] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:35:17,709] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:35:17,719] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:35:17,725] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:35:17,735] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:35:17,746] {logging_mixin.py:109} INFO - [2022-04-27 17:35:17,738] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:35:17,787] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:35:17,806] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.568 seconds
[2022-04-27 17:35:48,058] {processor.py:163} INFO - Started process (PID=4038) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:35:48,065] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:35:48,069] {logging_mixin.py:109} INFO - [2022-04-27 17:35:48,068] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:35:48,468] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:35:48,476] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:35:48,484] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:35:48,492] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:35:48,505] {logging_mixin.py:109} INFO - [2022-04-27 17:35:48,495] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:35:48,543] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:35:48,558] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.510 seconds
[2022-04-27 17:36:18,691] {processor.py:163} INFO - Started process (PID=4067) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:36:18,698] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:36:18,702] {logging_mixin.py:109} INFO - [2022-04-27 17:36:18,701] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:36:19,664] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:36:19,669] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:36:19,675] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:36:19,685] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:36:19,700] {logging_mixin.py:109} INFO - [2022-04-27 17:36:19,688] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:36:19,733] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:36:19,754] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.079 seconds
[2022-04-27 17:36:49,994] {processor.py:163} INFO - Started process (PID=4096) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:36:49,998] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:36:50,017] {logging_mixin.py:109} INFO - [2022-04-27 17:36:50,017] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:36:51,506] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:36:51,518] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:36:51,522] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:36:51,532] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:36:51,539] {logging_mixin.py:109} INFO - [2022-04-27 17:36:51,534] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:36:51,584] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:36:51,617] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.649 seconds
[2022-04-27 17:37:22,109] {processor.py:163} INFO - Started process (PID=4131) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:37:22,117] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:37:22,131] {logging_mixin.py:109} INFO - [2022-04-27 17:37:22,131] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:37:23,290] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:37:23,295] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:37:23,298] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:37:23,303] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:37:23,311] {logging_mixin.py:109} INFO - [2022-04-27 17:37:23,306] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:37:23,337] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:37:23,366] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.276 seconds
[2022-04-27 17:37:53,965] {processor.py:163} INFO - Started process (PID=4155) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:37:53,970] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:37:53,976] {logging_mixin.py:109} INFO - [2022-04-27 17:37:53,975] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:37:54,457] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:37:54,461] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:37:54,465] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:37:54,470] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:37:54,478] {logging_mixin.py:109} INFO - [2022-04-27 17:37:54,472] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:37:54,508] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:37:54,524] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.609 seconds
[2022-04-27 17:38:25,125] {processor.py:163} INFO - Started process (PID=4182) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:38:25,129] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:38:25,132] {logging_mixin.py:109} INFO - [2022-04-27 17:38:25,132] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:38:25,467] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:38:25,475] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:38:25,483] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:38:25,487] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:38:25,494] {logging_mixin.py:109} INFO - [2022-04-27 17:38:25,489] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:38:25,518] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:38:25,533] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.418 seconds
[2022-04-27 17:38:55,844] {processor.py:163} INFO - Started process (PID=4210) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:38:55,850] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:38:55,853] {logging_mixin.py:109} INFO - [2022-04-27 17:38:55,853] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:38:56,396] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:38:56,399] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:38:56,402] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:38:56,407] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:38:56,414] {logging_mixin.py:109} INFO - [2022-04-27 17:38:56,410] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:38:56,436] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:38:56,449] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.615 seconds
[2022-04-27 17:39:26,525] {processor.py:163} INFO - Started process (PID=4236) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:39:26,529] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:39:26,531] {logging_mixin.py:109} INFO - [2022-04-27 17:39:26,530] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:39:26,933] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:39:26,937] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:39:26,946] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:39:26,958] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:39:26,975] {logging_mixin.py:109} INFO - [2022-04-27 17:39:26,962] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:39:27,018] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:39:27,037] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.523 seconds
[2022-04-27 17:39:57,568] {processor.py:163} INFO - Started process (PID=4276) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:39:57,579] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:39:57,585] {logging_mixin.py:109} INFO - [2022-04-27 17:39:57,584] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:39:58,089] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:39:58,098] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:39:58,104] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:39:58,109] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:39:58,114] {logging_mixin.py:109} INFO - [2022-04-27 17:39:58,111] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:39:58,141] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:39:58,162] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.605 seconds
[2022-04-27 17:40:28,567] {processor.py:163} INFO - Started process (PID=4302) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:40:28,573] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:40:28,577] {logging_mixin.py:109} INFO - [2022-04-27 17:40:28,577] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:40:28,898] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:40:28,901] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:40:28,904] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:40:28,909] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:40:28,915] {logging_mixin.py:109} INFO - [2022-04-27 17:40:28,911] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:40:28,941] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:40:28,959] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.403 seconds
[2022-04-27 17:40:59,004] {processor.py:163} INFO - Started process (PID=4328) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:40:59,007] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:40:59,010] {logging_mixin.py:109} INFO - [2022-04-27 17:40:59,009] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:40:59,425] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:40:59,429] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:40:59,432] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:40:59,436] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:40:59,444] {logging_mixin.py:109} INFO - [2022-04-27 17:40:59,439] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:40:59,473] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:40:59,497] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.499 seconds
[2022-04-27 17:41:29,728] {processor.py:163} INFO - Started process (PID=4357) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:41:29,732] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:41:29,735] {logging_mixin.py:109} INFO - [2022-04-27 17:41:29,735] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:41:30,108] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:41:30,116] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:41:30,121] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:41:30,134] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:41:30,149] {logging_mixin.py:109} INFO - [2022-04-27 17:41:30,139] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:41:30,194] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:41:30,207] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.490 seconds
[2022-04-27 17:42:00,314] {processor.py:163} INFO - Started process (PID=4398) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:42:00,326] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:42:00,328] {logging_mixin.py:109} INFO - [2022-04-27 17:42:00,328] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:42:01,108] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:42:01,120] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:42:01,131] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:42:01,140] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:42:01,161] {logging_mixin.py:109} INFO - [2022-04-27 17:42:01,143] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:42:01,202] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:42:01,232] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.929 seconds
[2022-04-27 17:42:31,618] {processor.py:163} INFO - Started process (PID=4424) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:42:31,625] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:42:31,633] {logging_mixin.py:109} INFO - [2022-04-27 17:42:31,631] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:42:32,878] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:42:32,882] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:42:32,885] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:42:32,890] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:42:32,897] {logging_mixin.py:109} INFO - [2022-04-27 17:42:32,892] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:42:32,924] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:42:32,949] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.359 seconds
[2022-04-27 17:43:03,580] {processor.py:163} INFO - Started process (PID=4454) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:43:03,593] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:43:03,599] {logging_mixin.py:109} INFO - [2022-04-27 17:43:03,598] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:43:04,300] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:43:04,314] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:43:04,325] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:43:04,340] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:43:04,365] {logging_mixin.py:109} INFO - [2022-04-27 17:43:04,346] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:43:04,408] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:43:04,429] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.870 seconds
[2022-04-27 17:43:34,855] {processor.py:163} INFO - Started process (PID=4480) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:43:34,859] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:43:34,861] {logging_mixin.py:109} INFO - [2022-04-27 17:43:34,861] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:43:35,184] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:43:35,193] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:43:35,198] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:43:35,205] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:43:35,213] {logging_mixin.py:109} INFO - [2022-04-27 17:43:35,209] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:43:35,234] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:43:35,248] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.400 seconds
[2022-04-27 17:44:05,412] {processor.py:163} INFO - Started process (PID=4520) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:44:05,415] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:44:05,417] {logging_mixin.py:109} INFO - [2022-04-27 17:44:05,417] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:44:05,796] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:44:05,801] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:44:05,805] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:44:05,811] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:44:05,818] {logging_mixin.py:109} INFO - [2022-04-27 17:44:05,814] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:44:05,853] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:44:05,870] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.464 seconds
[2022-04-27 17:44:36,823] {processor.py:163} INFO - Started process (PID=4548) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:44:36,828] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:44:36,831] {logging_mixin.py:109} INFO - [2022-04-27 17:44:36,831] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:44:37,162] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:44:37,166] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:44:37,170] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:44:37,175] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:44:37,181] {logging_mixin.py:109} INFO - [2022-04-27 17:44:37,177] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:44:37,204] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:44:37,220] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.407 seconds
[2022-04-27 17:45:07,481] {processor.py:163} INFO - Started process (PID=4574) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:45:07,485] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:45:07,489] {logging_mixin.py:109} INFO - [2022-04-27 17:45:07,489] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:45:07,973] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:45:07,981] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:45:07,986] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:45:07,993] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:45:08,002] {logging_mixin.py:109} INFO - [2022-04-27 17:45:07,995] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:45:08,047] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:45:08,073] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.603 seconds
[2022-04-27 17:45:38,307] {processor.py:163} INFO - Started process (PID=4602) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:45:38,313] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:45:38,317] {logging_mixin.py:109} INFO - [2022-04-27 17:45:38,317] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:45:38,652] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:45:38,656] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:45:38,660] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:45:38,664] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:45:38,671] {logging_mixin.py:109} INFO - [2022-04-27 17:45:38,666] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:45:38,699] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:45:38,719] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.423 seconds
[2022-04-27 17:46:09,056] {processor.py:163} INFO - Started process (PID=4628) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:46:09,060] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:46:09,063] {logging_mixin.py:109} INFO - [2022-04-27 17:46:09,063] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:46:09,705] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:46:09,716] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:46:09,721] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:46:09,731] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:46:09,741] {logging_mixin.py:109} INFO - [2022-04-27 17:46:09,733] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:46:09,791] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:46:09,836] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.792 seconds
[2022-04-27 17:46:40,066] {processor.py:163} INFO - Started process (PID=4655) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:46:40,070] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:46:40,073] {logging_mixin.py:109} INFO - [2022-04-27 17:46:40,072] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:46:40,723] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:46:40,728] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:46:40,734] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:46:40,748] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:46:40,756] {logging_mixin.py:109} INFO - [2022-04-27 17:46:40,751] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:46:40,801] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:46:40,831] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.774 seconds
[2022-04-27 17:47:11,465] {processor.py:163} INFO - Started process (PID=4681) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:47:11,469] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:47:11,472] {logging_mixin.py:109} INFO - [2022-04-27 17:47:11,472] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:47:11,814] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:47:11,821] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:47:11,831] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:47:11,839] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:47:11,850] {logging_mixin.py:109} INFO - [2022-04-27 17:47:11,841] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:47:11,877] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:47:11,892] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.435 seconds
[2022-04-27 17:47:42,152] {processor.py:163} INFO - Started process (PID=4709) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:47:42,160] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:47:42,164] {logging_mixin.py:109} INFO - [2022-04-27 17:47:42,164] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:47:42,652] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:47:42,657] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:47:42,660] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:47:42,665] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:47:42,672] {logging_mixin.py:109} INFO - [2022-04-27 17:47:42,667] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:47:42,702] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:47:42,722] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.577 seconds
[2022-04-27 17:48:13,273] {processor.py:163} INFO - Started process (PID=4737) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:48:13,276] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:48:13,280] {logging_mixin.py:109} INFO - [2022-04-27 17:48:13,280] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:48:13,628] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:48:13,632] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:48:13,635] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:48:13,639] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:48:13,647] {logging_mixin.py:109} INFO - [2022-04-27 17:48:13,641] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:48:13,673] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:48:13,689] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.421 seconds
[2022-04-27 17:48:44,208] {processor.py:163} INFO - Started process (PID=4765) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:48:44,215] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:48:44,221] {logging_mixin.py:109} INFO - [2022-04-27 17:48:44,220] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:48:45,117] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:48:45,123] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:48:45,131] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:48:45,138] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:48:45,182] {logging_mixin.py:109} INFO - [2022-04-27 17:48:45,152] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:48:45,225] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:48:45,247] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.050 seconds
[2022-04-27 17:49:15,352] {processor.py:163} INFO - Started process (PID=4795) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:49:15,359] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:49:15,370] {logging_mixin.py:109} INFO - [2022-04-27 17:49:15,368] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:49:16,032] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:49:16,044] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:49:16,058] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:49:16,080] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:49:16,115] {logging_mixin.py:109} INFO - [2022-04-27 17:49:16,093] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:49:16,173] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:49:16,256] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.925 seconds
[2022-04-27 17:49:47,075] {processor.py:163} INFO - Started process (PID=4821) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:49:47,078] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:49:47,081] {logging_mixin.py:109} INFO - [2022-04-27 17:49:47,081] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:49:48,067] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:49:48,083] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:49:48,097] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:49:48,107] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:49:48,133] {logging_mixin.py:109} INFO - [2022-04-27 17:49:48,121] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:49:48,194] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:49:48,230] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.163 seconds
[2022-04-27 17:50:18,541] {processor.py:163} INFO - Started process (PID=4861) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:50:18,550] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:50:18,559] {logging_mixin.py:109} INFO - [2022-04-27 17:50:18,558] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:50:19,239] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:50:19,284] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:50:19,300] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:50:19,323] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:50:19,356] {logging_mixin.py:109} INFO - [2022-04-27 17:50:19,329] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:50:19,421] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:50:19,466] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.980 seconds
[2022-04-27 17:50:49,570] {processor.py:163} INFO - Started process (PID=4888) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:50:49,574] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:50:49,576] {logging_mixin.py:109} INFO - [2022-04-27 17:50:49,576] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:50:49,992] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:50:49,997] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:50:50,001] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:50:50,005] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:50:50,013] {logging_mixin.py:109} INFO - [2022-04-27 17:50:50,007] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:50:50,042] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:50:50,057] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.491 seconds
[2022-04-27 17:51:20,181] {processor.py:163} INFO - Started process (PID=4915) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:51:20,185] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:51:20,188] {logging_mixin.py:109} INFO - [2022-04-27 17:51:20,187] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:51:20,558] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:51:20,563] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:51:20,566] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:51:20,571] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:51:20,579] {logging_mixin.py:109} INFO - [2022-04-27 17:51:20,573] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:51:20,606] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:51:20,621] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.447 seconds
[2022-04-27 17:51:50,726] {processor.py:163} INFO - Started process (PID=4940) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:51:50,731] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:51:50,734] {logging_mixin.py:109} INFO - [2022-04-27 17:51:50,734] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:51:51,123] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:51:51,126] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:51:51,130] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:51:51,134] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:51:51,141] {logging_mixin.py:109} INFO - [2022-04-27 17:51:51,136] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:51:51,165] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:51:51,178] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.457 seconds
[2022-04-27 17:52:21,731] {processor.py:163} INFO - Started process (PID=4967) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:52:21,734] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:52:21,736] {logging_mixin.py:109} INFO - [2022-04-27 17:52:21,736] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:52:22,368] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:52:22,382] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:52:22,389] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:52:22,398] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:52:22,409] {logging_mixin.py:109} INFO - [2022-04-27 17:52:22,401] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:52:22,449] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:52:22,477] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.753 seconds
[2022-04-27 17:52:52,924] {processor.py:163} INFO - Started process (PID=4994) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:52:52,931] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:52:52,935] {logging_mixin.py:109} INFO - [2022-04-27 17:52:52,935] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:52:53,417] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:52:53,423] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:52:53,428] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:52:53,438] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:52:53,449] {logging_mixin.py:109} INFO - [2022-04-27 17:52:53,440] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:52:53,495] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:52:53,521] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.602 seconds
[2022-04-27 17:53:23,691] {processor.py:163} INFO - Started process (PID=5020) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:53:23,697] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:53:23,703] {logging_mixin.py:109} INFO - [2022-04-27 17:53:23,703] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:53:24,322] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:53:24,327] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:53:24,335] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:53:24,339] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:53:24,347] {logging_mixin.py:109} INFO - [2022-04-27 17:53:24,342] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:53:24,371] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:53:24,389] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.712 seconds
[2022-04-27 17:53:54,916] {processor.py:163} INFO - Started process (PID=5048) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:53:54,920] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:53:54,923] {logging_mixin.py:109} INFO - [2022-04-27 17:53:54,923] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:53:55,491] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:53:55,506] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:53:55,520] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:53:55,545] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:53:55,586] {logging_mixin.py:109} INFO - [2022-04-27 17:53:55,555] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:53:55,650] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:53:55,693] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.793 seconds
[2022-04-27 17:54:26,120] {processor.py:163} INFO - Started process (PID=5074) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:54:26,124] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:54:26,126] {logging_mixin.py:109} INFO - [2022-04-27 17:54:26,126] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:54:26,736] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:54:26,742] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:54:26,745] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:54:26,751] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:54:26,758] {logging_mixin.py:109} INFO - [2022-04-27 17:54:26,753] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:54:26,784] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:54:26,800] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.688 seconds
[2022-04-27 17:54:57,203] {processor.py:163} INFO - Started process (PID=5112) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:54:57,208] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:54:57,213] {logging_mixin.py:109} INFO - [2022-04-27 17:54:57,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:54:57,855] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:54:57,861] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:54:57,868] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:54:57,872] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:54:57,884] {logging_mixin.py:109} INFO - [2022-04-27 17:54:57,875] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:54:57,932] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:54:57,961] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.766 seconds
[2022-04-27 17:55:28,235] {processor.py:163} INFO - Started process (PID=5138) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:55:28,242] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:55:28,246] {logging_mixin.py:109} INFO - [2022-04-27 17:55:28,245] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:55:28,724] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:55:28,741] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:55:28,745] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:55:28,756] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:55:28,785] {logging_mixin.py:109} INFO - [2022-04-27 17:55:28,779] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:55:29,034] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:55:29,338] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.116 seconds
[2022-04-27 17:56:00,304] {processor.py:163} INFO - Started process (PID=5155) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:56:00,382] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:56:00,390] {logging_mixin.py:109} INFO - [2022-04-27 17:56:00,389] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:56:07,169] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:56:07,217] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:56:07,252] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:56:07,327] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:56:07,447] {logging_mixin.py:109} INFO - [2022-04-27 17:56:07,351] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:56:08,014] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:56:08,222] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 7.954 seconds
[2022-04-27 17:56:38,997] {processor.py:163} INFO - Started process (PID=5182) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:56:39,002] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:56:39,007] {logging_mixin.py:109} INFO - [2022-04-27 17:56:39,006] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:56:41,200] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:56:41,227] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:56:41,237] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:56:41,261] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:56:41,283] {logging_mixin.py:109} INFO - [2022-04-27 17:56:41,267] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:56:41,388] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:56:41,446] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.490 seconds
[2022-04-27 17:57:11,742] {processor.py:163} INFO - Started process (PID=5208) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:57:11,787] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:57:11,809] {logging_mixin.py:109} INFO - [2022-04-27 17:57:11,809] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:57:13,569] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:57:13,581] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:57:13,593] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:57:13,616] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:57:13,636] {logging_mixin.py:109} INFO - [2022-04-27 17:57:13,620] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:57:13,677] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:57:13,699] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.982 seconds
[2022-04-27 17:57:44,559] {processor.py:163} INFO - Started process (PID=5233) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:57:44,565] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-27 17:57:44,570] {logging_mixin.py:109} INFO - [2022-04-27 17:57:44,570] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:57:45,130] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-27 17:57:45,138] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-27 17:57:45,143] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-27 17:57:45,149] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-27 17:57:45,159] {logging_mixin.py:109} INFO - [2022-04-27 17:57:45,152] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-27 17:57:45,211] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-27 17:57:45,248] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.701 seconds
