[2022-04-28 01:06:16,854] {processor.py:163} INFO - Started process (PID=81) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:06:16,860] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:06:16,863] {logging_mixin.py:109} INFO - [2022-04-28 01:06:16,863] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:06:21,831] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:06:21,876] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:06:21,890] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:06:21,931] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:06:21,997] {logging_mixin.py:109} INFO - [2022-04-28 01:06:21,934] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:06:22,073] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:06:22,121] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 5.272 seconds
[2022-04-28 01:06:52,394] {processor.py:163} INFO - Started process (PID=107) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:06:52,398] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:06:52,400] {logging_mixin.py:109} INFO - [2022-04-28 01:06:52,400] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:06:52,969] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:06:52,975] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:06:52,981] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:06:52,988] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:06:52,997] {logging_mixin.py:109} INFO - [2022-04-28 01:06:52,990] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:06:53,040] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:06:53,059] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.671 seconds
[2022-04-28 01:07:23,449] {processor.py:163} INFO - Started process (PID=133) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:07:23,451] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:07:23,454] {logging_mixin.py:109} INFO - [2022-04-28 01:07:23,454] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:07:25,078] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:07:25,090] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:07:25,100] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:07:25,112] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:07:25,125] {logging_mixin.py:109} INFO - [2022-04-28 01:07:25,114] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:07:25,159] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:07:25,182] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.744 seconds
[2022-04-28 01:07:55,720] {processor.py:163} INFO - Started process (PID=160) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:07:55,739] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:07:55,761] {logging_mixin.py:109} INFO - [2022-04-28 01:07:55,761] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:08:03,054] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:08:03,096] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:08:03,123] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:08:03,224] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:08:03,372] {logging_mixin.py:109} INFO - [2022-04-28 01:08:03,259] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:08:03,636] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:08:03,789] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 8.125 seconds
[2022-04-28 01:08:35,221] {processor.py:163} INFO - Started process (PID=186) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:08:35,239] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:08:35,252] {logging_mixin.py:109} INFO - [2022-04-28 01:08:35,250] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:08:44,934] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:08:44,955] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:08:44,958] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:08:44,989] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:08:45,051] {logging_mixin.py:109} INFO - [2022-04-28 01:08:45,006] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:08:45,219] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:08:45,291] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 10.136 seconds
[2022-04-28 01:09:15,839] {processor.py:163} INFO - Started process (PID=212) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:09:15,846] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:09:15,850] {logging_mixin.py:109} INFO - [2022-04-28 01:09:15,850] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:09:17,387] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:09:17,401] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:09:17,411] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:09:17,424] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:09:17,445] {logging_mixin.py:109} INFO - [2022-04-28 01:09:17,430] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:09:17,501] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:09:17,548] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.719 seconds
[2022-04-28 01:09:48,327] {processor.py:163} INFO - Started process (PID=241) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:09:48,332] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:09:48,334] {logging_mixin.py:109} INFO - [2022-04-28 01:09:48,334] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:09:50,117] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:09:50,122] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:09:50,125] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:09:50,129] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:09:50,141] {logging_mixin.py:109} INFO - [2022-04-28 01:09:50,132] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:09:50,166] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:09:50,184] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.875 seconds
[2022-04-28 01:10:21,132] {processor.py:163} INFO - Started process (PID=269) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:10:21,135] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:10:21,137] {logging_mixin.py:109} INFO - [2022-04-28 01:10:21,137] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:10:21,734] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:10:21,741] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:10:21,747] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:10:21,759] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:10:21,769] {logging_mixin.py:109} INFO - [2022-04-28 01:10:21,762] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:10:21,809] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:10:21,832] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.705 seconds
[2022-04-28 01:10:51,933] {processor.py:163} INFO - Started process (PID=296) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:10:51,938] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:10:51,942] {logging_mixin.py:109} INFO - [2022-04-28 01:10:51,941] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:10:52,659] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:10:52,669] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:10:52,673] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:10:52,678] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:10:52,685] {logging_mixin.py:109} INFO - [2022-04-28 01:10:52,680] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:10:52,762] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:10:52,809] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.883 seconds
[2022-04-28 01:11:23,408] {processor.py:163} INFO - Started process (PID=323) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:11:23,420] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:11:23,427] {logging_mixin.py:109} INFO - [2022-04-28 01:11:23,426] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:11:29,261] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:11:29,287] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:11:29,309] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:11:29,338] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:11:29,368] {logging_mixin.py:109} INFO - [2022-04-28 01:11:29,348] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:11:29,405] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:11:29,453] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 6.060 seconds
[2022-04-28 01:11:59,785] {processor.py:163} INFO - Started process (PID=349) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:11:59,788] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:11:59,790] {logging_mixin.py:109} INFO - [2022-04-28 01:11:59,790] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:12:00,322] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:12:00,325] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:12:00,330] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:12:00,336] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:12:00,342] {logging_mixin.py:109} INFO - [2022-04-28 01:12:00,338] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:12:00,368] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:12:00,380] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.601 seconds
[2022-04-28 01:12:31,222] {processor.py:163} INFO - Started process (PID=377) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:12:31,229] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:12:31,235] {logging_mixin.py:109} INFO - [2022-04-28 01:12:31,235] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:12:33,240] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:12:33,265] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:12:33,275] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:12:33,290] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:12:33,307] {logging_mixin.py:109} INFO - [2022-04-28 01:12:33,293] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:12:33,433] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:12:33,461] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.254 seconds
[2022-04-28 01:13:04,538] {processor.py:163} INFO - Started process (PID=407) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:13:04,542] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:13:04,546] {logging_mixin.py:109} INFO - [2022-04-28 01:13:04,545] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:13:05,375] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:13:05,381] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:13:05,386] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:13:05,390] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:13:05,399] {logging_mixin.py:109} INFO - [2022-04-28 01:13:05,392] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:13:05,427] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:13:05,458] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.930 seconds
[2022-04-28 01:13:36,026] {processor.py:163} INFO - Started process (PID=434) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:13:36,029] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:13:36,031] {logging_mixin.py:109} INFO - [2022-04-28 01:13:36,030] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:13:36,599] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:13:36,603] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:13:36,607] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:13:36,613] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:13:36,623] {logging_mixin.py:109} INFO - [2022-04-28 01:13:36,615] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:13:36,652] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:13:36,661] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.641 seconds
[2022-04-28 01:14:06,778] {processor.py:163} INFO - Started process (PID=462) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:14:06,780] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:14:06,782] {logging_mixin.py:109} INFO - [2022-04-28 01:14:06,782] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:14:07,474] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:14:07,479] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:14:07,482] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:14:07,487] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:14:07,493] {logging_mixin.py:109} INFO - [2022-04-28 01:14:07,488] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:14:07,515] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:14:07,553] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.780 seconds
[2022-04-28 01:14:37,946] {processor.py:163} INFO - Started process (PID=498) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:14:37,958] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:14:37,962] {logging_mixin.py:109} INFO - [2022-04-28 01:14:37,961] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:14:39,350] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:14:39,368] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:14:39,375] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:14:39,388] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:14:39,410] {logging_mixin.py:109} INFO - [2022-04-28 01:14:39,393] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:14:39,448] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:14:39,494] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.581 seconds
[2022-04-28 01:15:09,964] {processor.py:163} INFO - Started process (PID=525) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:15:09,967] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:15:09,969] {logging_mixin.py:109} INFO - [2022-04-28 01:15:09,969] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:15:10,417] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:15:10,420] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:15:10,422] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:15:10,427] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:15:10,431] {logging_mixin.py:109} INFO - [2022-04-28 01:15:10,428] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:15:10,447] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:15:10,464] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.507 seconds
[2022-04-28 01:15:41,193] {processor.py:163} INFO - Started process (PID=551) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:15:41,196] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:15:41,198] {logging_mixin.py:109} INFO - [2022-04-28 01:15:41,198] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:15:41,663] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:15:41,671] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:15:41,676] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:15:41,680] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:15:41,690] {logging_mixin.py:109} INFO - [2022-04-28 01:15:41,683] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:15:41,718] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:15:41,732] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.543 seconds
[2022-04-28 01:16:12,400] {processor.py:163} INFO - Started process (PID=575) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:16:12,405] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:16:12,407] {logging_mixin.py:109} INFO - [2022-04-28 01:16:12,407] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:16:13,074] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:16:13,082] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:16:13,087] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:16:13,097] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:16:13,107] {logging_mixin.py:109} INFO - [2022-04-28 01:16:13,098] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:16:13,142] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:16:13,167] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.771 seconds
[2022-04-28 01:16:43,891] {processor.py:163} INFO - Started process (PID=609) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:16:43,903] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:16:43,914] {logging_mixin.py:109} INFO - [2022-04-28 01:16:43,912] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:16:44,504] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:16:44,513] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:16:44,519] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:16:44,526] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:16:44,537] {logging_mixin.py:109} INFO - [2022-04-28 01:16:44,528] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:16:44,558] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:16:44,581] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.721 seconds
[2022-04-28 01:17:14,924] {processor.py:163} INFO - Started process (PID=636) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:17:14,928] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:17:14,932] {logging_mixin.py:109} INFO - [2022-04-28 01:17:14,932] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:17:15,436] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:17:15,440] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:17:15,444] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:17:15,449] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:17:15,456] {logging_mixin.py:109} INFO - [2022-04-28 01:17:15,451] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:17:15,475] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:17:15,490] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.572 seconds
[2022-04-28 01:17:45,753] {processor.py:163} INFO - Started process (PID=662) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:17:45,757] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:17:45,759] {logging_mixin.py:109} INFO - [2022-04-28 01:17:45,759] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:17:46,233] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:17:46,237] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:17:46,241] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:17:46,246] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:17:46,253] {logging_mixin.py:109} INFO - [2022-04-28 01:17:46,248] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:17:46,273] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:17:46,286] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.540 seconds
[2022-04-28 01:18:16,586] {processor.py:163} INFO - Started process (PID=688) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:18:16,593] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:18:16,599] {logging_mixin.py:109} INFO - [2022-04-28 01:18:16,598] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:18:17,745] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:18:17,758] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:18:17,771] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:18:17,779] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:18:17,790] {logging_mixin.py:109} INFO - [2022-04-28 01:18:17,781] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:18:17,822] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:18:17,844] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.282 seconds
[2022-04-28 01:18:48,925] {processor.py:163} INFO - Started process (PID=725) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:18:48,934] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:18:48,939] {logging_mixin.py:109} INFO - [2022-04-28 01:18:48,938] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:18:49,931] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:18:49,944] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:18:49,951] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:18:49,962] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:18:49,972] {logging_mixin.py:109} INFO - [2022-04-28 01:18:49,964] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:18:50,003] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:18:50,029] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.124 seconds
[2022-04-28 01:19:20,264] {processor.py:163} INFO - Started process (PID=753) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:19:20,267] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:19:20,269] {logging_mixin.py:109} INFO - [2022-04-28 01:19:20,269] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:19:21,093] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:19:21,101] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:19:21,104] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:19:21,108] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:19:21,121] {logging_mixin.py:109} INFO - [2022-04-28 01:19:21,117] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:19:21,141] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:19:21,159] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.901 seconds
[2022-04-28 01:19:51,827] {processor.py:163} INFO - Started process (PID=781) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:19:51,830] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:19:51,832] {logging_mixin.py:109} INFO - [2022-04-28 01:19:51,832] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:19:52,236] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:19:52,239] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:19:52,242] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:19:52,246] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:19:52,250] {logging_mixin.py:109} INFO - [2022-04-28 01:19:52,247] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:19:52,268] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:19:52,280] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.458 seconds
[2022-04-28 01:20:23,227] {processor.py:163} INFO - Started process (PID=819) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:20:23,230] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:20:23,232] {logging_mixin.py:109} INFO - [2022-04-28 01:20:23,232] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:20:23,725] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:20:23,728] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:20:23,731] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:20:23,734] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:20:23,739] {logging_mixin.py:109} INFO - [2022-04-28 01:20:23,735] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:20:23,756] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:20:23,769] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.549 seconds
[2022-04-28 01:20:54,436] {processor.py:163} INFO - Started process (PID=845) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:20:54,439] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:20:54,440] {logging_mixin.py:109} INFO - [2022-04-28 01:20:54,440] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:20:54,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:20:54,966] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:20:54,969] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:20:54,973] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:20:54,977] {logging_mixin.py:109} INFO - [2022-04-28 01:20:54,974] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:20:55,024] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:20:55,083] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.651 seconds
[2022-04-28 01:21:25,888] {processor.py:163} INFO - Started process (PID=883) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:21:25,892] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:21:25,894] {logging_mixin.py:109} INFO - [2022-04-28 01:21:25,894] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:21:26,873] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:21:26,877] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:21:26,880] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:21:26,884] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:21:26,891] {logging_mixin.py:109} INFO - [2022-04-28 01:21:26,886] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:21:26,922] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:21:26,939] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.068 seconds
[2022-04-28 01:21:57,695] {processor.py:163} INFO - Started process (PID=912) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:21:57,698] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:21:57,701] {logging_mixin.py:109} INFO - [2022-04-28 01:21:57,701] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:21:58,132] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:21:58,137] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:21:58,141] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:21:58,146] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:21:58,153] {logging_mixin.py:109} INFO - [2022-04-28 01:21:58,148] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:21:58,173] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:21:58,185] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.498 seconds
[2022-04-28 01:22:28,535] {processor.py:163} INFO - Started process (PID=937) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:22:28,539] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:22:28,542] {logging_mixin.py:109} INFO - [2022-04-28 01:22:28,541] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:22:29,117] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:22:29,124] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:22:29,129] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:22:29,137] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:22:29,149] {logging_mixin.py:109} INFO - [2022-04-28 01:22:29,140] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:22:29,189] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:22:29,204] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.676 seconds
[2022-04-28 01:22:59,468] {processor.py:163} INFO - Started process (PID=965) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:22:59,472] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:22:59,474] {logging_mixin.py:109} INFO - [2022-04-28 01:22:59,474] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:23:00,007] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:23:00,012] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:23:00,018] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:23:00,023] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:23:00,034] {logging_mixin.py:109} INFO - [2022-04-28 01:23:00,025] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:23:00,056] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:23:00,068] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.608 seconds
[2022-04-28 01:23:30,356] {processor.py:163} INFO - Started process (PID=992) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:23:30,360] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:23:30,363] {logging_mixin.py:109} INFO - [2022-04-28 01:23:30,363] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:23:30,802] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:23:30,808] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:23:30,812] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:23:30,816] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:23:30,821] {logging_mixin.py:109} INFO - [2022-04-28 01:23:30,817] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:23:30,835] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:23:30,845] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.498 seconds
[2022-04-28 01:24:01,210] {processor.py:163} INFO - Started process (PID=1030) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:24:01,212] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:24:01,214] {logging_mixin.py:109} INFO - [2022-04-28 01:24:01,214] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:24:01,672] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:24:01,676] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:24:01,680] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:24:01,685] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:24:01,700] {logging_mixin.py:109} INFO - [2022-04-28 01:24:01,687] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:24:01,723] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:24:01,740] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.535 seconds
[2022-04-28 01:24:31,865] {processor.py:163} INFO - Started process (PID=1057) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:24:31,867] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:24:31,869] {logging_mixin.py:109} INFO - [2022-04-28 01:24:31,869] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:24:32,327] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:24:32,331] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:24:32,334] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:24:32,339] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:24:32,345] {logging_mixin.py:109} INFO - [2022-04-28 01:24:32,341] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:24:32,381] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:24:32,397] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.537 seconds
[2022-04-28 01:25:03,100] {processor.py:163} INFO - Started process (PID=1084) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:25:03,111] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:25:03,119] {logging_mixin.py:109} INFO - [2022-04-28 01:25:03,118] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:25:04,183] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:25:04,188] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:25:04,192] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:25:04,198] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:25:04,205] {logging_mixin.py:109} INFO - [2022-04-28 01:25:04,201] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:25:04,227] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:25:04,256] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.178 seconds
[2022-04-28 01:25:34,807] {processor.py:163} INFO - Started process (PID=1119) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:25:34,815] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:25:34,821] {logging_mixin.py:109} INFO - [2022-04-28 01:25:34,820] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:25:36,425] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:25:36,443] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:25:36,459] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:25:36,480] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:25:36,504] {logging_mixin.py:109} INFO - [2022-04-28 01:25:36,485] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:25:36,573] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:25:36,607] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.823 seconds
[2022-04-28 01:26:07,117] {processor.py:163} INFO - Started process (PID=1144) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:26:07,122] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:26:07,125] {logging_mixin.py:109} INFO - [2022-04-28 01:26:07,124] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:26:07,900] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:26:07,904] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:26:07,908] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:26:07,912] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:26:07,917] {logging_mixin.py:109} INFO - [2022-04-28 01:26:07,914] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:26:07,972] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:26:07,993] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.890 seconds
[2022-04-28 01:26:38,186] {processor.py:163} INFO - Started process (PID=1169) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:26:38,194] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:26:38,199] {logging_mixin.py:109} INFO - [2022-04-28 01:26:38,199] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:26:39,030] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:26:39,039] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:26:39,046] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:26:39,056] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:26:39,065] {logging_mixin.py:109} INFO - [2022-04-28 01:26:39,059] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:26:39,094] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:26:39,109] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.954 seconds
[2022-04-28 01:27:09,788] {processor.py:163} INFO - Started process (PID=1196) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:27:09,792] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:27:09,793] {logging_mixin.py:109} INFO - [2022-04-28 01:27:09,793] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:27:10,360] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:27:10,365] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:27:10,369] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:27:10,374] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:27:10,380] {logging_mixin.py:109} INFO - [2022-04-28 01:27:10,375] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:27:10,401] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:27:10,418] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.639 seconds
[2022-04-28 01:27:40,911] {processor.py:163} INFO - Started process (PID=1224) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:27:40,915] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:27:40,917] {logging_mixin.py:109} INFO - [2022-04-28 01:27:40,917] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:27:41,387] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:27:41,392] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:27:41,396] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:27:41,402] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:27:41,408] {logging_mixin.py:109} INFO - [2022-04-28 01:27:41,403] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:27:41,423] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:27:41,435] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.533 seconds
[2022-04-28 01:28:11,768] {processor.py:163} INFO - Started process (PID=1253) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:28:11,773] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:28:11,776] {logging_mixin.py:109} INFO - [2022-04-28 01:28:11,775] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:28:12,263] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:28:12,268] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:28:12,272] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:28:12,278] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:28:12,286] {logging_mixin.py:109} INFO - [2022-04-28 01:28:12,280] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:28:12,308] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:28:12,321] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.564 seconds
[2022-04-28 01:28:42,955] {processor.py:163} INFO - Started process (PID=1281) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:28:42,958] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:28:42,960] {logging_mixin.py:109} INFO - [2022-04-28 01:28:42,960] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:28:43,464] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:28:43,471] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:28:43,476] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:28:43,485] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:28:43,501] {logging_mixin.py:109} INFO - [2022-04-28 01:28:43,487] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:28:43,536] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:28:43,553] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.606 seconds
[2022-04-28 01:29:14,271] {processor.py:163} INFO - Started process (PID=1310) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:29:14,276] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:29:14,280] {logging_mixin.py:109} INFO - [2022-04-28 01:29:14,280] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:29:15,862] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:29:15,866] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:29:15,872] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:29:15,880] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:29:15,892] {logging_mixin.py:109} INFO - [2022-04-28 01:29:15,885] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:29:15,918] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:29:15,949] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.692 seconds
[2022-04-28 01:29:46,436] {processor.py:163} INFO - Started process (PID=1337) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:29:46,439] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:29:46,441] {logging_mixin.py:109} INFO - [2022-04-28 01:29:46,441] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:29:47,258] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:29:47,267] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:29:47,273] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:29:47,283] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:29:47,291] {logging_mixin.py:109} INFO - [2022-04-28 01:29:47,285] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:29:47,316] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:29:47,337] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.911 seconds
[2022-04-28 01:30:17,609] {processor.py:163} INFO - Started process (PID=1366) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:30:17,623] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:30:17,628] {logging_mixin.py:109} INFO - [2022-04-28 01:30:17,627] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:30:18,685] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:30:18,694] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:30:18,702] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:30:18,713] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:30:18,724] {logging_mixin.py:109} INFO - [2022-04-28 01:30:18,715] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:30:18,753] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:30:18,782] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.196 seconds
[2022-04-28 01:30:48,953] {processor.py:163} INFO - Started process (PID=1406) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:30:48,961] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:30:48,965] {logging_mixin.py:109} INFO - [2022-04-28 01:30:48,964] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:30:49,838] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:30:49,845] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:30:49,850] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:30:49,854] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:30:49,864] {logging_mixin.py:109} INFO - [2022-04-28 01:30:49,860] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:30:49,897] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:30:49,918] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.977 seconds
[2022-04-28 01:31:20,449] {processor.py:163} INFO - Started process (PID=1433) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:31:20,453] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:31:20,456] {logging_mixin.py:109} INFO - [2022-04-28 01:31:20,455] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:31:20,942] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:31:20,947] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:31:20,950] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:31:20,955] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:31:20,962] {logging_mixin.py:109} INFO - [2022-04-28 01:31:20,957] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:31:20,986] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:31:21,003] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.561 seconds
[2022-04-28 01:31:51,166] {processor.py:163} INFO - Started process (PID=1460) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:31:51,170] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:31:51,172] {logging_mixin.py:109} INFO - [2022-04-28 01:31:51,172] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:31:51,938] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:31:51,942] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:31:51,944] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:31:51,948] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:31:51,953] {logging_mixin.py:109} INFO - [2022-04-28 01:31:51,949] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:31:51,967] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:31:51,977] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.819 seconds
[2022-04-28 01:32:22,270] {processor.py:163} INFO - Started process (PID=1488) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:32:22,275] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:32:22,278] {logging_mixin.py:109} INFO - [2022-04-28 01:32:22,278] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:32:22,982] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:32:22,986] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:32:22,989] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:32:22,995] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:32:23,002] {logging_mixin.py:109} INFO - [2022-04-28 01:32:22,998] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:32:23,024] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:32:23,039] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.781 seconds
[2022-04-28 01:32:53,545] {processor.py:163} INFO - Started process (PID=1527) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:32:53,548] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:32:53,551] {logging_mixin.py:109} INFO - [2022-04-28 01:32:53,550] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:32:54,084] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:32:54,089] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:32:54,096] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:32:54,119] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:32:54,130] {logging_mixin.py:109} INFO - [2022-04-28 01:32:54,123] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:32:54,157] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:32:54,188] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.649 seconds
[2022-04-28 01:33:24,674] {processor.py:163} INFO - Started process (PID=1556) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:33:24,682] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:33:24,686] {logging_mixin.py:109} INFO - [2022-04-28 01:33:24,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:33:26,691] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:33:26,715] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:33:26,730] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:33:26,755] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:33:26,768] {logging_mixin.py:109} INFO - [2022-04-28 01:33:26,757] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:33:26,801] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:33:26,835] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.174 seconds
[2022-04-28 01:33:57,238] {processor.py:163} INFO - Started process (PID=1581) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:33:57,254] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:33:57,264] {logging_mixin.py:109} INFO - [2022-04-28 01:33:57,263] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:33:58,418] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:33:58,421] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:33:58,425] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:33:58,429] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:33:58,436] {logging_mixin.py:109} INFO - [2022-04-28 01:33:58,432] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:33:58,465] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:33:58,481] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.277 seconds
[2022-04-28 01:34:28,898] {processor.py:163} INFO - Started process (PID=1608) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:34:28,905] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:34:28,915] {logging_mixin.py:109} INFO - [2022-04-28 01:34:28,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:34:29,660] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:34:29,663] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:34:29,666] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:34:29,670] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:34:29,675] {logging_mixin.py:109} INFO - [2022-04-28 01:34:29,671] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:34:29,690] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:34:29,699] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.828 seconds
[2022-04-28 01:35:00,177] {processor.py:163} INFO - Started process (PID=1637) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:35:00,182] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:35:00,185] {logging_mixin.py:109} INFO - [2022-04-28 01:35:00,185] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:35:00,698] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:35:00,702] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:35:00,706] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:35:00,710] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:35:00,715] {logging_mixin.py:109} INFO - [2022-04-28 01:35:00,711] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:35:00,736] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:35:00,750] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.581 seconds
[2022-04-28 01:35:31,116] {processor.py:163} INFO - Started process (PID=1665) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:35:31,122] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:35:31,125] {logging_mixin.py:109} INFO - [2022-04-28 01:35:31,124] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:35:32,105] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:35:32,111] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:35:32,118] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:35:32,131] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:35:32,142] {logging_mixin.py:109} INFO - [2022-04-28 01:35:32,134] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:35:32,177] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:35:32,208] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.106 seconds
[2022-04-28 01:36:02,503] {processor.py:163} INFO - Started process (PID=1693) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:36:02,506] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:36:02,507] {logging_mixin.py:109} INFO - [2022-04-28 01:36:02,507] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:36:02,915] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:36:02,918] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:36:02,920] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:36:02,932] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:36:02,938] {logging_mixin.py:109} INFO - [2022-04-28 01:36:02,933] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:36:02,959] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:36:02,972] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.478 seconds
[2022-04-28 01:36:33,677] {processor.py:163} INFO - Started process (PID=1721) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:36:33,680] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:36:33,685] {logging_mixin.py:109} INFO - [2022-04-28 01:36:33,684] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:36:34,393] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:36:34,399] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:36:34,403] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:36:34,410] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:36:34,417] {logging_mixin.py:109} INFO - [2022-04-28 01:36:34,412] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:36:34,436] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:36:34,451] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.788 seconds
[2022-04-28 01:37:04,778] {processor.py:163} INFO - Started process (PID=1760) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:37:04,784] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:37:04,792] {logging_mixin.py:109} INFO - [2022-04-28 01:37:04,791] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:37:05,857] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:37:05,868] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:37:05,876] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:37:05,889] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:37:05,899] {logging_mixin.py:109} INFO - [2022-04-28 01:37:05,891] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:37:05,943] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:37:05,969] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.200 seconds
[2022-04-28 01:37:36,167] {processor.py:163} INFO - Started process (PID=1789) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:37:36,171] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:37:36,173] {logging_mixin.py:109} INFO - [2022-04-28 01:37:36,172] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:37:36,575] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:37:36,579] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:37:36,581] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:37:36,584] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:37:36,588] {logging_mixin.py:109} INFO - [2022-04-28 01:37:36,585] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:37:36,603] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:37:36,611] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.455 seconds
[2022-04-28 01:38:06,681] {processor.py:163} INFO - Started process (PID=1815) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:38:06,694] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:38:06,700] {logging_mixin.py:109} INFO - [2022-04-28 01:38:06,699] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:38:07,154] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:38:07,159] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:38:07,162] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:38:07,167] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:38:07,173] {logging_mixin.py:109} INFO - [2022-04-28 01:38:07,169] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:38:07,194] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:38:07,207] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.544 seconds
[2022-04-28 01:38:37,739] {processor.py:163} INFO - Started process (PID=1842) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:38:37,749] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:38:37,756] {logging_mixin.py:109} INFO - [2022-04-28 01:38:37,756] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:38:38,258] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:38:38,262] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:38:38,264] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:38:38,269] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:38:38,275] {logging_mixin.py:109} INFO - [2022-04-28 01:38:38,271] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:38:38,296] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:38:38,310] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.603 seconds
[2022-04-28 01:39:09,100] {processor.py:163} INFO - Started process (PID=1879) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:39:09,103] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:39:09,114] {logging_mixin.py:109} INFO - [2022-04-28 01:39:09,114] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:39:09,799] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:39:09,811] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:39:09,815] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:39:09,820] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:39:09,836] {logging_mixin.py:109} INFO - [2022-04-28 01:39:09,831] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:39:09,874] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:39:09,896] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.811 seconds
[2022-04-28 01:39:40,000] {processor.py:163} INFO - Started process (PID=1908) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:39:40,003] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:39:40,007] {logging_mixin.py:109} INFO - [2022-04-28 01:39:40,006] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:39:40,320] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:39:40,323] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:39:40,326] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:39:40,330] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:39:40,335] {logging_mixin.py:109} INFO - [2022-04-28 01:39:40,332] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:39:40,352] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:39:40,363] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.369 seconds
[2022-04-28 01:44:28,289] {processor.py:163} INFO - Started process (PID=81) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:44:28,296] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:44:28,299] {logging_mixin.py:109} INFO - [2022-04-28 01:44:28,298] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:44:30,815] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:44:30,841] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:44:30,846] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:44:30,872] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:44:30,938] {logging_mixin.py:109} INFO - [2022-04-28 01:44:30,890] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:44:31,010] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:44:31,044] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.772 seconds
[2022-04-28 01:45:01,585] {processor.py:163} INFO - Started process (PID=107) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:45:01,588] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:45:01,590] {logging_mixin.py:109} INFO - [2022-04-28 01:45:01,590] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:45:02,012] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:45:02,015] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:45:02,021] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:45:02,027] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:45:02,032] {logging_mixin.py:109} INFO - [2022-04-28 01:45:02,028] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:45:02,054] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:45:02,066] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.485 seconds
[2022-04-28 01:45:32,296] {processor.py:163} INFO - Started process (PID=135) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:45:32,299] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:45:32,301] {logging_mixin.py:109} INFO - [2022-04-28 01:45:32,300] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:45:32,821] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:45:32,825] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:45:32,830] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:45:32,835] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:45:32,842] {logging_mixin.py:109} INFO - [2022-04-28 01:45:32,837] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:45:32,862] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:45:32,873] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.584 seconds
[2022-04-28 01:46:02,998] {processor.py:163} INFO - Started process (PID=172) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:46:03,002] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:46:03,004] {logging_mixin.py:109} INFO - [2022-04-28 01:46:03,004] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:46:03,582] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:46:03,586] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:46:03,589] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:46:03,593] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:46:03,598] {logging_mixin.py:109} INFO - [2022-04-28 01:46:03,594] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:46:03,623] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:46:03,635] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.643 seconds
[2022-04-28 01:46:35,436] {processor.py:163} INFO - Started process (PID=200) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:46:35,440] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:46:35,446] {logging_mixin.py:109} INFO - [2022-04-28 01:46:35,446] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:46:36,959] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:46:36,966] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:46:36,977] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:46:36,992] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:46:37,010] {logging_mixin.py:109} INFO - [2022-04-28 01:46:36,996] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:46:37,067] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:46:37,111] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.685 seconds
[2022-04-28 01:47:07,570] {processor.py:163} INFO - Started process (PID=234) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:47:07,573] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:47:07,576] {logging_mixin.py:109} INFO - [2022-04-28 01:47:07,575] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:47:08,223] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:47:08,227] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:47:08,229] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:47:08,233] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:47:08,238] {logging_mixin.py:109} INFO - [2022-04-28 01:47:08,234] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:47:08,256] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:47:08,269] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.726 seconds
[2022-04-28 01:47:38,399] {processor.py:163} INFO - Started process (PID=261) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:47:38,401] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:47:38,403] {logging_mixin.py:109} INFO - [2022-04-28 01:47:38,403] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:47:38,959] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:47:38,965] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:47:38,969] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:47:38,973] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:47:38,983] {logging_mixin.py:109} INFO - [2022-04-28 01:47:38,975] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:47:39,008] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:47:39,028] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.634 seconds
[2022-04-28 01:48:09,816] {processor.py:163} INFO - Started process (PID=289) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:48:09,819] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:48:09,821] {logging_mixin.py:109} INFO - [2022-04-28 01:48:09,821] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:48:10,301] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:48:10,306] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:48:10,310] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:48:10,316] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:48:10,323] {logging_mixin.py:109} INFO - [2022-04-28 01:48:10,318] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:48:10,353] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:48:10,363] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.554 seconds
[2022-04-28 01:48:40,667] {processor.py:163} INFO - Started process (PID=330) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:48:40,673] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:48:40,676] {logging_mixin.py:109} INFO - [2022-04-28 01:48:40,675] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:48:41,673] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:48:41,678] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:48:41,682] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:48:41,697] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:48:41,705] {logging_mixin.py:109} INFO - [2022-04-28 01:48:41,699] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:48:41,746] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:48:41,768] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.113 seconds
[2022-04-28 01:49:12,100] {processor.py:163} INFO - Started process (PID=359) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:49:12,103] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:49:12,104] {logging_mixin.py:109} INFO - [2022-04-28 01:49:12,104] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:49:12,491] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:49:12,495] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:49:12,497] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:49:12,501] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:49:12,505] {logging_mixin.py:109} INFO - [2022-04-28 01:49:12,502] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:49:12,523] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:49:12,535] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.441 seconds
[2022-04-28 01:49:42,958] {processor.py:163} INFO - Started process (PID=385) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:49:42,961] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:49:42,964] {logging_mixin.py:109} INFO - [2022-04-28 01:49:42,963] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:49:43,440] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:49:43,444] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:49:43,447] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:49:43,452] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:49:43,459] {logging_mixin.py:109} INFO - [2022-04-28 01:49:43,454] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:49:43,489] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:49:43,503] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.551 seconds
[2022-04-28 01:50:13,782] {processor.py:163} INFO - Started process (PID=423) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:50:13,784] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:50:13,786] {logging_mixin.py:109} INFO - [2022-04-28 01:50:13,786] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:50:14,170] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:50:14,174] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:50:14,178] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:50:14,182] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:50:14,189] {logging_mixin.py:109} INFO - [2022-04-28 01:50:14,184] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:50:14,208] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:50:14,219] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.445 seconds
[2022-04-28 01:50:44,545] {processor.py:163} INFO - Started process (PID=451) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:50:44,552] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:50:44,556] {logging_mixin.py:109} INFO - [2022-04-28 01:50:44,556] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:50:45,389] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:50:45,392] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:50:45,395] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:50:45,398] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:50:45,403] {logging_mixin.py:109} INFO - [2022-04-28 01:50:45,400] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:50:45,436] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:50:45,447] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.927 seconds
[2022-04-28 01:51:15,707] {processor.py:163} INFO - Started process (PID=488) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:51:15,711] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:51:15,713] {logging_mixin.py:109} INFO - [2022-04-28 01:51:15,713] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:51:16,129] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:51:16,134] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:51:16,138] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:51:16,145] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:51:16,152] {logging_mixin.py:109} INFO - [2022-04-28 01:51:16,146] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:51:16,183] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:51:16,197] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.496 seconds
[2022-04-28 01:51:46,289] {processor.py:163} INFO - Started process (PID=514) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:51:46,293] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:51:46,297] {logging_mixin.py:109} INFO - [2022-04-28 01:51:46,296] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:51:46,775] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:51:46,779] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:51:46,781] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:51:46,785] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:51:46,790] {logging_mixin.py:109} INFO - [2022-04-28 01:51:46,787] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:51:46,821] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:51:46,835] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.556 seconds
[2022-04-28 01:52:16,917] {processor.py:163} INFO - Started process (PID=544) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:52:16,919] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:52:16,922] {logging_mixin.py:109} INFO - [2022-04-28 01:52:16,922] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:52:17,316] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:52:17,319] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:52:17,322] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:52:17,326] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:52:17,330] {logging_mixin.py:109} INFO - [2022-04-28 01:52:17,327] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:52:17,350] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:52:17,362] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.454 seconds
[2022-04-28 01:52:47,608] {processor.py:163} INFO - Started process (PID=572) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:52:47,611] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:52:47,614] {logging_mixin.py:109} INFO - [2022-04-28 01:52:47,613] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:52:48,035] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:52:48,039] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:52:48,041] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:52:48,045] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:52:48,050] {logging_mixin.py:109} INFO - [2022-04-28 01:52:48,047] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:52:48,066] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:52:48,076] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.473 seconds
[2022-04-28 01:53:18,301] {processor.py:163} INFO - Started process (PID=609) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:53:18,303] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:53:18,305] {logging_mixin.py:109} INFO - [2022-04-28 01:53:18,305] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:53:19,978] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:53:19,991] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:53:20,001] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:53:20,011] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:53:20,031] {logging_mixin.py:109} INFO - [2022-04-28 01:53:20,018] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:53:20,082] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:53:20,114] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.826 seconds
[2022-04-28 01:53:50,398] {processor.py:163} INFO - Started process (PID=636) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:53:50,402] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:53:50,404] {logging_mixin.py:109} INFO - [2022-04-28 01:53:50,404] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:53:50,825] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:53:50,830] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:53:50,834] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:53:50,839] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:53:50,846] {logging_mixin.py:109} INFO - [2022-04-28 01:53:50,841] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:53:50,877] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:53:50,892] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.500 seconds
[2022-04-28 01:54:21,323] {processor.py:163} INFO - Started process (PID=663) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:54:21,326] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:54:21,328] {logging_mixin.py:109} INFO - [2022-04-28 01:54:21,328] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:54:22,053] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:54:22,091] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:54:22,094] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:54:22,111] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:54:22,137] {logging_mixin.py:109} INFO - [2022-04-28 01:54:22,124] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:54:22,296] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:54:22,336] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.017 seconds
[2022-04-28 01:54:53,041] {processor.py:163} INFO - Started process (PID=689) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:54:53,073] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:54:53,100] {logging_mixin.py:109} INFO - [2022-04-28 01:54:53,099] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:55:01,183] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:55:01,218] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:55:01,241] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:55:01,276] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:55:01,344] {logging_mixin.py:109} INFO - [2022-04-28 01:55:01,299] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:55:01,692] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:55:01,889] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 8.900 seconds
[2022-04-28 01:55:32,755] {processor.py:163} INFO - Started process (PID=715) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:55:32,786] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:55:32,802] {logging_mixin.py:109} INFO - [2022-04-28 01:55:32,802] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:55:37,049] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:55:37,064] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:55:37,124] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:55:37,186] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:55:37,234] {logging_mixin.py:109} INFO - [2022-04-28 01:55:37,206] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:55:37,482] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:55:37,633] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.931 seconds
[2022-04-28 01:56:08,591] {processor.py:163} INFO - Started process (PID=741) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:56:08,597] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:56:08,601] {logging_mixin.py:109} INFO - [2022-04-28 01:56:08,600] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:56:10,330] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:56:10,336] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:56:10,355] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:56:10,372] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:56:10,392] {logging_mixin.py:109} INFO - [2022-04-28 01:56:10,382] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:56:10,497] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:56:10,572] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.002 seconds
[2022-04-28 01:56:40,982] {processor.py:163} INFO - Started process (PID=768) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:56:41,002] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:56:41,009] {logging_mixin.py:109} INFO - [2022-04-28 01:56:41,008] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:56:43,248] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:56:43,269] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:56:43,291] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:56:43,310] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:56:43,361] {logging_mixin.py:109} INFO - [2022-04-28 01:56:43,314] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:56:43,491] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:56:43,566] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.603 seconds
[2022-04-28 01:57:13,935] {processor.py:163} INFO - Started process (PID=785) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:57:13,938] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:57:13,940] {logging_mixin.py:109} INFO - [2022-04-28 01:57:13,940] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:57:14,841] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:57:14,854] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:57:14,858] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:57:14,865] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:57:14,892] {logging_mixin.py:109} INFO - [2022-04-28 01:57:14,871] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:57:15,001] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:57:15,060] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.144 seconds
[2022-04-28 01:57:46,092] {processor.py:163} INFO - Started process (PID=810) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:57:46,095] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:57:46,098] {logging_mixin.py:109} INFO - [2022-04-28 01:57:46,097] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:57:47,335] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:57:47,347] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:57:47,350] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:57:47,357] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:57:47,363] {logging_mixin.py:109} INFO - [2022-04-28 01:57:47,358] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:57:47,396] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:57:47,433] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.348 seconds
[2022-04-28 01:58:17,634] {processor.py:163} INFO - Started process (PID=848) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:58:17,645] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:58:17,648] {logging_mixin.py:109} INFO - [2022-04-28 01:58:17,647] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:58:19,010] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:58:19,015] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:58:19,019] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:58:19,024] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:58:19,038] {logging_mixin.py:109} INFO - [2022-04-28 01:58:19,033] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:58:19,062] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:58:19,089] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.472 seconds
[2022-04-28 01:58:49,681] {processor.py:163} INFO - Started process (PID=876) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:58:49,690] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:58:49,694] {logging_mixin.py:109} INFO - [2022-04-28 01:58:49,694] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:58:51,852] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:58:51,859] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:58:51,867] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:58:51,879] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:58:51,903] {logging_mixin.py:109} INFO - [2022-04-28 01:58:51,884] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:58:51,943] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:58:51,979] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.338 seconds
[2022-04-28 01:59:22,451] {processor.py:163} INFO - Started process (PID=903) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:59:22,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:59:22,465] {logging_mixin.py:109} INFO - [2022-04-28 01:59:22,465] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:59:23,477] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:59:23,493] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:59:23,503] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:59:23,514] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:59:23,531] {logging_mixin.py:109} INFO - [2022-04-28 01:59:23,517] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:59:23,561] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:59:23,584] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.138 seconds
[2022-04-28 01:59:53,976] {processor.py:163} INFO - Started process (PID=929) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:59:53,993] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 01:59:53,997] {logging_mixin.py:109} INFO - [2022-04-28 01:59:53,996] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:59:55,095] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 01:59:55,110] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 01:59:55,122] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 01:59:55,139] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 01:59:55,153] {logging_mixin.py:109} INFO - [2022-04-28 01:59:55,142] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 01:59:55,190] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 01:59:55,216] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.252 seconds
[2022-04-28 02:00:26,010] {processor.py:163} INFO - Started process (PID=955) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:00:26,018] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:00:26,022] {logging_mixin.py:109} INFO - [2022-04-28 02:00:26,022] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:00:26,709] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:00:26,719] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:00:26,727] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:00:26,735] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:00:26,744] {logging_mixin.py:109} INFO - [2022-04-28 02:00:26,737] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:00:26,780] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:00:26,796] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.801 seconds
[2022-04-28 02:00:57,085] {processor.py:163} INFO - Started process (PID=994) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:00:57,096] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:00:57,099] {logging_mixin.py:109} INFO - [2022-04-28 02:00:57,099] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:00:58,254] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:00:58,258] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:00:58,264] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:00:58,271] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:00:58,284] {logging_mixin.py:109} INFO - [2022-04-28 02:00:58,273] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:00:58,318] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:00:58,342] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.291 seconds
[2022-04-28 02:01:28,513] {processor.py:163} INFO - Started process (PID=1020) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:01:28,515] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:01:28,517] {logging_mixin.py:109} INFO - [2022-04-28 02:01:28,517] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:01:29,016] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:01:29,026] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:01:29,032] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:01:29,036] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:01:29,047] {logging_mixin.py:109} INFO - [2022-04-28 02:01:29,038] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:01:29,074] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:01:29,086] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.577 seconds
[2022-04-28 02:01:59,497] {processor.py:163} INFO - Started process (PID=1046) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:01:59,500] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:01:59,501] {logging_mixin.py:109} INFO - [2022-04-28 02:01:59,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:01:59,956] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:01:59,960] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:01:59,965] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:01:59,970] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:01:59,977] {logging_mixin.py:109} INFO - [2022-04-28 02:01:59,972] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:01:59,993] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:02:00,002] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.514 seconds
[2022-04-28 02:02:30,648] {processor.py:163} INFO - Started process (PID=1072) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:02:30,650] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:02:30,653] {logging_mixin.py:109} INFO - [2022-04-28 02:02:30,652] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:02:31,485] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:02:31,489] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:02:31,499] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:02:31,503] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:02:31,509] {logging_mixin.py:109} INFO - [2022-04-28 02:02:31,505] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:02:31,539] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:02:31,557] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.916 seconds
[2022-04-28 02:03:01,819] {processor.py:163} INFO - Started process (PID=1108) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:03:01,827] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:03:01,829] {logging_mixin.py:109} INFO - [2022-04-28 02:03:01,829] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:03:02,883] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:03:02,903] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:03:02,912] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:03:02,919] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:03:02,931] {logging_mixin.py:109} INFO - [2022-04-28 02:03:02,922] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:03:02,962] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:03:02,982] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.173 seconds
[2022-04-28 02:03:33,587] {processor.py:163} INFO - Started process (PID=1136) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:03:33,592] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:03:33,595] {logging_mixin.py:109} INFO - [2022-04-28 02:03:33,594] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:03:34,042] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:03:34,046] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:03:34,049] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:03:34,053] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:03:34,060] {logging_mixin.py:109} INFO - [2022-04-28 02:03:34,054] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:03:34,083] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:03:34,098] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.519 seconds
[2022-04-28 02:04:04,728] {processor.py:163} INFO - Started process (PID=1163) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:04:04,731] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:04:04,733] {logging_mixin.py:109} INFO - [2022-04-28 02:04:04,733] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:04:05,147] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:04:05,151] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:04:05,154] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:04:05,160] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:04:05,167] {logging_mixin.py:109} INFO - [2022-04-28 02:04:05,161] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:04:05,188] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:04:05,203] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.484 seconds
[2022-04-28 02:04:35,940] {processor.py:163} INFO - Started process (PID=1192) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:04:35,952] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:04:35,958] {logging_mixin.py:109} INFO - [2022-04-28 02:04:35,958] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:04:36,588] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:04:36,594] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:04:36,598] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:04:36,606] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:04:36,616] {logging_mixin.py:109} INFO - [2022-04-28 02:04:36,608] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:04:36,639] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:04:36,655] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.736 seconds
[2022-04-28 02:05:06,983] {processor.py:163} INFO - Started process (PID=1218) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:05:06,991] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:05:06,995] {logging_mixin.py:109} INFO - [2022-04-28 02:05:06,995] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:05:07,660] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:05:07,672] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:05:07,681] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:05:07,692] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:05:07,703] {logging_mixin.py:109} INFO - [2022-04-28 02:05:07,695] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:05:07,737] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:05:07,752] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.819 seconds
[2022-04-28 02:05:37,979] {processor.py:163} INFO - Started process (PID=1244) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:05:37,989] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:05:38,003] {logging_mixin.py:109} INFO - [2022-04-28 02:05:38,003] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:05:38,730] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:05:38,758] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:05:38,771] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:05:38,793] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:05:38,801] {logging_mixin.py:109} INFO - [2022-04-28 02:05:38,796] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:05:38,860] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:05:38,903] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.946 seconds
[2022-04-28 02:06:09,375] {processor.py:163} INFO - Started process (PID=1268) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:06:09,390] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:06:09,398] {logging_mixin.py:109} INFO - [2022-04-28 02:06:09,396] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:06:11,229] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:06:11,252] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:06:11,264] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:06:11,284] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:06:11,302] {logging_mixin.py:109} INFO - [2022-04-28 02:06:11,289] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:06:11,354] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:06:11,388] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.040 seconds
[2022-04-28 02:06:41,995] {processor.py:163} INFO - Started process (PID=1294) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:06:42,004] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:06:42,012] {logging_mixin.py:109} INFO - [2022-04-28 02:06:42,009] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:06:43,619] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:06:43,624] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:06:43,628] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:06:43,634] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:06:43,643] {logging_mixin.py:109} INFO - [2022-04-28 02:06:43,636] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:06:43,673] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:06:43,692] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.716 seconds
[2022-04-28 02:07:13,885] {processor.py:163} INFO - Started process (PID=1320) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:07:13,896] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:07:13,899] {logging_mixin.py:109} INFO - [2022-04-28 02:07:13,899] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:07:14,752] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:07:14,766] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:07:14,789] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:07:14,795] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:07:14,803] {logging_mixin.py:109} INFO - [2022-04-28 02:07:14,796] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:07:14,825] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:07:14,840] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.960 seconds
[2022-04-28 02:07:44,936] {processor.py:163} INFO - Started process (PID=1347) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:07:44,945] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:07:44,947] {logging_mixin.py:109} INFO - [2022-04-28 02:07:44,947] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:07:45,569] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:07:45,572] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:07:45,574] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:07:45,578] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:07:45,584] {logging_mixin.py:109} INFO - [2022-04-28 02:07:45,580] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:07:45,599] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:07:45,611] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.689 seconds
[2022-04-28 02:08:16,033] {processor.py:163} INFO - Started process (PID=1374) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:08:16,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:08:16,039] {logging_mixin.py:109} INFO - [2022-04-28 02:08:16,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:08:18,360] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:08:18,367] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:08:18,373] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:08:18,386] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:08:18,402] {logging_mixin.py:109} INFO - [2022-04-28 02:08:18,390] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:08:18,433] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:08:18,449] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.431 seconds
[2022-04-28 02:08:48,899] {processor.py:163} INFO - Started process (PID=1401) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:08:48,902] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:08:48,904] {logging_mixin.py:109} INFO - [2022-04-28 02:08:48,904] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:08:49,302] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:08:49,307] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:08:49,312] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:08:49,317] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:08:49,323] {logging_mixin.py:109} INFO - [2022-04-28 02:08:49,318] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:08:49,341] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:08:49,351] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.458 seconds
[2022-04-28 02:09:19,709] {processor.py:163} INFO - Started process (PID=1427) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:09:19,714] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:09:19,717] {logging_mixin.py:109} INFO - [2022-04-28 02:09:19,716] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:09:20,166] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:09:20,171] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:09:20,175] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:09:20,182] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:09:20,189] {logging_mixin.py:109} INFO - [2022-04-28 02:09:20,184] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:09:20,209] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:09:20,223] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.522 seconds
[2022-04-28 02:09:50,573] {processor.py:163} INFO - Started process (PID=1454) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:09:50,582] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:09:50,586] {logging_mixin.py:109} INFO - [2022-04-28 02:09:50,586] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:09:52,705] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:09:52,720] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:09:52,739] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:09:52,759] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:09:52,777] {logging_mixin.py:109} INFO - [2022-04-28 02:09:52,770] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:09:52,858] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:09:52,922] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.367 seconds
[2022-04-28 02:10:23,486] {processor.py:163} INFO - Started process (PID=1479) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:10:23,494] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:10:23,497] {logging_mixin.py:109} INFO - [2022-04-28 02:10:23,497] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:10:24,283] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:10:24,289] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:10:24,294] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:10:24,301] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:10:24,311] {logging_mixin.py:109} INFO - [2022-04-28 02:10:24,303] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:10:24,401] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:10:24,439] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.959 seconds
[2022-04-28 02:10:54,554] {processor.py:163} INFO - Started process (PID=1508) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:10:54,557] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:10:54,559] {logging_mixin.py:109} INFO - [2022-04-28 02:10:54,559] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:10:55,049] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:10:55,067] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:10:55,072] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:10:55,078] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:10:55,084] {logging_mixin.py:109} INFO - [2022-04-28 02:10:55,080] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:10:55,113] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:10:55,125] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.578 seconds
[2022-04-28 02:11:25,583] {processor.py:163} INFO - Started process (PID=1546) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:11:25,590] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:11:25,600] {logging_mixin.py:109} INFO - [2022-04-28 02:11:25,598] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:11:30,069] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:11:30,085] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:11:30,104] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:11:30,139] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:11:30,161] {logging_mixin.py:109} INFO - [2022-04-28 02:11:30,141] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:11:30,243] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:11:30,283] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.731 seconds
[2022-04-28 02:12:00,773] {processor.py:163} INFO - Started process (PID=1571) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:12:00,782] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:12:00,792] {logging_mixin.py:109} INFO - [2022-04-28 02:12:00,792] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:12:01,728] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:12:01,731] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:12:01,734] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:12:01,737] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:12:01,742] {logging_mixin.py:109} INFO - [2022-04-28 02:12:01,739] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:12:01,760] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:12:01,776] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.015 seconds
[2022-04-28 02:12:31,997] {processor.py:163} INFO - Started process (PID=1599) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:12:32,001] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:12:32,004] {logging_mixin.py:109} INFO - [2022-04-28 02:12:32,004] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:12:32,542] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:12:32,545] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:12:32,547] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:12:32,551] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:12:32,557] {logging_mixin.py:109} INFO - [2022-04-28 02:12:32,553] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:12:32,573] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:12:32,582] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.595 seconds
[2022-04-28 02:13:03,108] {processor.py:163} INFO - Started process (PID=1629) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:13:03,118] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:13:03,124] {logging_mixin.py:109} INFO - [2022-04-28 02:13:03,123] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:13:03,790] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:13:03,796] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:13:03,801] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:13:03,808] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:13:03,816] {logging_mixin.py:109} INFO - [2022-04-28 02:13:03,810] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:13:03,840] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:13:03,857] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.757 seconds
[2022-04-28 02:13:34,497] {processor.py:163} INFO - Started process (PID=1656) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:13:34,502] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:13:34,504] {logging_mixin.py:109} INFO - [2022-04-28 02:13:34,504] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:13:35,149] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:13:35,157] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:13:35,162] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:13:35,167] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:13:35,188] {logging_mixin.py:109} INFO - [2022-04-28 02:13:35,168] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:13:35,211] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:13:35,224] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.734 seconds
[2022-04-28 02:14:05,612] {processor.py:163} INFO - Started process (PID=1692) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:14:05,616] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:14:05,618] {logging_mixin.py:109} INFO - [2022-04-28 02:14:05,618] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:14:06,101] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:14:06,107] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:14:06,112] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:14:06,118] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:14:06,125] {logging_mixin.py:109} INFO - [2022-04-28 02:14:06,120] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:14:06,146] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:14:06,160] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.552 seconds
[2022-04-28 02:14:36,464] {processor.py:163} INFO - Started process (PID=1722) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:14:36,467] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:14:36,469] {logging_mixin.py:109} INFO - [2022-04-28 02:14:36,469] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:14:36,918] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:14:36,927] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:14:36,935] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:14:36,941] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:14:36,952] {logging_mixin.py:109} INFO - [2022-04-28 02:14:36,944] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:14:36,987] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:14:37,015] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.579 seconds
[2022-04-28 02:15:07,221] {processor.py:163} INFO - Started process (PID=1752) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:15:07,225] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:15:07,227] {logging_mixin.py:109} INFO - [2022-04-28 02:15:07,227] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:15:07,617] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:15:07,622] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:15:07,625] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:15:07,630] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:15:07,637] {logging_mixin.py:109} INFO - [2022-04-28 02:15:07,632] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:15:07,660] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:15:07,675] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.461 seconds
[2022-04-28 02:15:38,170] {processor.py:163} INFO - Started process (PID=1779) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:15:38,182] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:15:38,188] {logging_mixin.py:109} INFO - [2022-04-28 02:15:38,186] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:15:42,479] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:15:42,520] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:15:42,528] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:15:42,571] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:15:42,608] {logging_mixin.py:109} INFO - [2022-04-28 02:15:42,590] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:15:42,777] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:15:42,810] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.663 seconds
[2022-04-28 02:16:13,126] {processor.py:163} INFO - Started process (PID=1806) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:16:13,140] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:16:13,143] {logging_mixin.py:109} INFO - [2022-04-28 02:16:13,142] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:16:15,650] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:16:15,658] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:16:15,662] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:16:15,677] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:16:15,683] {logging_mixin.py:109} INFO - [2022-04-28 02:16:15,679] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:16:15,720] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:16:15,742] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.632 seconds
[2022-04-28 02:16:46,201] {processor.py:163} INFO - Started process (PID=1839) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:16:46,205] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:16:46,218] {logging_mixin.py:109} INFO - [2022-04-28 02:16:46,217] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:16:46,999] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:16:47,008] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:16:47,014] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:16:47,030] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:16:47,055] {logging_mixin.py:109} INFO - [2022-04-28 02:16:47,033] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:16:47,082] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:16:47,102] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.924 seconds
[2022-04-28 02:17:17,301] {processor.py:163} INFO - Started process (PID=1866) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:17:17,305] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:17:17,307] {logging_mixin.py:109} INFO - [2022-04-28 02:17:17,307] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:17:17,640] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:17:17,643] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:17:17,646] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:17:17,649] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:17:17,654] {logging_mixin.py:109} INFO - [2022-04-28 02:17:17,650] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:17:17,673] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:17:17,684] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.388 seconds
[2022-04-28 02:17:48,020] {processor.py:163} INFO - Started process (PID=1892) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:17:48,025] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:17:48,029] {logging_mixin.py:109} INFO - [2022-04-28 02:17:48,028] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:17:48,362] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:17:48,368] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:17:48,372] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:17:48,379] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:17:48,385] {logging_mixin.py:109} INFO - [2022-04-28 02:17:48,381] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:17:48,409] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:17:48,424] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.415 seconds
[2022-04-28 02:18:18,670] {processor.py:163} INFO - Started process (PID=1920) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:18:18,677] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:18:18,680] {logging_mixin.py:109} INFO - [2022-04-28 02:18:18,679] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:18:19,153] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:18:19,168] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:18:19,173] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:18:19,182] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:18:19,199] {logging_mixin.py:109} INFO - [2022-04-28 02:18:19,188] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:18:19,248] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:18:19,272] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.610 seconds
[2022-04-28 02:18:49,895] {processor.py:163} INFO - Started process (PID=1946) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:18:49,899] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:18:49,901] {logging_mixin.py:109} INFO - [2022-04-28 02:18:49,901] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:18:50,185] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:18:50,189] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:18:50,191] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:18:50,194] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:18:50,199] {logging_mixin.py:109} INFO - [2022-04-28 02:18:50,196] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:18:50,219] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:18:50,232] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.343 seconds
[2022-04-28 02:19:20,805] {processor.py:163} INFO - Started process (PID=1972) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:19:20,813] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:19:20,817] {logging_mixin.py:109} INFO - [2022-04-28 02:19:20,816] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:19:21,345] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:19:21,351] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:19:21,355] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:19:21,362] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:19:21,372] {logging_mixin.py:109} INFO - [2022-04-28 02:19:21,364] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:19:21,398] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:19:21,409] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.615 seconds
[2022-04-28 02:19:51,775] {processor.py:163} INFO - Started process (PID=2007) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:19:51,800] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:19:51,809] {logging_mixin.py:109} INFO - [2022-04-28 02:19:51,807] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:19:52,592] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:19:52,596] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:19:52,599] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:19:52,604] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:19:52,618] {logging_mixin.py:109} INFO - [2022-04-28 02:19:52,612] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:19:52,651] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:19:52,668] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.919 seconds
[2022-04-28 02:20:23,028] {processor.py:163} INFO - Started process (PID=2036) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:20:23,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:20:23,059] {logging_mixin.py:109} INFO - [2022-04-28 02:20:23,058] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:20:23,536] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:20:23,543] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:20:23,547] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:20:23,552] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:20:23,560] {logging_mixin.py:109} INFO - [2022-04-28 02:20:23,553] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:20:23,598] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:20:23,612] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.613 seconds
[2022-04-28 02:20:54,325] {processor.py:163} INFO - Started process (PID=2063) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:20:54,343] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:20:54,351] {logging_mixin.py:109} INFO - [2022-04-28 02:20:54,350] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:20:55,141] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:20:55,147] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:20:55,152] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:20:55,160] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:20:55,174] {logging_mixin.py:109} INFO - [2022-04-28 02:20:55,165] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:20:55,234] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:20:55,259] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.952 seconds
[2022-04-28 02:21:25,465] {processor.py:163} INFO - Started process (PID=2094) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:21:25,468] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:21:25,482] {logging_mixin.py:109} INFO - [2022-04-28 02:21:25,482] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:21:26,323] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:21:26,329] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:21:26,333] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:21:26,339] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:21:26,347] {logging_mixin.py:109} INFO - [2022-04-28 02:21:26,342] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:21:26,371] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:21:26,388] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.934 seconds
[2022-04-28 02:21:56,842] {processor.py:163} INFO - Started process (PID=2121) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:21:56,853] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:21:56,855] {logging_mixin.py:109} INFO - [2022-04-28 02:21:56,855] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:21:57,620] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:21:57,630] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:21:57,634] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:21:57,641] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:21:57,655] {logging_mixin.py:109} INFO - [2022-04-28 02:21:57,649] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:21:57,699] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:21:57,723] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.887 seconds
[2022-04-28 02:22:28,726] {processor.py:163} INFO - Started process (PID=2148) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:22:28,729] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:22:28,730] {logging_mixin.py:109} INFO - [2022-04-28 02:22:28,730] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:22:29,665] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:22:29,669] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:22:29,677] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:22:29,683] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:22:29,692] {logging_mixin.py:109} INFO - [2022-04-28 02:22:29,686] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:22:29,735] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:22:29,753] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.031 seconds
[2022-04-28 02:23:00,015] {processor.py:163} INFO - Started process (PID=2184) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:23:00,019] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:23:00,021] {logging_mixin.py:109} INFO - [2022-04-28 02:23:00,021] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:23:00,363] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:23:00,367] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:23:00,370] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:23:00,376] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:23:00,384] {logging_mixin.py:109} INFO - [2022-04-28 02:23:00,378] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:23:00,408] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:23:00,427] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.415 seconds
[2022-04-28 02:23:30,527] {processor.py:163} INFO - Started process (PID=2213) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:23:30,532] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:23:30,534] {logging_mixin.py:109} INFO - [2022-04-28 02:23:30,533] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:23:30,908] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:23:30,917] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:23:30,922] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:23:30,929] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:23:30,940] {logging_mixin.py:109} INFO - [2022-04-28 02:23:30,932] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:23:30,985] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:23:31,001] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.489 seconds
[2022-04-28 02:24:02,058] {processor.py:163} INFO - Started process (PID=2240) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:24:02,065] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:24:02,073] {logging_mixin.py:109} INFO - [2022-04-28 02:24:02,072] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:24:02,721] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:24:02,727] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:24:02,731] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:24:02,737] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:24:02,745] {logging_mixin.py:109} INFO - [2022-04-28 02:24:02,739] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:24:02,772] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:24:02,791] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.750 seconds
[2022-04-28 02:24:33,218] {processor.py:163} INFO - Started process (PID=2266) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:24:33,221] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:24:33,224] {logging_mixin.py:109} INFO - [2022-04-28 02:24:33,224] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:24:33,536] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:24:33,540] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:24:33,544] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:24:33,551] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:24:33,557] {logging_mixin.py:109} INFO - [2022-04-28 02:24:33,552] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:24:33,586] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:24:33,612] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.422 seconds
[2022-04-28 02:25:04,374] {processor.py:163} INFO - Started process (PID=2291) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:25:04,376] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:25:04,379] {logging_mixin.py:109} INFO - [2022-04-28 02:25:04,379] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:25:04,795] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:25:04,800] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:25:04,815] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:25:04,838] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:25:04,848] {logging_mixin.py:109} INFO - [2022-04-28 02:25:04,840] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:25:04,885] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:25:04,903] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.536 seconds
[2022-04-28 02:25:35,504] {processor.py:163} INFO - Started process (PID=2319) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:25:35,517] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:25:35,521] {logging_mixin.py:109} INFO - [2022-04-28 02:25:35,520] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:25:35,978] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:25:35,984] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:25:35,989] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:25:35,996] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:25:36,005] {logging_mixin.py:109} INFO - [2022-04-28 02:25:35,998] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:25:36,031] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:25:36,048] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.550 seconds
[2022-04-28 02:26:06,634] {processor.py:163} INFO - Started process (PID=2346) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:26:06,644] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:26:06,653] {logging_mixin.py:109} INFO - [2022-04-28 02:26:06,652] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:26:09,013] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:26:09,039] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:26:09,048] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:26:09,064] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:26:09,078] {logging_mixin.py:109} INFO - [2022-04-28 02:26:09,068] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:26:09,114] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:26:09,132] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.537 seconds
[2022-04-28 02:26:39,294] {processor.py:163} INFO - Started process (PID=2373) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:26:39,311] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:26:39,314] {logging_mixin.py:109} INFO - [2022-04-28 02:26:39,314] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:26:42,117] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:26:42,132] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:26:42,142] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:26:42,146] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:26:42,166] {logging_mixin.py:109} INFO - [2022-04-28 02:26:42,148] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:26:42,224] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:26:42,240] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.997 seconds
[2022-04-28 02:27:12,703] {processor.py:163} INFO - Started process (PID=2400) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:27:12,708] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:27:12,711] {logging_mixin.py:109} INFO - [2022-04-28 02:27:12,710] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:27:13,547] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:27:13,557] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:27:13,565] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:27:13,576] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:27:13,590] {logging_mixin.py:109} INFO - [2022-04-28 02:27:13,578] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:27:13,624] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:27:13,662] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.966 seconds
[2022-04-28 02:27:43,997] {processor.py:163} INFO - Started process (PID=2424) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:27:44,019] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:27:44,023] {logging_mixin.py:109} INFO - [2022-04-28 02:27:44,023] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:27:47,579] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:27:47,594] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:27:47,611] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:27:47,632] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:27:47,671] {logging_mixin.py:109} INFO - [2022-04-28 02:27:47,636] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:27:47,843] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:27:47,934] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.966 seconds
[2022-04-28 02:28:18,227] {processor.py:163} INFO - Started process (PID=2450) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:28:18,271] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:28:18,285] {logging_mixin.py:109} INFO - [2022-04-28 02:28:18,284] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:28:19,851] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:28:19,865] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:28:19,901] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:28:19,911] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:28:19,948] {logging_mixin.py:109} INFO - [2022-04-28 02:28:19,921] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:28:20,015] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:28:20,040] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.840 seconds
[2022-04-28 02:28:50,119] {processor.py:163} INFO - Started process (PID=2477) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:28:50,136] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:28:50,139] {logging_mixin.py:109} INFO - [2022-04-28 02:28:50,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:28:50,569] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:28:50,573] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:28:50,575] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:28:50,579] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:28:50,586] {logging_mixin.py:109} INFO - [2022-04-28 02:28:50,581] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:28:50,622] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:28:50,650] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.540 seconds
[2022-04-28 02:29:20,811] {processor.py:163} INFO - Started process (PID=2504) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:29:20,854] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:29:20,868] {logging_mixin.py:109} INFO - [2022-04-28 02:29:20,867] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:29:22,535] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:29:22,541] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:29:22,548] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:29:22,558] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:29:22,570] {logging_mixin.py:109} INFO - [2022-04-28 02:29:22,560] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:29:22,624] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:29:22,659] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.888 seconds
[2022-04-28 02:29:53,175] {processor.py:163} INFO - Started process (PID=2530) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:29:53,179] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:29:53,183] {logging_mixin.py:109} INFO - [2022-04-28 02:29:53,182] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:29:53,899] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:29:53,908] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:29:53,914] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:29:53,922] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:29:53,933] {logging_mixin.py:109} INFO - [2022-04-28 02:29:53,926] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:29:53,963] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:29:53,981] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.813 seconds
[2022-04-28 02:30:24,604] {processor.py:163} INFO - Started process (PID=2559) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:30:24,607] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:30:24,609] {logging_mixin.py:109} INFO - [2022-04-28 02:30:24,609] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:30:24,938] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:30:24,941] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:30:24,944] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:30:24,947] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:30:24,951] {logging_mixin.py:109} INFO - [2022-04-28 02:30:24,948] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:30:24,974] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:30:24,991] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.393 seconds
[2022-04-28 02:30:55,123] {processor.py:163} INFO - Started process (PID=2586) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:30:55,141] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:30:55,144] {logging_mixin.py:109} INFO - [2022-04-28 02:30:55,144] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:30:55,663] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:30:55,666] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:30:55,669] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:30:55,672] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:30:55,678] {logging_mixin.py:109} INFO - [2022-04-28 02:30:55,674] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:30:55,696] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:30:55,707] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.611 seconds
[2022-04-28 02:31:25,976] {processor.py:163} INFO - Started process (PID=2616) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:31:25,982] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:31:25,990] {logging_mixin.py:109} INFO - [2022-04-28 02:31:25,990] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:31:27,240] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:31:27,245] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:31:27,254] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:31:27,262] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:31:27,273] {logging_mixin.py:109} INFO - [2022-04-28 02:31:27,266] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:31:27,319] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:31:27,342] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.387 seconds
[2022-04-28 02:31:58,098] {processor.py:163} INFO - Started process (PID=2645) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:31:58,108] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:31:58,116] {logging_mixin.py:109} INFO - [2022-04-28 02:31:58,114] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:31:58,594] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:31:58,601] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:31:58,606] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:31:58,611] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:31:58,618] {logging_mixin.py:109} INFO - [2022-04-28 02:31:58,613] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:31:58,642] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:31:58,659] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.573 seconds
[2022-04-28 02:32:29,333] {processor.py:163} INFO - Started process (PID=2673) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:32:29,337] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:32:29,339] {logging_mixin.py:109} INFO - [2022-04-28 02:32:29,338] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:32:29,729] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:32:29,735] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:32:29,740] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:32:29,746] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:32:29,755] {logging_mixin.py:109} INFO - [2022-04-28 02:32:29,749] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:32:29,781] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:32:29,797] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.470 seconds
[2022-04-28 02:32:59,942] {processor.py:163} INFO - Started process (PID=2711) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:32:59,947] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:32:59,950] {logging_mixin.py:109} INFO - [2022-04-28 02:32:59,949] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:33:00,328] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:33:00,333] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:33:00,337] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:33:00,342] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:33:00,348] {logging_mixin.py:109} INFO - [2022-04-28 02:33:00,344] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:33:00,368] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:33:00,380] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.447 seconds
[2022-04-28 02:33:31,111] {processor.py:163} INFO - Started process (PID=2738) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:33:31,133] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:33:31,146] {logging_mixin.py:109} INFO - [2022-04-28 02:33:31,145] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:33:32,352] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:33:32,386] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:33:32,407] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:33:32,433] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:33:32,469] {logging_mixin.py:109} INFO - [2022-04-28 02:33:32,442] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:33:32,514] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:33:32,547] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.479 seconds
[2022-04-28 02:34:03,184] {processor.py:163} INFO - Started process (PID=2766) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:34:03,191] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:34:03,193] {logging_mixin.py:109} INFO - [2022-04-28 02:34:03,193] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:34:03,851] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:34:03,855] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:34:03,857] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:34:03,862] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:34:03,874] {logging_mixin.py:109} INFO - [2022-04-28 02:34:03,864] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:34:03,905] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:34:03,921] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.745 seconds
[2022-04-28 02:34:34,596] {processor.py:163} INFO - Started process (PID=2792) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:34:34,602] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:34:34,605] {logging_mixin.py:109} INFO - [2022-04-28 02:34:34,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:34:35,731] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:34:35,734] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:34:35,737] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:34:35,741] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:34:35,746] {logging_mixin.py:109} INFO - [2022-04-28 02:34:35,743] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:34:35,773] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:34:35,817] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.234 seconds
[2022-04-28 02:35:06,461] {processor.py:163} INFO - Started process (PID=2819) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:35:06,465] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:35:06,467] {logging_mixin.py:109} INFO - [2022-04-28 02:35:06,467] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:35:06,903] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:35:06,908] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:35:06,913] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:35:06,918] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:35:06,925] {logging_mixin.py:109} INFO - [2022-04-28 02:35:06,920] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:35:06,954] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:35:06,965] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.520 seconds
[2022-04-28 02:35:37,201] {processor.py:163} INFO - Started process (PID=2847) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:35:37,204] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:35:37,206] {logging_mixin.py:109} INFO - [2022-04-28 02:35:37,206] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:35:37,503] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:35:37,508] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:35:37,511] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:35:37,517] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:35:37,523] {logging_mixin.py:109} INFO - [2022-04-28 02:35:37,518] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:35:37,547] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:35:37,560] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.368 seconds
[2022-04-28 02:36:07,829] {processor.py:163} INFO - Started process (PID=2875) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:36:07,832] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:36:07,835] {logging_mixin.py:109} INFO - [2022-04-28 02:36:07,835] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:36:08,173] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:36:08,177] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:36:08,181] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:36:08,187] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:36:08,194] {logging_mixin.py:109} INFO - [2022-04-28 02:36:08,188] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:36:08,238] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:36:08,255] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.434 seconds
[2022-04-28 02:36:38,481] {processor.py:163} INFO - Started process (PID=2916) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:36:38,484] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:36:38,486] {logging_mixin.py:109} INFO - [2022-04-28 02:36:38,486] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:36:38,842] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:36:38,849] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:36:38,856] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:36:38,862] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:36:38,870] {logging_mixin.py:109} INFO - [2022-04-28 02:36:38,864] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:36:38,905] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:36:38,921] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.444 seconds
[2022-04-28 02:37:09,970] {processor.py:163} INFO - Started process (PID=2947) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:37:09,976] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:37:09,981] {logging_mixin.py:109} INFO - [2022-04-28 02:37:09,981] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:37:10,900] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:37:10,912] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:37:10,918] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:37:10,936] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:37:10,953] {logging_mixin.py:109} INFO - [2022-04-28 02:37:10,941] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:37:10,996] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:37:11,030] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.075 seconds
[2022-04-28 02:37:41,454] {processor.py:163} INFO - Started process (PID=2974) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:37:41,464] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:37:41,468] {logging_mixin.py:109} INFO - [2022-04-28 02:37:41,467] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:37:42,679] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:37:42,693] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:37:42,704] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:37:42,712] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:37:42,736] {logging_mixin.py:109} INFO - [2022-04-28 02:37:42,715] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:37:42,779] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:37:42,812] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.368 seconds
[2022-04-28 02:38:12,917] {processor.py:163} INFO - Started process (PID=3000) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:38:12,920] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:38:12,924] {logging_mixin.py:109} INFO - [2022-04-28 02:38:12,923] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:38:13,413] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:38:13,417] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:38:13,421] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:38:13,427] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:38:13,434] {logging_mixin.py:109} INFO - [2022-04-28 02:38:13,429] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:38:13,465] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:38:13,483] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.573 seconds
[2022-04-28 02:38:43,605] {processor.py:163} INFO - Started process (PID=3028) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:38:43,608] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:38:43,612] {logging_mixin.py:109} INFO - [2022-04-28 02:38:43,612] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:38:43,985] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:38:43,988] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:38:43,991] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:38:43,994] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:38:43,999] {logging_mixin.py:109} INFO - [2022-04-28 02:38:43,995] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:38:44,022] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:38:44,035] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.440 seconds
[2022-04-28 02:39:14,791] {processor.py:163} INFO - Started process (PID=3056) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:39:14,796] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:39:14,799] {logging_mixin.py:109} INFO - [2022-04-28 02:39:14,798] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:39:15,107] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:39:15,111] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:39:15,113] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:39:15,116] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:39:15,121] {logging_mixin.py:109} INFO - [2022-04-28 02:39:15,118] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:39:15,151] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:39:15,166] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.384 seconds
[2022-04-28 02:39:45,285] {processor.py:163} INFO - Started process (PID=3098) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:39:45,292] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:39:45,297] {logging_mixin.py:109} INFO - [2022-04-28 02:39:45,296] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:39:46,900] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:39:46,919] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:39:46,931] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:39:46,944] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:39:46,962] {logging_mixin.py:109} INFO - [2022-04-28 02:39:46,947] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:39:47,008] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:39:47,034] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.758 seconds
[2022-04-28 02:40:17,401] {processor.py:163} INFO - Started process (PID=3116) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:40:17,405] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:40:17,407] {logging_mixin.py:109} INFO - [2022-04-28 02:40:17,407] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:40:17,728] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:40:17,733] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:40:17,736] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:40:17,741] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:40:17,747] {logging_mixin.py:109} INFO - [2022-04-28 02:40:17,742] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:40:17,768] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:40:17,781] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.386 seconds
[2022-04-28 02:40:48,613] {processor.py:163} INFO - Started process (PID=3152) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:40:48,618] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:40:48,621] {logging_mixin.py:109} INFO - [2022-04-28 02:40:48,620] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:40:48,994] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:40:48,998] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:40:49,002] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:40:49,008] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:40:49,016] {logging_mixin.py:109} INFO - [2022-04-28 02:40:49,009] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:40:49,041] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:40:49,052] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.447 seconds
[2022-04-28 02:41:19,470] {processor.py:163} INFO - Started process (PID=3180) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:41:19,473] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:41:19,475] {logging_mixin.py:109} INFO - [2022-04-28 02:41:19,475] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:41:20,456] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:41:20,466] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:41:20,472] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:41:20,476] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:41:20,481] {logging_mixin.py:109} INFO - [2022-04-28 02:41:20,477] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:41:20,501] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:41:20,512] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.050 seconds
[2022-04-28 02:41:50,789] {processor.py:163} INFO - Started process (PID=3207) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:41:50,793] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:41:50,794] {logging_mixin.py:109} INFO - [2022-04-28 02:41:50,794] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:41:51,156] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:41:51,161] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:41:51,164] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:41:51,170] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:41:51,178] {logging_mixin.py:109} INFO - [2022-04-28 02:41:51,173] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:41:51,204] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:41:51,218] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.438 seconds
[2022-04-28 02:42:21,327] {processor.py:163} INFO - Started process (PID=3236) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:42:21,333] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:42:21,337] {logging_mixin.py:109} INFO - [2022-04-28 02:42:21,337] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:42:21,713] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:42:21,717] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:42:21,719] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:42:21,724] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:42:21,729] {logging_mixin.py:109} INFO - [2022-04-28 02:42:21,725] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:42:21,748] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:42:21,759] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.437 seconds
[2022-04-28 02:42:52,274] {processor.py:163} INFO - Started process (PID=3264) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:42:52,279] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:42:52,282] {logging_mixin.py:109} INFO - [2022-04-28 02:42:52,282] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:42:52,566] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:42:52,571] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:42:52,575] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:42:52,580] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:42:52,587] {logging_mixin.py:109} INFO - [2022-04-28 02:42:52,582] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:42:52,605] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:42:52,616] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.352 seconds
[2022-04-28 02:43:22,954] {processor.py:163} INFO - Started process (PID=3305) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:43:22,958] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:43:22,964] {logging_mixin.py:109} INFO - [2022-04-28 02:43:22,963] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:43:23,879] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:43:23,890] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:43:23,895] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:43:23,906] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:43:23,923] {logging_mixin.py:109} INFO - [2022-04-28 02:43:23,909] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:43:23,971] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:43:24,005] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.077 seconds
[2022-04-28 02:43:54,862] {processor.py:163} INFO - Started process (PID=3322) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:43:54,881] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:43:54,888] {logging_mixin.py:109} INFO - [2022-04-28 02:43:54,888] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:43:55,582] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:43:55,587] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:43:55,591] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:43:55,596] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:43:55,606] {logging_mixin.py:109} INFO - [2022-04-28 02:43:55,598] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:43:55,644] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:43:55,667] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.830 seconds
[2022-04-28 02:44:26,374] {processor.py:163} INFO - Started process (PID=3349) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:44:26,380] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:44:26,382] {logging_mixin.py:109} INFO - [2022-04-28 02:44:26,382] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:44:27,138] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:44:27,147] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:44:27,151] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:44:27,158] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:44:27,166] {logging_mixin.py:109} INFO - [2022-04-28 02:44:27,160] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:44:27,194] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:44:27,210] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.843 seconds
[2022-04-28 02:44:58,006] {processor.py:163} INFO - Started process (PID=3376) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:44:58,019] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:44:58,026] {logging_mixin.py:109} INFO - [2022-04-28 02:44:58,025] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:45:00,568] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:45:00,596] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:45:00,618] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:45:00,628] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:45:00,681] {logging_mixin.py:109} INFO - [2022-04-28 02:45:00,638] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:45:00,808] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:45:00,875] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.886 seconds
[2022-04-28 02:45:31,101] {processor.py:163} INFO - Started process (PID=3401) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:45:31,106] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:45:31,107] {logging_mixin.py:109} INFO - [2022-04-28 02:45:31,107] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:45:31,804] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:45:31,810] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:45:31,821] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:45:31,826] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:45:31,839] {logging_mixin.py:109} INFO - [2022-04-28 02:45:31,835] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:45:31,885] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:45:31,915] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.818 seconds
[2022-04-28 02:46:02,218] {processor.py:163} INFO - Started process (PID=3429) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:46:02,226] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:46:02,230] {logging_mixin.py:109} INFO - [2022-04-28 02:46:02,230] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:46:02,621] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:46:02,624] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:46:02,627] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:46:02,630] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:46:02,636] {logging_mixin.py:109} INFO - [2022-04-28 02:46:02,632] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:46:02,656] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:46:02,666] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.459 seconds
[2022-04-28 02:46:32,914] {processor.py:163} INFO - Started process (PID=3461) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:46:32,929] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:46:32,937] {logging_mixin.py:109} INFO - [2022-04-28 02:46:32,937] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:46:33,332] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:46:33,336] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:46:33,339] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:46:33,343] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:46:33,350] {logging_mixin.py:109} INFO - [2022-04-28 02:46:33,345] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:46:33,369] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:46:33,381] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.477 seconds
[2022-04-28 02:47:03,518] {processor.py:163} INFO - Started process (PID=3484) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:47:03,522] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:47:03,525] {logging_mixin.py:109} INFO - [2022-04-28 02:47:03,524] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:47:04,003] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:47:04,009] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:47:04,014] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:47:04,020] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:47:04,037] {logging_mixin.py:109} INFO - [2022-04-28 02:47:04,023] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:47:04,062] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:47:04,077] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.565 seconds
[2022-04-28 02:47:34,760] {processor.py:163} INFO - Started process (PID=3522) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:47:34,764] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:47:34,766] {logging_mixin.py:109} INFO - [2022-04-28 02:47:34,766] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:47:35,137] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:47:35,152] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:47:35,158] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:47:35,162] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:47:35,168] {logging_mixin.py:109} INFO - [2022-04-28 02:47:35,163] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:47:35,237] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:47:35,263] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.509 seconds
[2022-04-28 02:48:06,140] {processor.py:163} INFO - Started process (PID=3550) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:48:06,161] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:48:06,171] {logging_mixin.py:109} INFO - [2022-04-28 02:48:06,171] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:48:07,461] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:48:07,465] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:48:07,469] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:48:07,473] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:48:07,486] {logging_mixin.py:109} INFO - [2022-04-28 02:48:07,482] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:48:07,519] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:48:07,532] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.425 seconds
[2022-04-28 02:48:37,837] {processor.py:163} INFO - Started process (PID=3592) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:48:37,841] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:48:37,844] {logging_mixin.py:109} INFO - [2022-04-28 02:48:37,844] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:48:38,327] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:48:38,336] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:48:38,342] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:48:38,348] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:48:38,359] {logging_mixin.py:109} INFO - [2022-04-28 02:48:38,350] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:48:38,425] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:48:38,469] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.640 seconds
[2022-04-28 02:49:08,642] {processor.py:163} INFO - Started process (PID=3618) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:49:08,648] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:49:08,651] {logging_mixin.py:109} INFO - [2022-04-28 02:49:08,650] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:49:08,955] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:49:08,959] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:49:08,962] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:49:08,965] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:49:08,971] {logging_mixin.py:109} INFO - [2022-04-28 02:49:08,967] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:49:08,995] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:49:09,007] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.373 seconds
[2022-04-28 02:49:39,323] {processor.py:163} INFO - Started process (PID=3645) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:49:39,328] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:49:39,331] {logging_mixin.py:109} INFO - [2022-04-28 02:49:39,331] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:49:39,613] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:49:39,616] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:49:39,620] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:49:39,624] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:49:39,629] {logging_mixin.py:109} INFO - [2022-04-28 02:49:39,625] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:49:39,652] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:49:39,668] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.354 seconds
[2022-04-28 02:50:09,909] {processor.py:163} INFO - Started process (PID=3671) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:50:09,913] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:50:09,915] {logging_mixin.py:109} INFO - [2022-04-28 02:50:09,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:50:10,232] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:50:10,236] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:50:10,239] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:50:10,243] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:50:10,249] {logging_mixin.py:109} INFO - [2022-04-28 02:50:10,244] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:50:10,272] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:50:10,288] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.385 seconds
[2022-04-28 02:50:40,553] {processor.py:163} INFO - Started process (PID=3698) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:50:40,558] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:50:40,562] {logging_mixin.py:109} INFO - [2022-04-28 02:50:40,561] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:50:40,948] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:50:40,954] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:50:40,958] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:50:40,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:50:40,971] {logging_mixin.py:109} INFO - [2022-04-28 02:50:40,965] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:50:40,992] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:50:41,006] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.464 seconds
[2022-04-28 02:51:11,648] {processor.py:163} INFO - Started process (PID=3726) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:51:11,651] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:51:11,653] {logging_mixin.py:109} INFO - [2022-04-28 02:51:11,653] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:51:11,958] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:51:11,964] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:51:11,967] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:51:11,971] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:51:11,977] {logging_mixin.py:109} INFO - [2022-04-28 02:51:11,972] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:51:12,002] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:51:12,061] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.421 seconds
[2022-04-28 02:51:42,188] {processor.py:163} INFO - Started process (PID=3765) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:51:42,190] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:51:42,192] {logging_mixin.py:109} INFO - [2022-04-28 02:51:42,192] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:51:42,516] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:51:42,528] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:51:42,533] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:51:42,542] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:51:42,552] {logging_mixin.py:109} INFO - [2022-04-28 02:51:42,546] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:51:42,587] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:51:42,607] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.423 seconds
[2022-04-28 02:52:13,341] {processor.py:163} INFO - Started process (PID=3791) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:52:13,344] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:52:13,346] {logging_mixin.py:109} INFO - [2022-04-28 02:52:13,345] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:52:13,625] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:52:13,629] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:52:13,632] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:52:13,636] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:52:13,641] {logging_mixin.py:109} INFO - [2022-04-28 02:52:13,637] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:52:13,659] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:52:13,672] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.340 seconds
[2022-04-28 02:52:43,912] {processor.py:163} INFO - Started process (PID=3831) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:52:43,915] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:52:43,917] {logging_mixin.py:109} INFO - [2022-04-28 02:52:43,917] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:52:44,604] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:52:44,618] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:52:44,627] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:52:44,641] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:52:44,664] {logging_mixin.py:109} INFO - [2022-04-28 02:52:44,644] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:52:44,739] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:52:44,763] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.859 seconds
[2022-04-28 02:53:14,941] {processor.py:163} INFO - Started process (PID=3860) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:53:14,948] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:53:14,951] {logging_mixin.py:109} INFO - [2022-04-28 02:53:14,950] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:53:15,288] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:53:15,291] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:53:15,294] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:53:15,297] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:53:15,302] {logging_mixin.py:109} INFO - [2022-04-28 02:53:15,298] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:53:15,322] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:53:15,333] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.399 seconds
[2022-04-28 02:53:45,462] {processor.py:163} INFO - Started process (PID=3890) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:53:45,465] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:53:45,467] {logging_mixin.py:109} INFO - [2022-04-28 02:53:45,467] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:53:45,770] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:53:45,773] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:53:45,776] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:53:45,780] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:53:45,787] {logging_mixin.py:109} INFO - [2022-04-28 02:53:45,782] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:53:45,829] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:53:45,864] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.408 seconds
[2022-04-28 02:54:16,149] {processor.py:163} INFO - Started process (PID=3917) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:54:16,162] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:54:16,164] {logging_mixin.py:109} INFO - [2022-04-28 02:54:16,164] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:54:16,954] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:54:16,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:54:16,971] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:54:16,985] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:54:17,000] {logging_mixin.py:109} INFO - [2022-04-28 02:54:16,988] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:54:17,063] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:54:17,111] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.976 seconds
[2022-04-28 02:54:47,270] {processor.py:163} INFO - Started process (PID=3951) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:54:47,276] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:54:47,278] {logging_mixin.py:109} INFO - [2022-04-28 02:54:47,278] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:54:47,626] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:54:47,636] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:54:47,645] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:54:47,649] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:54:47,657] {logging_mixin.py:109} INFO - [2022-04-28 02:54:47,650] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:54:47,700] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:54:47,723] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.483 seconds
[2022-04-28 02:55:17,927] {processor.py:163} INFO - Started process (PID=3977) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:55:17,929] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:55:17,930] {logging_mixin.py:109} INFO - [2022-04-28 02:55:17,930] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:55:18,394] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:55:18,404] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:55:18,407] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:55:18,412] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:55:18,418] {logging_mixin.py:109} INFO - [2022-04-28 02:55:18,414] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:55:18,442] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:55:18,458] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.536 seconds
[2022-04-28 02:55:48,603] {processor.py:163} INFO - Started process (PID=4003) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:55:48,606] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:55:48,608] {logging_mixin.py:109} INFO - [2022-04-28 02:55:48,608] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:55:49,190] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:55:49,200] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:55:49,204] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:55:49,213] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:55:49,220] {logging_mixin.py:109} INFO - [2022-04-28 02:55:49,214] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:55:49,293] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:55:49,308] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.709 seconds
[2022-04-28 02:56:20,056] {processor.py:163} INFO - Started process (PID=4039) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:56:20,063] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:56:20,068] {logging_mixin.py:109} INFO - [2022-04-28 02:56:20,067] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:56:20,572] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:56:20,576] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:56:20,580] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:56:20,585] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:56:20,593] {logging_mixin.py:109} INFO - [2022-04-28 02:56:20,587] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:56:20,617] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:56:20,631] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.586 seconds
[2022-04-28 02:56:51,216] {processor.py:163} INFO - Started process (PID=4068) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:56:51,220] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:56:51,222] {logging_mixin.py:109} INFO - [2022-04-28 02:56:51,222] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:56:51,530] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:56:51,533] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:56:51,536] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:56:51,540] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:56:51,545] {logging_mixin.py:109} INFO - [2022-04-28 02:56:51,541] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:56:51,563] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:56:51,574] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.368 seconds
[2022-04-28 02:57:21,800] {processor.py:163} INFO - Started process (PID=4095) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:57:21,807] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:57:21,811] {logging_mixin.py:109} INFO - [2022-04-28 02:57:21,810] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:57:22,207] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:57:22,215] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:57:22,223] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:57:22,232] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:57:22,244] {logging_mixin.py:109} INFO - [2022-04-28 02:57:22,237] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:57:22,269] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:57:22,292] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.503 seconds
[2022-04-28 02:57:52,902] {processor.py:163} INFO - Started process (PID=4136) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:57:52,908] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:57:52,915] {logging_mixin.py:109} INFO - [2022-04-28 02:57:52,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:57:53,616] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:57:53,625] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:57:53,634] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:57:53,647] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:57:53,658] {logging_mixin.py:109} INFO - [2022-04-28 02:57:53,649] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:57:53,698] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:57:53,717] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.836 seconds
[2022-04-28 02:58:24,364] {processor.py:163} INFO - Started process (PID=4162) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:58:24,370] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:58:24,373] {logging_mixin.py:109} INFO - [2022-04-28 02:58:24,372] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:58:24,735] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:58:24,741] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:58:24,747] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:58:24,751] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:58:24,762] {logging_mixin.py:109} INFO - [2022-04-28 02:58:24,754] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:58:24,788] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:58:24,804] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.448 seconds
[2022-04-28 02:58:55,023] {processor.py:163} INFO - Started process (PID=4190) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:58:55,028] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:58:55,032] {logging_mixin.py:109} INFO - [2022-04-28 02:58:55,032] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:58:55,571] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:58:55,580] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:58:55,588] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:58:55,598] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:58:55,611] {logging_mixin.py:109} INFO - [2022-04-28 02:58:55,601] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:58:55,646] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:58:55,665] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.647 seconds
[2022-04-28 02:59:26,425] {processor.py:163} INFO - Started process (PID=4218) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:59:26,428] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:59:26,431] {logging_mixin.py:109} INFO - [2022-04-28 02:59:26,431] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:59:26,881] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:59:26,885] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:59:26,888] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:59:26,892] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:59:26,898] {logging_mixin.py:109} INFO - [2022-04-28 02:59:26,893] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:59:26,924] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:59:26,937] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.521 seconds
[2022-04-28 02:59:57,706] {processor.py:163} INFO - Started process (PID=4257) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:59:57,712] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 02:59:57,714] {logging_mixin.py:109} INFO - [2022-04-28 02:59:57,714] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:59:58,110] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 02:59:58,118] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 02:59:58,123] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 02:59:58,130] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 02:59:58,141] {logging_mixin.py:109} INFO - [2022-04-28 02:59:58,133] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 02:59:58,179] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 02:59:58,199] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.501 seconds
[2022-04-28 03:00:29,174] {processor.py:163} INFO - Started process (PID=4283) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:00:29,183] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:00:29,191] {logging_mixin.py:109} INFO - [2022-04-28 03:00:29,189] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:00:30,069] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:00:30,076] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:00:30,081] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:00:30,087] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:00:30,095] {logging_mixin.py:109} INFO - [2022-04-28 03:00:30,089] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:00:30,125] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:00:30,143] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.981 seconds
[2022-04-28 03:01:00,560] {processor.py:163} INFO - Started process (PID=4309) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:01:00,576] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:01:00,579] {logging_mixin.py:109} INFO - [2022-04-28 03:01:00,579] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:01:03,007] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:01:03,024] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:01:03,027] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:01:03,032] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:01:03,045] {logging_mixin.py:109} INFO - [2022-04-28 03:01:03,038] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:01:03,092] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:01:03,119] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.582 seconds
[2022-04-28 03:01:33,589] {processor.py:163} INFO - Started process (PID=4335) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:01:33,599] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:01:33,606] {logging_mixin.py:109} INFO - [2022-04-28 03:01:33,606] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:01:34,073] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:01:34,078] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:01:34,083] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:01:34,090] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:01:34,098] {logging_mixin.py:109} INFO - [2022-04-28 03:01:34,092] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:01:34,124] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:01:34,139] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.555 seconds
[2022-04-28 03:02:04,934] {processor.py:163} INFO - Started process (PID=4362) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:02:04,938] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:02:04,940] {logging_mixin.py:109} INFO - [2022-04-28 03:02:04,940] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:02:05,225] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:02:05,231] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:02:05,235] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:02:05,240] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:02:05,247] {logging_mixin.py:109} INFO - [2022-04-28 03:02:05,242] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:02:05,271] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:02:05,286] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.378 seconds
[2022-04-28 03:02:35,451] {processor.py:163} INFO - Started process (PID=4392) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:02:35,455] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:02:35,457] {logging_mixin.py:109} INFO - [2022-04-28 03:02:35,457] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:02:35,753] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:02:35,757] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:02:35,759] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:02:35,763] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:02:35,768] {logging_mixin.py:109} INFO - [2022-04-28 03:02:35,764] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:02:35,786] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:02:35,797] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.357 seconds
[2022-04-28 03:03:06,571] {processor.py:163} INFO - Started process (PID=4420) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:03:06,576] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:03:06,579] {logging_mixin.py:109} INFO - [2022-04-28 03:03:06,578] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:03:07,025] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:03:07,033] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:03:07,040] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:03:07,050] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:03:07,067] {logging_mixin.py:109} INFO - [2022-04-28 03:03:07,053] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:03:07,152] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:03:07,203] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.641 seconds
[2022-04-28 03:03:38,047] {processor.py:163} INFO - Started process (PID=4447) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:03:38,049] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:03:38,053] {logging_mixin.py:109} INFO - [2022-04-28 03:03:38,053] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:03:38,431] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:03:38,435] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:03:38,438] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:03:38,447] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:03:38,463] {logging_mixin.py:109} INFO - [2022-04-28 03:03:38,455] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:03:38,501] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:03:38,544] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.506 seconds
[2022-04-28 03:04:08,845] {processor.py:163} INFO - Started process (PID=4489) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:04:08,853] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:04:08,858] {logging_mixin.py:109} INFO - [2022-04-28 03:04:08,858] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:04:09,517] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:04:09,523] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:04:09,527] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:04:09,540] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:04:09,550] {logging_mixin.py:109} INFO - [2022-04-28 03:04:09,542] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:04:09,595] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:04:09,616] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.785 seconds
[2022-04-28 03:04:39,872] {processor.py:163} INFO - Started process (PID=4515) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:04:39,875] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:04:39,877] {logging_mixin.py:109} INFO - [2022-04-28 03:04:39,876] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:04:40,243] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:04:40,248] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:04:40,252] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:04:40,257] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:04:40,266] {logging_mixin.py:109} INFO - [2022-04-28 03:04:40,260] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:04:40,290] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:04:40,303] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.441 seconds
[2022-04-28 03:05:10,824] {processor.py:163} INFO - Started process (PID=4543) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:05:10,827] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:05:10,828] {logging_mixin.py:109} INFO - [2022-04-28 03:05:10,828] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:05:11,186] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:05:11,190] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:05:11,193] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:05:11,197] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:05:11,202] {logging_mixin.py:109} INFO - [2022-04-28 03:05:11,199] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:05:11,227] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:05:11,245] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.428 seconds
[2022-04-28 03:05:41,593] {processor.py:163} INFO - Started process (PID=4570) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:05:41,597] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:05:41,600] {logging_mixin.py:109} INFO - [2022-04-28 03:05:41,599] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:05:42,231] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:05:42,238] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:05:42,243] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:05:42,252] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:05:42,267] {logging_mixin.py:109} INFO - [2022-04-28 03:05:42,254] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:05:42,290] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:05:42,310] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.725 seconds
[2022-04-28 03:06:12,618] {processor.py:163} INFO - Started process (PID=4597) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:06:12,622] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:06:12,624] {logging_mixin.py:109} INFO - [2022-04-28 03:06:12,624] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:06:13,213] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:06:13,219] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:06:13,223] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:06:13,229] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:06:13,238] {logging_mixin.py:109} INFO - [2022-04-28 03:06:13,232] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:06:13,274] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:06:13,293] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.681 seconds
[2022-04-28 03:06:43,959] {processor.py:163} INFO - Started process (PID=4623) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:06:43,962] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:06:43,964] {logging_mixin.py:109} INFO - [2022-04-28 03:06:43,964] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:06:44,266] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:06:44,272] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:06:44,276] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:06:44,281] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:06:44,286] {logging_mixin.py:109} INFO - [2022-04-28 03:06:44,283] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:06:44,304] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:06:44,316] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.363 seconds
[2022-04-28 03:07:14,522] {processor.py:163} INFO - Started process (PID=4649) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:07:14,526] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:07:14,528] {logging_mixin.py:109} INFO - [2022-04-28 03:07:14,528] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:07:14,815] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:07:14,820] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:07:14,824] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:07:14,829] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:07:14,834] {logging_mixin.py:109} INFO - [2022-04-28 03:07:14,831] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:07:14,852] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:07:14,863] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.347 seconds
[2022-04-28 03:07:44,917] {processor.py:163} INFO - Started process (PID=4678) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:07:44,923] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:07:44,925] {logging_mixin.py:109} INFO - [2022-04-28 03:07:44,925] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:07:45,270] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:07:45,276] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:07:45,280] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:07:45,286] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:07:45,294] {logging_mixin.py:109} INFO - [2022-04-28 03:07:45,288] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:07:45,324] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:07:45,339] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.431 seconds
[2022-04-28 03:08:16,243] {processor.py:163} INFO - Started process (PID=4710) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:08:16,252] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:08:16,262] {logging_mixin.py:109} INFO - [2022-04-28 03:08:16,261] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:08:18,698] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:08:18,772] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:08:18,844] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:08:18,862] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:08:18,888] {logging_mixin.py:109} INFO - [2022-04-28 03:08:18,867] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:08:18,950] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:08:18,971] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.761 seconds
[2022-04-28 03:08:49,626] {processor.py:163} INFO - Started process (PID=4738) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:08:49,634] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:08:49,637] {logging_mixin.py:109} INFO - [2022-04-28 03:08:49,636] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:08:50,332] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:08:50,341] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:08:50,344] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:08:50,355] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:08:50,361] {logging_mixin.py:109} INFO - [2022-04-28 03:08:50,356] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:08:50,389] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:08:50,410] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.799 seconds
[2022-04-28 03:09:20,627] {processor.py:163} INFO - Started process (PID=4765) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:09:20,631] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:09:20,634] {logging_mixin.py:109} INFO - [2022-04-28 03:09:20,633] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:09:20,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:09:20,968] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:09:20,973] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:09:20,981] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:09:20,990] {logging_mixin.py:109} INFO - [2022-04-28 03:09:20,984] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:09:21,021] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:09:21,035] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.415 seconds
[2022-04-28 03:09:51,258] {processor.py:163} INFO - Started process (PID=4791) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:09:51,271] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:09:51,283] {logging_mixin.py:109} INFO - [2022-04-28 03:09:51,282] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:09:52,920] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:09:52,932] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:09:52,937] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:09:52,943] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:09:52,964] {logging_mixin.py:109} INFO - [2022-04-28 03:09:52,951] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:09:53,014] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:09:53,039] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.795 seconds
[2022-04-28 03:10:23,497] {processor.py:163} INFO - Started process (PID=4817) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:10:23,500] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:10:23,502] {logging_mixin.py:109} INFO - [2022-04-28 03:10:23,502] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:10:23,859] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:10:23,865] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:10:23,868] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:10:23,874] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:10:23,882] {logging_mixin.py:109} INFO - [2022-04-28 03:10:23,876] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:10:23,905] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:10:23,919] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.428 seconds
[2022-04-28 03:10:54,168] {processor.py:163} INFO - Started process (PID=4844) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:10:54,172] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:10:54,174] {logging_mixin.py:109} INFO - [2022-04-28 03:10:54,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:10:54,470] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:10:54,475] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:10:54,479] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:10:54,485] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:10:54,493] {logging_mixin.py:109} INFO - [2022-04-28 03:10:54,487] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:10:54,515] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:10:54,526] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.363 seconds
[2022-04-28 03:11:24,606] {processor.py:163} INFO - Started process (PID=4872) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:11:24,611] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:11:24,614] {logging_mixin.py:109} INFO - [2022-04-28 03:11:24,613] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:11:24,895] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:11:24,900] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:11:24,903] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:11:24,907] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:11:24,913] {logging_mixin.py:109} INFO - [2022-04-28 03:11:24,908] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:11:24,941] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:11:24,952] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.352 seconds
[2022-04-28 03:11:55,233] {processor.py:163} INFO - Started process (PID=4900) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:11:55,237] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:11:55,239] {logging_mixin.py:109} INFO - [2022-04-28 03:11:55,239] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:11:55,639] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:11:55,645] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:11:55,649] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:11:55,655] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:11:55,664] {logging_mixin.py:109} INFO - [2022-04-28 03:11:55,657] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:11:55,696] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:11:55,712] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.487 seconds
[2022-04-28 03:12:26,599] {processor.py:163} INFO - Started process (PID=4928) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:12:26,602] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:12:26,605] {logging_mixin.py:109} INFO - [2022-04-28 03:12:26,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:12:26,956] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:12:26,959] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:12:26,962] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:12:26,966] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:12:26,972] {logging_mixin.py:109} INFO - [2022-04-28 03:12:26,968] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:12:26,993] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:12:27,005] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.411 seconds
[2022-04-28 03:12:57,083] {processor.py:163} INFO - Started process (PID=4965) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:12:57,090] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:12:57,093] {logging_mixin.py:109} INFO - [2022-04-28 03:12:57,093] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:12:57,685] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:12:57,692] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:12:57,697] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:12:57,703] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:12:57,711] {logging_mixin.py:109} INFO - [2022-04-28 03:12:57,705] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:12:57,738] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:12:57,760] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.687 seconds
[2022-04-28 03:13:27,938] {processor.py:163} INFO - Started process (PID=4989) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:13:27,944] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:13:27,948] {logging_mixin.py:109} INFO - [2022-04-28 03:13:27,948] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:13:28,901] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:13:28,908] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:13:28,913] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:13:28,918] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:13:28,926] {logging_mixin.py:109} INFO - [2022-04-28 03:13:28,921] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:13:28,948] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:13:28,963] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.039 seconds
[2022-04-28 03:14:00,029] {processor.py:163} INFO - Started process (PID=5028) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:14:00,031] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:14:00,036] {logging_mixin.py:109} INFO - [2022-04-28 03:14:00,036] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:14:00,460] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:14:00,465] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:14:00,470] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:14:00,476] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:14:00,484] {logging_mixin.py:109} INFO - [2022-04-28 03:14:00,478] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:14:00,512] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:14:00,543] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.530 seconds
[2022-04-28 03:14:30,729] {processor.py:163} INFO - Started process (PID=5054) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:14:30,732] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:14:30,734] {logging_mixin.py:109} INFO - [2022-04-28 03:14:30,733] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:14:31,167] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:14:31,170] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:14:31,180] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:14:31,184] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:14:31,191] {logging_mixin.py:109} INFO - [2022-04-28 03:14:31,186] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:14:31,212] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:14:31,228] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.508 seconds
[2022-04-28 03:15:01,394] {processor.py:163} INFO - Started process (PID=5082) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:15:01,397] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:15:01,400] {logging_mixin.py:109} INFO - [2022-04-28 03:15:01,399] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:15:01,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:15:01,982] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:15:01,992] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:15:02,002] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:15:02,014] {logging_mixin.py:109} INFO - [2022-04-28 03:15:02,004] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:15:02,081] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:15:02,102] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.715 seconds
[2022-04-28 03:15:32,627] {processor.py:163} INFO - Started process (PID=5119) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:15:32,634] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:15:32,636] {logging_mixin.py:109} INFO - [2022-04-28 03:15:32,636] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:15:33,451] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:15:33,454] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:15:33,458] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:15:33,462] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:15:33,467] {logging_mixin.py:109} INFO - [2022-04-28 03:15:33,464] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:15:33,491] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:15:33,529] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.920 seconds
[2022-04-28 03:16:03,936] {processor.py:163} INFO - Started process (PID=5147) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:16:03,938] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:16:03,940] {logging_mixin.py:109} INFO - [2022-04-28 03:16:03,940] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:16:04,325] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:16:04,342] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:16:04,346] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:16:04,355] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:16:04,363] {logging_mixin.py:109} INFO - [2022-04-28 03:16:04,359] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:16:04,397] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:16:04,419] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.491 seconds
[2022-04-28 03:16:34,497] {processor.py:163} INFO - Started process (PID=5175) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:16:34,499] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:16:34,501] {logging_mixin.py:109} INFO - [2022-04-28 03:16:34,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:16:34,806] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:16:34,811] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:16:34,816] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:16:34,822] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:16:34,828] {logging_mixin.py:109} INFO - [2022-04-28 03:16:34,823] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:16:34,851] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:16:34,864] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.398 seconds
[2022-04-28 03:17:05,778] {processor.py:163} INFO - Started process (PID=5212) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:17:05,781] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:17:05,783] {logging_mixin.py:109} INFO - [2022-04-28 03:17:05,783] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:17:06,274] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:17:06,290] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:17:06,308] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:17:06,322] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:17:06,341] {logging_mixin.py:109} INFO - [2022-04-28 03:17:06,327] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:17:06,397] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:17:06,439] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.670 seconds
[2022-04-28 03:17:37,100] {processor.py:163} INFO - Started process (PID=5240) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:17:37,106] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:17:37,109] {logging_mixin.py:109} INFO - [2022-04-28 03:17:37,108] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:17:37,601] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:17:37,618] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:17:37,624] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:17:37,634] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:17:37,646] {logging_mixin.py:109} INFO - [2022-04-28 03:17:37,637] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:17:37,709] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:17:37,733] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.637 seconds
[2022-04-28 03:18:07,892] {processor.py:163} INFO - Started process (PID=5275) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:18:07,894] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:18:07,896] {logging_mixin.py:109} INFO - [2022-04-28 03:18:07,896] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:18:08,683] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:18:08,692] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:18:08,696] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:18:08,702] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:18:08,709] {logging_mixin.py:109} INFO - [2022-04-28 03:18:08,703] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:18:08,736] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:18:08,759] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.890 seconds
[2022-04-28 03:18:38,942] {processor.py:163} INFO - Started process (PID=5306) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:18:38,944] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:18:38,946] {logging_mixin.py:109} INFO - [2022-04-28 03:18:38,946] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:18:39,296] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:18:39,300] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:18:39,304] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:18:39,308] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:18:39,314] {logging_mixin.py:109} INFO - [2022-04-28 03:18:39,310] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:18:39,340] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:18:39,354] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.422 seconds
[2022-04-28 03:19:10,091] {processor.py:163} INFO - Started process (PID=5332) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:19:10,093] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:19:10,095] {logging_mixin.py:109} INFO - [2022-04-28 03:19:10,095] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:19:10,412] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:19:10,418] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:19:10,422] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:19:10,427] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:19:10,434] {logging_mixin.py:109} INFO - [2022-04-28 03:19:10,429] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:19:10,458] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:19:10,477] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.395 seconds
[2022-04-28 03:19:40,622] {processor.py:163} INFO - Started process (PID=5360) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:19:40,626] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:19:40,633] {logging_mixin.py:109} INFO - [2022-04-28 03:19:40,628] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:19:40,941] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:19:40,945] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:19:40,949] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:19:40,953] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:19:40,960] {logging_mixin.py:109} INFO - [2022-04-28 03:19:40,955] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:19:40,985] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:19:40,998] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.384 seconds
[2022-04-28 03:20:11,381] {processor.py:163} INFO - Started process (PID=5399) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:20:11,387] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:20:11,389] {logging_mixin.py:109} INFO - [2022-04-28 03:20:11,389] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:20:12,165] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:20:12,176] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:20:12,186] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:20:12,204] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:20:12,233] {logging_mixin.py:109} INFO - [2022-04-28 03:20:12,217] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:20:12,289] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:20:12,320] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.953 seconds
[2022-04-28 03:20:43,146] {processor.py:163} INFO - Started process (PID=5427) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:20:43,153] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:20:43,157] {logging_mixin.py:109} INFO - [2022-04-28 03:20:43,156] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:20:43,754] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:20:43,760] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:20:43,766] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:20:43,782] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:20:43,800] {logging_mixin.py:109} INFO - [2022-04-28 03:20:43,786] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:20:43,850] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:20:43,877] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.742 seconds
[2022-04-28 03:21:14,636] {processor.py:163} INFO - Started process (PID=5453) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:21:14,640] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:21:14,642] {logging_mixin.py:109} INFO - [2022-04-28 03:21:14,642] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:21:14,958] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:21:14,962] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:21:14,966] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:21:14,971] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:21:14,980] {logging_mixin.py:109} INFO - [2022-04-28 03:21:14,973] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:21:15,003] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:21:15,018] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.388 seconds
[2022-04-28 03:21:45,461] {processor.py:163} INFO - Started process (PID=5493) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:21:45,466] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:21:45,469] {logging_mixin.py:109} INFO - [2022-04-28 03:21:45,468] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:21:45,752] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:21:45,757] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:21:45,762] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:21:45,768] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:21:45,775] {logging_mixin.py:109} INFO - [2022-04-28 03:21:45,770] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:21:45,799] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:21:45,813] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.363 seconds
[2022-04-28 03:22:16,413] {processor.py:163} INFO - Started process (PID=5522) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:22:16,418] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:22:16,420] {logging_mixin.py:109} INFO - [2022-04-28 03:22:16,420] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:22:16,863] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:22:16,868] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:22:16,873] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:22:16,878] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:22:16,886] {logging_mixin.py:109} INFO - [2022-04-28 03:22:16,881] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:22:16,933] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:22:16,953] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.545 seconds
[2022-04-28 03:22:47,322] {processor.py:163} INFO - Started process (PID=5550) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:22:47,325] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:22:47,328] {logging_mixin.py:109} INFO - [2022-04-28 03:22:47,328] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:22:47,800] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:22:47,807] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:22:47,812] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:22:47,820] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:22:47,844] {logging_mixin.py:109} INFO - [2022-04-28 03:22:47,822] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:22:47,895] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:22:47,917] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.604 seconds
[2022-04-28 03:23:18,113] {processor.py:163} INFO - Started process (PID=5587) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:23:18,124] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:23:18,131] {logging_mixin.py:109} INFO - [2022-04-28 03:23:18,131] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:23:18,484] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:23:18,489] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:23:18,493] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:23:18,499] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:23:18,507] {logging_mixin.py:109} INFO - [2022-04-28 03:23:18,501] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:23:18,531] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:23:18,547] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.447 seconds
[2022-04-28 03:23:48,826] {processor.py:163} INFO - Started process (PID=5611) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:23:48,837] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:23:48,839] {logging_mixin.py:109} INFO - [2022-04-28 03:23:48,839] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:23:50,464] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:23:50,478] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:23:50,495] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:23:50,507] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:23:50,524] {logging_mixin.py:109} INFO - [2022-04-28 03:23:50,518] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:23:50,627] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:23:50,681] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.859 seconds
[2022-04-28 03:24:20,924] {processor.py:163} INFO - Started process (PID=5637) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:24:20,932] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:24:20,936] {logging_mixin.py:109} INFO - [2022-04-28 03:24:20,936] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:24:21,677] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:24:21,682] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:24:21,686] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:24:21,692] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:24:21,703] {logging_mixin.py:109} INFO - [2022-04-28 03:24:21,697] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:24:21,741] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:24:21,758] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.846 seconds
[2022-04-28 03:24:52,217] {processor.py:163} INFO - Started process (PID=5664) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:24:52,221] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:24:52,223] {logging_mixin.py:109} INFO - [2022-04-28 03:24:52,223] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:24:52,507] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:24:52,510] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:24:52,513] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:24:52,516] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:24:52,521] {logging_mixin.py:109} INFO - [2022-04-28 03:24:52,517] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:24:52,539] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:24:52,550] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.342 seconds
[2022-04-28 03:25:22,643] {processor.py:163} INFO - Started process (PID=5691) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:25:22,646] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:25:22,648] {logging_mixin.py:109} INFO - [2022-04-28 03:25:22,648] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:25:22,983] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:25:22,988] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:25:22,992] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:25:22,997] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:25:23,005] {logging_mixin.py:109} INFO - [2022-04-28 03:25:23,000] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:25:23,026] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:25:23,039] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.402 seconds
[2022-04-28 03:25:53,162] {processor.py:163} INFO - Started process (PID=5721) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:25:53,167] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:25:53,170] {logging_mixin.py:109} INFO - [2022-04-28 03:25:53,170] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:25:53,525] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:25:53,528] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:25:53,531] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:25:53,535] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:25:53,541] {logging_mixin.py:109} INFO - [2022-04-28 03:25:53,537] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:25:53,573] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:25:53,594] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.460 seconds
[2022-04-28 03:26:23,738] {processor.py:163} INFO - Started process (PID=5757) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:26:23,743] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:26:23,758] {logging_mixin.py:109} INFO - [2022-04-28 03:26:23,757] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:26:24,184] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:26:24,194] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:26:24,199] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:26:24,209] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:26:24,220] {logging_mixin.py:109} INFO - [2022-04-28 03:26:24,211] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:26:24,252] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:26:24,268] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.549 seconds
[2022-04-28 03:26:54,421] {processor.py:163} INFO - Started process (PID=5785) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:26:54,426] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:26:54,428] {logging_mixin.py:109} INFO - [2022-04-28 03:26:54,428] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:26:54,740] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:26:54,745] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:26:54,754] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:26:54,761] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:26:54,767] {logging_mixin.py:109} INFO - [2022-04-28 03:26:54,763] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:26:54,801] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:26:54,815] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.400 seconds
[2022-04-28 03:27:25,199] {processor.py:163} INFO - Started process (PID=5812) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:27:25,203] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:27:25,208] {logging_mixin.py:109} INFO - [2022-04-28 03:27:25,207] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:27:25,550] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:27:25,553] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:27:25,556] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:27:25,559] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:27:25,563] {logging_mixin.py:109} INFO - [2022-04-28 03:27:25,560] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:27:25,585] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:27:25,627] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.436 seconds
[2022-04-28 03:27:55,926] {processor.py:163} INFO - Started process (PID=5839) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:27:55,937] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:27:55,946] {logging_mixin.py:109} INFO - [2022-04-28 03:27:55,939] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:27:57,275] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:27:57,296] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:27:57,314] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:27:57,338] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:27:57,376] {logging_mixin.py:109} INFO - [2022-04-28 03:27:57,343] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:27:57,469] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:27:57,524] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.603 seconds
[2022-04-28 03:28:27,582] {processor.py:163} INFO - Started process (PID=5876) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:28:27,586] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:28:27,588] {logging_mixin.py:109} INFO - [2022-04-28 03:28:27,587] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:28:27,897] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:28:27,900] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:28:27,903] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:28:27,907] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:28:27,913] {logging_mixin.py:109} INFO - [2022-04-28 03:28:27,909] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:28:27,942] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:28:27,969] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.392 seconds
[2022-04-28 03:28:58,700] {processor.py:163} INFO - Started process (PID=5906) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:28:58,704] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:28:58,706] {logging_mixin.py:109} INFO - [2022-04-28 03:28:58,706] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:28:58,991] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:28:58,994] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:28:58,996] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:28:59,000] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:28:59,005] {logging_mixin.py:109} INFO - [2022-04-28 03:28:59,001] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:28:59,027] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:28:59,061] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.371 seconds
[2022-04-28 03:29:30,020] {processor.py:163} INFO - Started process (PID=5932) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:29:30,023] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:29:30,027] {logging_mixin.py:109} INFO - [2022-04-28 03:29:30,027] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:29:30,457] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:29:30,467] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:29:30,471] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:29:30,479] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:29:30,490] {logging_mixin.py:109} INFO - [2022-04-28 03:29:30,481] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:29:30,523] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:29:30,548] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.536 seconds
[2022-04-28 03:30:01,054] {processor.py:163} INFO - Started process (PID=5968) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:30:01,057] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:30:01,059] {logging_mixin.py:109} INFO - [2022-04-28 03:30:01,058] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:30:01,516] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:30:01,519] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:30:01,524] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:30:01,529] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:30:01,537] {logging_mixin.py:109} INFO - [2022-04-28 03:30:01,532] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:30:01,558] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:30:01,573] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.523 seconds
[2022-04-28 03:30:32,132] {processor.py:163} INFO - Started process (PID=5997) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:30:32,135] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:30:32,140] {logging_mixin.py:109} INFO - [2022-04-28 03:30:32,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:30:32,729] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:30:32,734] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:30:32,737] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:30:32,750] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:30:32,794] {logging_mixin.py:109} INFO - [2022-04-28 03:30:32,755] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:30:32,838] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:30:32,867] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.748 seconds
[2022-04-28 03:31:03,516] {processor.py:163} INFO - Started process (PID=6026) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:31:03,518] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:31:03,520] {logging_mixin.py:109} INFO - [2022-04-28 03:31:03,520] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:31:03,821] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:31:03,825] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:31:03,828] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:31:03,832] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:31:03,837] {logging_mixin.py:109} INFO - [2022-04-28 03:31:03,834] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:31:03,855] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:31:03,866] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.359 seconds
[2022-04-28 03:31:33,982] {processor.py:163} INFO - Started process (PID=6063) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:31:33,985] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:31:33,988] {logging_mixin.py:109} INFO - [2022-04-28 03:31:33,988] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:31:34,372] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:31:34,376] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:31:34,380] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:31:34,384] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:31:34,391] {logging_mixin.py:109} INFO - [2022-04-28 03:31:34,386] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:31:34,414] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:31:34,435] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.482 seconds
[2022-04-28 03:32:05,149] {processor.py:163} INFO - Started process (PID=6093) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:32:05,154] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:32:05,157] {logging_mixin.py:109} INFO - [2022-04-28 03:32:05,157] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:32:05,445] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:32:05,450] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:32:05,453] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:32:05,458] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:32:05,465] {logging_mixin.py:109} INFO - [2022-04-28 03:32:05,459] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:32:05,488] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:32:05,500] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.360 seconds
[2022-04-28 03:32:35,970] {processor.py:163} INFO - Started process (PID=6120) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:32:35,974] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:32:35,977] {logging_mixin.py:109} INFO - [2022-04-28 03:32:35,976] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:32:36,260] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:32:36,264] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:32:36,268] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:32:36,272] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:32:36,281] {logging_mixin.py:109} INFO - [2022-04-28 03:32:36,274] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:32:36,306] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:32:36,321] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.360 seconds
[2022-04-28 03:33:06,491] {processor.py:163} INFO - Started process (PID=6158) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:33:06,499] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:33:06,505] {logging_mixin.py:109} INFO - [2022-04-28 03:33:06,504] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:33:07,304] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:33:07,309] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:33:07,319] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:33:07,330] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:33:07,350] {logging_mixin.py:109} INFO - [2022-04-28 03:33:07,335] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:33:07,399] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:33:07,419] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.947 seconds
[2022-04-28 03:33:37,942] {processor.py:163} INFO - Started process (PID=6186) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:33:37,945] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:33:37,948] {logging_mixin.py:109} INFO - [2022-04-28 03:33:37,947] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:33:38,309] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:33:38,315] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:33:38,319] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:33:38,324] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:33:38,332] {logging_mixin.py:109} INFO - [2022-04-28 03:33:38,326] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:33:38,365] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:33:38,376] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.447 seconds
[2022-04-28 03:34:08,758] {processor.py:163} INFO - Started process (PID=6214) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:34:08,763] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:34:08,766] {logging_mixin.py:109} INFO - [2022-04-28 03:34:08,766] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:34:09,057] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:34:09,060] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:34:09,064] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:34:09,069] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:34:09,076] {logging_mixin.py:109} INFO - [2022-04-28 03:34:09,070] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:34:09,101] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:34:09,114] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.365 seconds
[2022-04-28 03:34:39,245] {processor.py:163} INFO - Started process (PID=6253) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:34:39,258] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:34:39,261] {logging_mixin.py:109} INFO - [2022-04-28 03:34:39,261] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:34:39,565] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:34:39,569] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:34:39,571] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:34:39,575] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:34:39,581] {logging_mixin.py:109} INFO - [2022-04-28 03:34:39,577] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:34:39,602] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:34:39,613] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.379 seconds
[2022-04-28 03:35:10,228] {processor.py:163} INFO - Started process (PID=6281) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:35:10,231] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:35:10,233] {logging_mixin.py:109} INFO - [2022-04-28 03:35:10,233] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:35:10,740] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:35:10,746] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:35:10,750] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:35:10,757] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:35:10,772] {logging_mixin.py:109} INFO - [2022-04-28 03:35:10,762] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:35:10,797] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:35:10,814] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.593 seconds
[2022-04-28 03:35:41,139] {processor.py:163} INFO - Started process (PID=6316) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:35:41,149] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:35:41,154] {logging_mixin.py:109} INFO - [2022-04-28 03:35:41,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:35:41,968] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:35:41,977] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:35:41,984] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:35:41,995] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:35:42,000] {logging_mixin.py:109} INFO - [2022-04-28 03:35:41,997] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:35:42,021] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:35:42,051] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.932 seconds
[2022-04-28 03:36:12,238] {processor.py:163} INFO - Started process (PID=6343) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:36:12,242] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:36:12,245] {logging_mixin.py:109} INFO - [2022-04-28 03:36:12,244] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:36:12,580] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:36:12,585] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:36:12,589] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:36:12,594] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:36:12,602] {logging_mixin.py:109} INFO - [2022-04-28 03:36:12,596] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:36:12,624] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:36:12,640] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.410 seconds
[2022-04-28 03:36:42,988] {processor.py:163} INFO - Started process (PID=6366) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:36:42,993] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:36:42,996] {logging_mixin.py:109} INFO - [2022-04-28 03:36:42,996] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:36:43,664] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:36:43,669] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:36:43,683] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:36:43,689] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:36:43,703] {logging_mixin.py:109} INFO - [2022-04-28 03:36:43,691] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:36:43,744] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:36:43,768] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.799 seconds
[2022-04-28 03:37:14,126] {processor.py:163} INFO - Started process (PID=6392) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:37:14,129] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:37:14,131] {logging_mixin.py:109} INFO - [2022-04-28 03:37:14,131] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:37:14,412] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:37:14,417] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:37:14,420] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:37:14,426] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:37:14,431] {logging_mixin.py:109} INFO - [2022-04-28 03:37:14,427] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:37:14,454] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:37:14,467] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.347 seconds
[2022-04-28 03:37:44,530] {processor.py:163} INFO - Started process (PID=6430) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:37:44,534] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:37:44,536] {logging_mixin.py:109} INFO - [2022-04-28 03:37:44,536] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:37:44,831] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:37:44,834] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:37:44,837] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:37:44,841] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:37:44,845] {logging_mixin.py:109} INFO - [2022-04-28 03:37:44,842] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:37:44,875] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:37:44,894] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.368 seconds
[2022-04-28 03:38:15,063] {processor.py:163} INFO - Started process (PID=6458) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:38:15,068] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:38:15,070] {logging_mixin.py:109} INFO - [2022-04-28 03:38:15,070] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:38:15,540] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:38:15,545] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:38:15,549] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:38:15,555] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:38:15,563] {logging_mixin.py:109} INFO - [2022-04-28 03:38:15,557] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:38:15,586] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:38:15,601] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.556 seconds
[2022-04-28 03:38:46,034] {processor.py:163} INFO - Started process (PID=6487) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:38:46,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:38:46,040] {logging_mixin.py:109} INFO - [2022-04-28 03:38:46,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:38:46,317] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:38:46,321] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:38:46,324] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:38:46,328] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:38:46,334] {logging_mixin.py:109} INFO - [2022-04-28 03:38:46,329] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:38:46,359] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:38:46,370] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.353 seconds
[2022-04-28 03:39:16,987] {processor.py:163} INFO - Started process (PID=6523) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:39:16,991] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:39:16,993] {logging_mixin.py:109} INFO - [2022-04-28 03:39:16,993] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:39:17,349] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:39:17,352] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:39:17,355] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:39:17,358] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:39:17,363] {logging_mixin.py:109} INFO - [2022-04-28 03:39:17,360] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:39:17,387] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:39:17,402] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.423 seconds
[2022-04-28 03:39:47,708] {processor.py:163} INFO - Started process (PID=6550) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:39:47,712] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:39:47,713] {logging_mixin.py:109} INFO - [2022-04-28 03:39:47,713] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:39:48,213] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:39:48,221] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:39:48,226] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:39:48,232] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:39:48,243] {logging_mixin.py:109} INFO - [2022-04-28 03:39:48,238] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:39:48,265] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:39:48,279] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.577 seconds
[2022-04-28 03:40:18,481] {processor.py:163} INFO - Started process (PID=6576) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:40:18,486] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:40:18,488] {logging_mixin.py:109} INFO - [2022-04-28 03:40:18,488] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:40:18,830] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:40:18,835] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:40:18,838] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:40:18,843] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:40:18,852] {logging_mixin.py:109} INFO - [2022-04-28 03:40:18,845] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:40:18,883] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:40:18,908] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.434 seconds
[2022-04-28 03:40:49,801] {processor.py:163} INFO - Started process (PID=6614) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:40:49,804] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:40:49,806] {logging_mixin.py:109} INFO - [2022-04-28 03:40:49,806] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:40:50,109] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:40:50,116] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:40:50,119] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:40:50,124] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:40:50,129] {logging_mixin.py:109} INFO - [2022-04-28 03:40:50,125] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:40:50,149] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:40:50,162] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.366 seconds
[2022-04-28 03:41:20,349] {processor.py:163} INFO - Started process (PID=6642) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:41:20,353] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:41:20,354] {logging_mixin.py:109} INFO - [2022-04-28 03:41:20,354] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:41:20,628] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:41:20,631] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:41:20,634] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:41:20,637] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:41:20,643] {logging_mixin.py:109} INFO - [2022-04-28 03:41:20,638] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:41:20,662] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:41:20,675] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.332 seconds
[2022-04-28 03:41:51,658] {processor.py:163} INFO - Started process (PID=6670) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:41:51,662] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:41:51,665] {logging_mixin.py:109} INFO - [2022-04-28 03:41:51,664] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:41:52,016] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:41:52,020] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:41:52,023] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:41:52,027] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:41:52,032] {logging_mixin.py:109} INFO - [2022-04-28 03:41:52,028] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:41:52,058] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:41:52,072] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.419 seconds
[2022-04-28 03:42:22,596] {processor.py:163} INFO - Started process (PID=6704) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:42:22,600] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:42:22,601] {logging_mixin.py:109} INFO - [2022-04-28 03:42:22,601] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:42:22,916] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:42:22,920] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:42:22,930] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:42:22,948] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:42:22,961] {logging_mixin.py:109} INFO - [2022-04-28 03:42:22,953] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:42:22,991] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:42:23,005] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.415 seconds
[2022-04-28 03:42:53,421] {processor.py:163} INFO - Started process (PID=6732) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:42:53,425] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:42:53,426] {logging_mixin.py:109} INFO - [2022-04-28 03:42:53,426] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:42:53,898] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:42:53,902] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:42:53,905] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:42:53,909] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:42:53,914] {logging_mixin.py:109} INFO - [2022-04-28 03:42:53,911] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:42:53,943] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:42:53,957] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.540 seconds
[2022-04-28 03:43:24,867] {processor.py:163} INFO - Started process (PID=6774) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:43:24,874] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:43:24,875] {logging_mixin.py:109} INFO - [2022-04-28 03:43:24,875] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:43:25,159] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:43:25,163] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:43:25,165] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:43:25,169] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:43:25,174] {logging_mixin.py:109} INFO - [2022-04-28 03:43:25,170] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:43:25,200] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:43:25,248] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.387 seconds
[2022-04-28 03:43:55,477] {processor.py:163} INFO - Started process (PID=6802) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:43:55,482] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:43:55,484] {logging_mixin.py:109} INFO - [2022-04-28 03:43:55,484] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:43:55,831] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:43:55,836] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:43:55,840] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:43:55,846] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:43:55,855] {logging_mixin.py:109} INFO - [2022-04-28 03:43:55,848] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:43:55,879] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:43:55,895] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.425 seconds
[2022-04-28 03:44:26,303] {processor.py:163} INFO - Started process (PID=6831) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:44:26,307] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:44:26,309] {logging_mixin.py:109} INFO - [2022-04-28 03:44:26,309] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:44:26,587] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:44:26,592] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:44:26,594] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:44:26,598] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:44:26,604] {logging_mixin.py:109} INFO - [2022-04-28 03:44:26,600] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:44:26,625] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:44:26,638] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.344 seconds
[2022-04-28 03:44:57,185] {processor.py:163} INFO - Started process (PID=6861) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:44:57,189] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:44:57,192] {logging_mixin.py:109} INFO - [2022-04-28 03:44:57,191] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:44:57,531] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:44:57,536] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:44:57,539] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:44:57,545] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:44:57,551] {logging_mixin.py:109} INFO - [2022-04-28 03:44:57,546] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:44:57,576] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:44:57,592] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.415 seconds
[2022-04-28 03:45:27,830] {processor.py:163} INFO - Started process (PID=6898) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:45:27,836] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:45:27,840] {logging_mixin.py:109} INFO - [2022-04-28 03:45:27,840] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:45:29,113] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:45:29,125] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:45:29,134] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:45:29,142] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:45:29,161] {logging_mixin.py:109} INFO - [2022-04-28 03:45:29,149] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:45:29,207] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:45:29,232] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.415 seconds
[2022-04-28 03:45:59,427] {processor.py:163} INFO - Started process (PID=6928) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:45:59,430] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:45:59,433] {logging_mixin.py:109} INFO - [2022-04-28 03:45:59,433] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:45:59,810] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:45:59,818] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:45:59,825] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:45:59,834] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:45:59,846] {logging_mixin.py:109} INFO - [2022-04-28 03:45:59,837] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:45:59,880] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:45:59,901] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.479 seconds
[2022-04-28 03:46:30,341] {processor.py:163} INFO - Started process (PID=6955) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:46:30,346] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:46:30,349] {logging_mixin.py:109} INFO - [2022-04-28 03:46:30,348] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:46:30,754] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:46:30,758] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:46:30,765] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:46:30,771] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:46:30,782] {logging_mixin.py:109} INFO - [2022-04-28 03:46:30,775] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:46:30,824] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:46:30,841] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.554 seconds
[2022-04-28 03:47:01,224] {processor.py:163} INFO - Started process (PID=6981) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:47:01,228] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:47:01,231] {logging_mixin.py:109} INFO - [2022-04-28 03:47:01,231] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:47:01,753] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:47:01,757] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:47:01,759] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:47:01,762] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:47:01,768] {logging_mixin.py:109} INFO - [2022-04-28 03:47:01,764] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:47:01,793] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:47:01,806] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.590 seconds
[2022-04-28 03:47:32,104] {processor.py:163} INFO - Started process (PID=7012) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:47:32,110] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:47:32,115] {logging_mixin.py:109} INFO - [2022-04-28 03:47:32,115] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:47:32,430] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:47:32,434] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:47:32,437] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:47:32,440] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:47:32,445] {logging_mixin.py:109} INFO - [2022-04-28 03:47:32,441] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:47:32,463] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:47:32,474] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.376 seconds
[2022-04-28 03:48:03,850] {processor.py:163} INFO - Started process (PID=7040) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:48:03,859] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:48:03,867] {logging_mixin.py:109} INFO - [2022-04-28 03:48:03,867] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:48:04,222] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:48:04,225] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:48:04,228] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:48:04,232] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:48:04,237] {logging_mixin.py:109} INFO - [2022-04-28 03:48:04,233] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:48:04,258] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:48:04,275] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.460 seconds
[2022-04-28 03:48:34,477] {processor.py:163} INFO - Started process (PID=7073) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:48:34,483] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:48:34,484] {logging_mixin.py:109} INFO - [2022-04-28 03:48:34,484] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:48:35,319] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:48:35,324] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:48:35,330] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:48:35,342] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:48:35,355] {logging_mixin.py:109} INFO - [2022-04-28 03:48:35,345] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:48:35,393] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:48:35,416] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.949 seconds
[2022-04-28 03:49:05,738] {processor.py:163} INFO - Started process (PID=7101) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:49:05,742] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:49:05,744] {logging_mixin.py:109} INFO - [2022-04-28 03:49:05,744] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:49:06,134] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:49:06,141] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:49:06,145] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:49:06,152] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:49:06,161] {logging_mixin.py:109} INFO - [2022-04-28 03:49:06,155] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:49:06,186] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:49:06,202] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.472 seconds
[2022-04-28 03:49:36,621] {processor.py:163} INFO - Started process (PID=7136) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:49:36,624] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:49:36,627] {logging_mixin.py:109} INFO - [2022-04-28 03:49:36,627] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:49:36,985] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:49:36,988] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:49:36,993] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:49:37,001] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:49:37,009] {logging_mixin.py:109} INFO - [2022-04-28 03:49:37,003] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:49:37,037] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:49:37,055] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.444 seconds
[2022-04-28 03:50:07,751] {processor.py:163} INFO - Started process (PID=7165) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:50:07,755] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:50:07,757] {logging_mixin.py:109} INFO - [2022-04-28 03:50:07,757] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:50:08,054] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:50:08,057] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:50:08,060] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:50:08,064] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:50:08,068] {logging_mixin.py:109} INFO - [2022-04-28 03:50:08,065] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:50:08,088] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:50:08,105] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.361 seconds
[2022-04-28 03:50:38,474] {processor.py:163} INFO - Started process (PID=7190) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:50:38,478] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:50:38,480] {logging_mixin.py:109} INFO - [2022-04-28 03:50:38,480] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:50:39,052] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:50:39,063] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:50:39,073] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:50:39,085] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:50:39,099] {logging_mixin.py:109} INFO - [2022-04-28 03:50:39,087] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:50:39,130] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:50:39,174] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.708 seconds
[2022-04-28 03:51:09,736] {processor.py:163} INFO - Started process (PID=7222) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:51:09,739] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:51:09,748] {logging_mixin.py:109} INFO - [2022-04-28 03:51:09,747] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:51:11,208] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:51:11,213] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:51:11,224] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:51:11,238] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:51:11,255] {logging_mixin.py:109} INFO - [2022-04-28 03:51:11,240] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:51:11,324] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:51:11,355] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.634 seconds
[2022-04-28 03:51:41,616] {processor.py:163} INFO - Started process (PID=7249) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:51:41,619] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:51:41,621] {logging_mixin.py:109} INFO - [2022-04-28 03:51:41,621] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:51:41,909] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:51:41,912] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:51:41,916] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:51:41,921] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:51:41,927] {logging_mixin.py:109} INFO - [2022-04-28 03:51:41,922] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:51:41,951] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:51:41,965] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.356 seconds
[2022-04-28 03:52:12,192] {processor.py:163} INFO - Started process (PID=7276) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:52:12,194] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:52:12,196] {logging_mixin.py:109} INFO - [2022-04-28 03:52:12,196] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:52:12,485] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:52:12,489] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:52:12,491] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:52:12,495] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:52:12,500] {logging_mixin.py:109} INFO - [2022-04-28 03:52:12,496] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:52:12,521] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:52:12,535] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.350 seconds
[2022-04-28 03:52:43,020] {processor.py:163} INFO - Started process (PID=7302) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:52:43,024] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:52:43,027] {logging_mixin.py:109} INFO - [2022-04-28 03:52:43,027] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:52:43,336] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:52:43,342] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:52:43,346] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:52:43,361] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:52:43,369] {logging_mixin.py:109} INFO - [2022-04-28 03:52:43,363] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:52:43,397] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:52:43,410] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.399 seconds
[2022-04-28 03:53:13,712] {processor.py:163} INFO - Started process (PID=7338) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:53:13,714] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:53:13,716] {logging_mixin.py:109} INFO - [2022-04-28 03:53:13,716] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:53:14,053] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:53:14,056] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:53:14,059] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:53:14,063] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:53:14,068] {logging_mixin.py:109} INFO - [2022-04-28 03:53:14,065] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:53:14,100] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:53:14,130] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.423 seconds
[2022-04-28 03:53:44,702] {processor.py:163} INFO - Started process (PID=7364) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:53:44,706] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:53:44,709] {logging_mixin.py:109} INFO - [2022-04-28 03:53:44,709] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:53:45,290] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:53:45,311] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:53:45,316] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:53:45,323] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:53:45,331] {logging_mixin.py:109} INFO - [2022-04-28 03:53:45,325] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:53:45,375] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:53:45,388] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.694 seconds
[2022-04-28 03:54:15,628] {processor.py:163} INFO - Started process (PID=7391) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:54:15,631] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:54:15,635] {logging_mixin.py:109} INFO - [2022-04-28 03:54:15,634] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:54:16,034] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:54:16,037] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:54:16,040] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:54:16,045] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:54:16,051] {logging_mixin.py:109} INFO - [2022-04-28 03:54:16,046] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:54:16,072] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:54:16,085] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.467 seconds
[2022-04-28 03:54:46,858] {processor.py:163} INFO - Started process (PID=7428) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:54:46,861] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:54:46,863] {logging_mixin.py:109} INFO - [2022-04-28 03:54:46,863] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:54:47,155] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:54:47,158] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:54:47,162] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:54:47,165] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:54:47,170] {logging_mixin.py:109} INFO - [2022-04-28 03:54:47,167] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:54:47,199] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:54:47,211] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.362 seconds
[2022-04-28 03:55:17,765] {processor.py:163} INFO - Started process (PID=7459) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:55:17,771] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:55:17,774] {logging_mixin.py:109} INFO - [2022-04-28 03:55:17,774] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:55:18,109] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:55:18,114] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:55:18,118] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:55:18,124] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:55:18,132] {logging_mixin.py:109} INFO - [2022-04-28 03:55:18,126] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:55:18,164] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:55:18,180] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.425 seconds
[2022-04-28 03:55:48,701] {processor.py:163} INFO - Started process (PID=7497) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:55:48,710] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:55:48,714] {logging_mixin.py:109} INFO - [2022-04-28 03:55:48,714] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:55:49,467] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:55:49,477] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:55:49,485] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:55:49,498] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:55:49,516] {logging_mixin.py:109} INFO - [2022-04-28 03:55:49,501] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:55:49,554] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:55:49,579] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.888 seconds
[2022-04-28 03:56:19,881] {processor.py:163} INFO - Started process (PID=7525) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:56:19,885] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:56:19,888] {logging_mixin.py:109} INFO - [2022-04-28 03:56:19,888] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:56:20,484] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:56:20,488] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:56:20,492] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:56:20,496] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:56:20,506] {logging_mixin.py:109} INFO - [2022-04-28 03:56:20,499] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:56:20,530] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:56:20,543] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.669 seconds
[2022-04-28 03:56:50,679] {processor.py:163} INFO - Started process (PID=7552) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:56:50,685] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:56:50,688] {logging_mixin.py:109} INFO - [2022-04-28 03:56:50,687] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:56:51,100] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:56:51,104] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:56:51,107] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:56:51,111] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:56:51,118] {logging_mixin.py:109} INFO - [2022-04-28 03:56:51,113] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:56:51,143] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:56:51,162] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.490 seconds
[2022-04-28 03:57:21,297] {processor.py:163} INFO - Started process (PID=7580) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:57:21,303] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:57:21,306] {logging_mixin.py:109} INFO - [2022-04-28 03:57:21,305] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:57:21,849] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:57:21,853] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:57:21,856] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:57:21,860] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:57:21,866] {logging_mixin.py:109} INFO - [2022-04-28 03:57:21,862] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:57:21,889] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:57:21,904] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.618 seconds
[2022-04-28 03:57:52,436] {processor.py:163} INFO - Started process (PID=7619) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:57:52,439] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:57:52,443] {logging_mixin.py:109} INFO - [2022-04-28 03:57:52,443] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:57:52,759] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:57:52,763] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:57:52,766] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:57:52,771] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:57:52,775] {logging_mixin.py:109} INFO - [2022-04-28 03:57:52,772] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:57:52,822] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:57:52,843] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.434 seconds
[2022-04-28 03:58:23,265] {processor.py:163} INFO - Started process (PID=7647) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:58:23,271] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:58:23,273] {logging_mixin.py:109} INFO - [2022-04-28 03:58:23,273] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:58:23,876] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:58:23,882] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:58:23,887] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:58:23,895] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:58:23,903] {logging_mixin.py:109} INFO - [2022-04-28 03:58:23,897] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:58:23,941] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:58:23,966] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.709 seconds
[2022-04-28 03:58:54,203] {processor.py:163} INFO - Started process (PID=7683) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:58:54,210] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:58:54,220] {logging_mixin.py:109} INFO - [2022-04-28 03:58:54,220] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:58:54,731] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:58:54,737] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:58:54,741] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:58:54,748] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:58:54,757] {logging_mixin.py:109} INFO - [2022-04-28 03:58:54,751] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:58:54,788] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:58:54,811] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.612 seconds
[2022-04-28 03:59:25,260] {processor.py:163} INFO - Started process (PID=7710) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:59:25,263] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:59:25,265] {logging_mixin.py:109} INFO - [2022-04-28 03:59:25,265] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:59:26,047] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:59:26,054] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:59:26,071] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:59:26,085] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:59:26,091] {logging_mixin.py:109} INFO - [2022-04-28 03:59:26,087] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:59:26,121] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:59:26,135] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.900 seconds
[2022-04-28 03:59:56,289] {processor.py:163} INFO - Started process (PID=7742) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:59:56,294] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 03:59:56,300] {logging_mixin.py:109} INFO - [2022-04-28 03:59:56,300] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:59:56,676] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 03:59:56,688] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 03:59:56,700] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 03:59:56,714] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 03:59:56,723] {logging_mixin.py:109} INFO - [2022-04-28 03:59:56,716] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 03:59:56,790] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 03:59:56,817] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.535 seconds
[2022-04-28 04:00:27,132] {processor.py:163} INFO - Started process (PID=7769) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:00:27,138] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:00:27,145] {logging_mixin.py:109} INFO - [2022-04-28 04:00:27,142] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:00:27,857] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:00:27,865] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:00:27,875] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:00:27,886] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:00:27,899] {logging_mixin.py:109} INFO - [2022-04-28 04:00:27,889] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:00:27,964] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:00:27,993] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.882 seconds
[2022-04-28 04:00:58,504] {processor.py:163} INFO - Started process (PID=7807) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:00:58,510] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:00:58,521] {logging_mixin.py:109} INFO - [2022-04-28 04:00:58,521] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:01:00,313] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:01:00,335] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:01:00,345] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:01:00,373] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:01:00,394] {logging_mixin.py:109} INFO - [2022-04-28 04:01:00,375] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:01:00,481] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:01:00,541] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.068 seconds
[2022-04-28 04:01:30,830] {processor.py:163} INFO - Started process (PID=7835) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:01:30,839] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:01:30,844] {logging_mixin.py:109} INFO - [2022-04-28 04:01:30,844] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:01:31,614] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:01:31,618] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:01:31,620] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:01:31,629] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:01:31,635] {logging_mixin.py:109} INFO - [2022-04-28 04:01:31,630] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:01:31,661] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:01:31,674] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.868 seconds
[2022-04-28 04:02:01,774] {processor.py:163} INFO - Started process (PID=7861) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:02:01,777] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:02:01,779] {logging_mixin.py:109} INFO - [2022-04-28 04:02:01,779] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:02:02,099] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:02:02,102] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:02:02,105] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:02:02,109] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:02:02,114] {logging_mixin.py:109} INFO - [2022-04-28 04:02:02,111] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:02:02,145] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:02:02,163] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.399 seconds
[2022-04-28 04:02:32,563] {processor.py:163} INFO - Started process (PID=7888) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:02:32,566] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:02:32,568] {logging_mixin.py:109} INFO - [2022-04-28 04:02:32,567] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:02:32,959] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:02:32,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:02:32,966] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:02:32,971] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:02:32,981] {logging_mixin.py:109} INFO - [2022-04-28 04:02:32,972] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:02:33,006] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:02:33,021] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.464 seconds
[2022-04-28 04:03:03,326] {processor.py:163} INFO - Started process (PID=7912) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:03:03,331] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:03:03,334] {logging_mixin.py:109} INFO - [2022-04-28 04:03:03,334] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:03:03,723] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:03:03,733] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:03:03,738] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:03:03,748] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:03:03,758] {logging_mixin.py:109} INFO - [2022-04-28 04:03:03,750] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:03:03,787] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:03:03,800] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.492 seconds
[2022-04-28 04:03:34,012] {processor.py:163} INFO - Started process (PID=7940) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:03:34,015] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:03:34,018] {logging_mixin.py:109} INFO - [2022-04-28 04:03:34,018] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:03:34,473] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:03:34,477] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:03:34,480] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:03:34,484] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:03:34,491] {logging_mixin.py:109} INFO - [2022-04-28 04:03:34,487] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:03:34,528] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:03:34,544] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.554 seconds
[2022-04-28 04:04:04,850] {processor.py:163} INFO - Started process (PID=7978) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:04:04,854] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:04:04,856] {logging_mixin.py:109} INFO - [2022-04-28 04:04:04,856] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:04:05,432] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:04:05,438] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:04:05,443] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:04:05,449] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:04:05,461] {logging_mixin.py:109} INFO - [2022-04-28 04:04:05,451] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:04:05,502] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:04:05,536] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.695 seconds
[2022-04-28 04:04:36,387] {processor.py:163} INFO - Started process (PID=8005) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:04:36,390] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:04:36,403] {logging_mixin.py:109} INFO - [2022-04-28 04:04:36,398] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:04:37,726] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:04:37,731] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:04:37,737] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:04:37,749] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:04:37,759] {logging_mixin.py:109} INFO - [2022-04-28 04:04:37,751] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:04:37,800] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:04:37,827] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.476 seconds
[2022-04-28 04:05:08,048] {processor.py:163} INFO - Started process (PID=8033) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:05:08,051] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:05:08,055] {logging_mixin.py:109} INFO - [2022-04-28 04:05:08,055] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:05:08,425] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:05:08,429] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:05:08,433] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:05:08,437] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:05:08,443] {logging_mixin.py:109} INFO - [2022-04-28 04:05:08,438] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:05:08,472] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:05:08,492] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.450 seconds
[2022-04-28 04:05:39,706] {processor.py:163} INFO - Started process (PID=8071) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:05:39,709] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:05:39,713] {logging_mixin.py:109} INFO - [2022-04-28 04:05:39,712] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:05:40,138] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:05:40,142] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:05:40,144] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:05:40,148] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:05:40,153] {logging_mixin.py:109} INFO - [2022-04-28 04:05:40,149] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:05:40,175] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:05:40,188] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.492 seconds
[2022-04-28 04:06:11,142] {processor.py:163} INFO - Started process (PID=8097) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:06:11,152] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:06:11,154] {logging_mixin.py:109} INFO - [2022-04-28 04:06:11,154] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:06:11,841] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:06:11,852] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:06:11,856] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:06:11,861] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:06:11,874] {logging_mixin.py:109} INFO - [2022-04-28 04:06:11,869] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:06:11,908] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:06:11,933] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.795 seconds
[2022-04-28 04:06:42,487] {processor.py:163} INFO - Started process (PID=8132) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:06:42,499] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:06:42,502] {logging_mixin.py:109} INFO - [2022-04-28 04:06:42,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:06:43,309] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:06:43,323] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:06:43,334] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:06:43,344] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:06:43,364] {logging_mixin.py:109} INFO - [2022-04-28 04:06:43,349] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:06:43,407] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:06:43,437] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.964 seconds
[2022-04-28 04:07:13,598] {processor.py:163} INFO - Started process (PID=8158) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:07:13,602] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:07:13,605] {logging_mixin.py:109} INFO - [2022-04-28 04:07:13,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:07:13,933] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:07:13,938] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:07:13,940] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:07:13,944] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:07:13,948] {logging_mixin.py:109} INFO - [2022-04-28 04:07:13,945] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:07:13,971] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:07:13,985] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.394 seconds
[2022-04-28 04:07:44,494] {processor.py:163} INFO - Started process (PID=8185) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:07:44,501] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:07:44,504] {logging_mixin.py:109} INFO - [2022-04-28 04:07:44,504] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:07:44,964] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:07:44,967] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:07:44,969] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:07:44,973] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:07:44,978] {logging_mixin.py:109} INFO - [2022-04-28 04:07:44,974] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:07:44,998] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:07:45,010] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.527 seconds
[2022-04-28 04:08:15,213] {processor.py:163} INFO - Started process (PID=8215) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:08:15,217] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:08:15,219] {logging_mixin.py:109} INFO - [2022-04-28 04:08:15,219] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:08:15,884] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:08:15,889] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:08:15,894] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:08:15,899] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:08:15,907] {logging_mixin.py:109} INFO - [2022-04-28 04:08:15,903] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:08:15,938] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:08:15,957] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.749 seconds
[2022-04-28 04:08:46,373] {processor.py:163} INFO - Started process (PID=8243) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:08:46,379] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:08:46,382] {logging_mixin.py:109} INFO - [2022-04-28 04:08:46,381] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:08:46,865] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:08:46,871] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:08:46,878] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:08:46,889] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:08:46,896] {logging_mixin.py:109} INFO - [2022-04-28 04:08:46,891] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:08:46,919] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:08:46,936] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.574 seconds
[2022-04-28 04:09:17,541] {processor.py:163} INFO - Started process (PID=8269) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:09:17,547] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 04:09:17,550] {logging_mixin.py:109} INFO - [2022-04-28 04:09:17,549] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:09:17,906] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 04:09:17,920] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 04:09:17,929] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 04:09:17,933] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 04:09:17,940] {logging_mixin.py:109} INFO - [2022-04-28 04:09:17,935] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 04:09:17,988] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 04:09:18,003] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.468 seconds
[2022-04-28 19:25:24,773] {processor.py:163} INFO - Started process (PID=80) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:25:24,790] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:25:24,806] {logging_mixin.py:109} INFO - [2022-04-28 19:25:24,795] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:25:29,833] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:25:29,850] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:25:29,869] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:25:29,887] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:25:29,916] {logging_mixin.py:109} INFO - [2022-04-28 19:25:29,896] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:25:30,003] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:25:30,052] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 5.318 seconds
[2022-04-28 19:26:00,885] {processor.py:163} INFO - Started process (PID=103) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:26:00,909] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:26:00,930] {logging_mixin.py:109} INFO - [2022-04-28 19:26:00,930] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:26:06,231] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:26:06,303] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:26:06,344] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:26:06,403] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:26:06,542] {logging_mixin.py:109} INFO - [2022-04-28 19:26:06,486] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:26:06,728] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:26:06,830] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 6.008 seconds
[2022-04-28 19:26:37,180] {processor.py:163} INFO - Started process (PID=129) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:26:37,194] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:26:37,197] {logging_mixin.py:109} INFO - [2022-04-28 19:26:37,196] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:26:39,189] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:26:39,201] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:26:39,206] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:26:39,231] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:26:39,252] {logging_mixin.py:109} INFO - [2022-04-28 19:26:39,234] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:26:39,331] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:26:39,371] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.205 seconds
[2022-04-28 19:27:10,069] {processor.py:163} INFO - Started process (PID=145) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:27:10,074] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:27:10,077] {logging_mixin.py:109} INFO - [2022-04-28 19:27:10,077] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:27:10,629] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:27:10,633] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:27:10,636] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:27:10,641] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:27:10,646] {logging_mixin.py:109} INFO - [2022-04-28 19:27:10,643] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:27:10,669] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:27:10,682] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.619 seconds
[2022-04-28 19:27:41,028] {processor.py:163} INFO - Started process (PID=170) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:27:41,032] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:27:41,035] {logging_mixin.py:109} INFO - [2022-04-28 19:27:41,034] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:27:41,534] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:27:41,538] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:27:41,542] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:27:41,546] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:27:41,557] {logging_mixin.py:109} INFO - [2022-04-28 19:27:41,548] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:27:41,598] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:27:41,618] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.597 seconds
[2022-04-28 19:28:11,761] {processor.py:163} INFO - Started process (PID=196) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:28:11,766] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:28:11,777] {logging_mixin.py:109} INFO - [2022-04-28 19:28:11,776] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:28:15,283] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:28:15,307] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:28:15,314] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:28:15,349] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:28:15,379] {logging_mixin.py:109} INFO - [2022-04-28 19:28:15,352] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:28:15,465] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:28:15,506] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.765 seconds
[2022-04-28 19:28:46,027] {processor.py:163} INFO - Started process (PID=214) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:28:46,034] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:28:46,043] {logging_mixin.py:109} INFO - [2022-04-28 19:28:46,041] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:28:46,954] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:28:46,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:28:46,978] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:28:46,992] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:28:47,012] {logging_mixin.py:109} INFO - [2022-04-28 19:28:46,997] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:28:47,123] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:28:47,173] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.164 seconds
[2022-04-28 19:29:17,570] {processor.py:163} INFO - Started process (PID=242) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:29:17,593] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:29:17,601] {logging_mixin.py:109} INFO - [2022-04-28 19:29:17,600] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:29:18,634] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:29:18,639] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:29:18,644] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:29:18,667] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:29:18,680] {logging_mixin.py:109} INFO - [2022-04-28 19:29:18,671] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:29:18,714] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:29:18,732] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.168 seconds
[2022-04-28 19:29:48,992] {processor.py:163} INFO - Started process (PID=269) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:29:49,003] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:29:49,010] {logging_mixin.py:109} INFO - [2022-04-28 19:29:49,009] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:29:50,185] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:29:50,190] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:29:50,194] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:29:50,204] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:29:50,222] {logging_mixin.py:109} INFO - [2022-04-28 19:29:50,206] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:29:50,259] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:29:50,296] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.317 seconds
[2022-04-28 19:30:20,713] {processor.py:163} INFO - Started process (PID=294) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:30:20,733] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:30:20,743] {logging_mixin.py:109} INFO - [2022-04-28 19:30:20,741] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:30:22,344] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:30:22,356] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:30:22,366] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:30:22,374] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:30:22,384] {logging_mixin.py:109} INFO - [2022-04-28 19:30:22,376] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:30:22,429] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:30:22,466] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.769 seconds
[2022-04-28 19:30:52,733] {processor.py:163} INFO - Started process (PID=319) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:30:52,738] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:30:52,744] {logging_mixin.py:109} INFO - [2022-04-28 19:30:52,743] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:30:54,426] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:30:54,445] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:30:54,467] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:30:54,488] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:30:54,522] {logging_mixin.py:109} INFO - [2022-04-28 19:30:54,503] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:30:54,626] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:30:54,677] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.963 seconds
[2022-04-28 19:31:25,405] {processor.py:163} INFO - Started process (PID=353) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:31:25,420] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:31:25,424] {logging_mixin.py:109} INFO - [2022-04-28 19:31:25,423] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:31:33,502] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:31:33,537] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:31:33,552] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:31:33,606] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:31:33,681] {logging_mixin.py:109} INFO - [2022-04-28 19:31:33,624] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:31:33,849] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:31:33,952] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 8.587 seconds
[2022-04-28 19:32:04,434] {processor.py:163} INFO - Started process (PID=370) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:32:04,449] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:32:04,460] {logging_mixin.py:109} INFO - [2022-04-28 19:32:04,458] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:32:06,069] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:32:06,087] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:32:06,104] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:32:06,117] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:32:06,131] {logging_mixin.py:109} INFO - [2022-04-28 19:32:06,120] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:32:06,263] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:32:06,333] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.913 seconds
[2022-04-28 19:32:36,766] {processor.py:163} INFO - Started process (PID=396) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:32:36,771] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:32:36,774] {logging_mixin.py:109} INFO - [2022-04-28 19:32:36,774] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:32:37,847] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:32:37,862] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:32:37,869] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:32:37,881] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:32:37,900] {logging_mixin.py:109} INFO - [2022-04-28 19:32:37,885] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:32:37,935] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:32:37,953] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.199 seconds
[2022-04-28 19:33:08,408] {processor.py:163} INFO - Started process (PID=422) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:33:08,416] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:33:08,419] {logging_mixin.py:109} INFO - [2022-04-28 19:33:08,418] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:33:09,246] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:33:09,252] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:33:09,255] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:33:09,260] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:33:09,271] {logging_mixin.py:109} INFO - [2022-04-28 19:33:09,265] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:33:09,300] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:33:09,321] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.922 seconds
[2022-04-28 19:33:39,630] {processor.py:163} INFO - Started process (PID=445) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:33:39,657] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:33:39,680] {logging_mixin.py:109} INFO - [2022-04-28 19:33:39,680] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:33:43,611] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:33:43,641] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:33:43,660] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:33:43,677] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:33:43,708] {logging_mixin.py:109} INFO - [2022-04-28 19:33:43,692] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:33:43,811] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:33:43,874] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.280 seconds
[2022-04-28 19:34:14,708] {processor.py:163} INFO - Started process (PID=465) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:34:14,713] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:34:14,725] {logging_mixin.py:109} INFO - [2022-04-28 19:34:14,725] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:34:16,594] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:34:16,626] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:34:16,633] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:34:16,677] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:34:16,706] {logging_mixin.py:109} INFO - [2022-04-28 19:34:16,686] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:34:16,771] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:34:16,806] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.139 seconds
[2022-04-28 19:34:51,158] {processor.py:163} INFO - Started process (PID=491) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:34:51,269] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:34:51,324] {logging_mixin.py:109} INFO - [2022-04-28 19:34:51,323] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:34:53,942] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:34:53,965] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:34:53,971] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:34:53,981] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:34:53,990] {logging_mixin.py:109} INFO - [2022-04-28 19:34:53,984] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:34:54,034] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:34:54,069] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.932 seconds
[2022-04-28 19:35:25,561] {processor.py:163} INFO - Started process (PID=518) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:35:25,568] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:35:25,571] {logging_mixin.py:109} INFO - [2022-04-28 19:35:25,571] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:35:27,221] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:35:27,241] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:35:27,255] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:35:27,272] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:35:27,305] {logging_mixin.py:109} INFO - [2022-04-28 19:35:27,280] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:35:27,406] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:35:27,439] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.887 seconds
[2022-04-28 19:36:02,521] {processor.py:163} INFO - Started process (PID=546) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:36:02,526] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:36:02,531] {logging_mixin.py:109} INFO - [2022-04-28 19:36:02,530] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:36:04,707] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:36:04,738] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:36:04,794] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:36:04,805] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:36:04,846] {logging_mixin.py:109} INFO - [2022-04-28 19:36:04,816] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:36:05,214] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:36:05,263] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.762 seconds
[2022-04-28 19:36:43,241] {processor.py:163} INFO - Started process (PID=573) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:36:43,253] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:36:43,263] {logging_mixin.py:109} INFO - [2022-04-28 19:36:43,262] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:36:46,440] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:36:46,472] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:36:46,487] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:36:46,509] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:36:46,550] {logging_mixin.py:109} INFO - [2022-04-28 19:36:46,522] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:36:46,766] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:36:46,824] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.611 seconds
[2022-04-28 19:37:20,233] {processor.py:163} INFO - Started process (PID=602) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:37:20,237] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:37:20,241] {logging_mixin.py:109} INFO - [2022-04-28 19:37:20,241] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:37:23,386] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:37:23,401] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:37:23,415] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:37:23,437] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:37:23,458] {logging_mixin.py:109} INFO - [2022-04-28 19:37:23,440] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:37:23,558] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:37:23,618] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.400 seconds
[2022-04-28 19:37:57,837] {processor.py:163} INFO - Started process (PID=629) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:37:57,862] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:37:57,879] {logging_mixin.py:109} INFO - [2022-04-28 19:37:57,878] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:37:59,059] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:37:59,073] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:37:59,086] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:37:59,106] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:37:59,131] {logging_mixin.py:109} INFO - [2022-04-28 19:37:59,110] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:37:59,184] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:37:59,204] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.389 seconds
[2022-04-28 19:38:33,057] {processor.py:163} INFO - Started process (PID=656) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:38:33,072] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:38:33,085] {logging_mixin.py:109} INFO - [2022-04-28 19:38:33,082] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:38:34,579] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:38:34,609] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:38:34,618] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:38:34,635] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:38:34,679] {logging_mixin.py:109} INFO - [2022-04-28 19:38:34,642] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:38:34,730] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:38:34,757] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.755 seconds
[2022-04-28 19:39:09,706] {processor.py:163} INFO - Started process (PID=684) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:39:09,715] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:39:09,720] {logging_mixin.py:109} INFO - [2022-04-28 19:39:09,719] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:39:10,504] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:39:10,512] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:39:10,519] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:39:10,539] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:39:10,550] {logging_mixin.py:109} INFO - [2022-04-28 19:39:10,543] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:39:10,609] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:39:10,636] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.943 seconds
[2022-04-28 19:39:44,717] {processor.py:163} INFO - Started process (PID=710) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:39:44,722] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:39:44,726] {logging_mixin.py:109} INFO - [2022-04-28 19:39:44,726] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:39:45,781] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:39:45,792] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:39:45,800] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:39:45,811] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:39:45,830] {logging_mixin.py:109} INFO - [2022-04-28 19:39:45,817] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:39:45,875] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:39:45,890] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.179 seconds
[2022-04-28 19:40:17,518] {processor.py:163} INFO - Started process (PID=736) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:40:17,531] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:40:17,535] {logging_mixin.py:109} INFO - [2022-04-28 19:40:17,535] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:40:18,600] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:40:18,613] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:40:18,623] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:40:18,638] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:40:18,655] {logging_mixin.py:109} INFO - [2022-04-28 19:40:18,642] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:40:18,688] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:40:18,712] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.211 seconds
[2022-04-28 19:40:52,070] {processor.py:163} INFO - Started process (PID=764) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:40:52,074] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:40:52,086] {logging_mixin.py:109} INFO - [2022-04-28 19:40:52,086] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:40:54,401] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:40:54,416] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:40:54,429] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:40:54,444] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:40:54,470] {logging_mixin.py:109} INFO - [2022-04-28 19:40:54,449] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:40:54,516] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:40:54,544] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.489 seconds
[2022-04-28 19:41:26,551] {processor.py:163} INFO - Started process (PID=789) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:41:26,560] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:41:26,565] {logging_mixin.py:109} INFO - [2022-04-28 19:41:26,565] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:41:27,495] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:41:27,511] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:41:27,520] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:41:27,540] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:41:27,586] {logging_mixin.py:109} INFO - [2022-04-28 19:41:27,553] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:41:27,663] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:41:27,718] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.181 seconds
[2022-04-28 19:41:58,480] {processor.py:163} INFO - Started process (PID=815) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:41:58,490] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:41:58,498] {logging_mixin.py:109} INFO - [2022-04-28 19:41:58,498] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:41:59,619] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:41:59,623] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:41:59,636] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:41:59,649] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:41:59,659] {logging_mixin.py:109} INFO - [2022-04-28 19:41:59,652] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:41:59,692] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:41:59,714] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.249 seconds
[2022-04-28 19:42:31,685] {processor.py:163} INFO - Started process (PID=843) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:42:31,693] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:42:31,702] {logging_mixin.py:109} INFO - [2022-04-28 19:42:31,701] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:42:32,877] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:42:32,899] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:42:32,902] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:42:32,923] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:42:32,946] {logging_mixin.py:109} INFO - [2022-04-28 19:42:32,927] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:42:32,998] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:42:33,072] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.407 seconds
[2022-04-28 19:43:08,260] {processor.py:163} INFO - Started process (PID=879) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:43:08,277] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:43:08,286] {logging_mixin.py:109} INFO - [2022-04-28 19:43:08,283] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:43:09,489] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:43:09,493] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:43:09,496] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:43:09,500] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:43:09,508] {logging_mixin.py:109} INFO - [2022-04-28 19:43:09,502] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:43:09,542] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:43:09,557] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.315 seconds
[2022-04-28 19:43:40,060] {processor.py:163} INFO - Started process (PID=906) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:43:40,068] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:43:40,073] {logging_mixin.py:109} INFO - [2022-04-28 19:43:40,072] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:43:40,655] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:43:40,659] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:43:40,662] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:43:40,674] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:43:40,686] {logging_mixin.py:109} INFO - [2022-04-28 19:43:40,677] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:43:40,727] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:43:40,741] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.693 seconds
[2022-04-28 19:44:11,541] {processor.py:163} INFO - Started process (PID=931) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:44:11,547] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:44:11,551] {logging_mixin.py:109} INFO - [2022-04-28 19:44:11,550] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:44:12,009] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:44:12,034] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:44:12,048] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:44:12,064] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:44:12,089] {logging_mixin.py:109} INFO - [2022-04-28 19:44:12,078] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:44:12,150] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:44:12,170] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.640 seconds
[2022-04-28 19:44:42,337] {processor.py:163} INFO - Started process (PID=957) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:44:42,349] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:44:42,352] {logging_mixin.py:109} INFO - [2022-04-28 19:44:42,352] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:44:43,014] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:44:43,026] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:44:43,033] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:44:43,044] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:44:43,056] {logging_mixin.py:109} INFO - [2022-04-28 19:44:43,047] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:44:43,092] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:44:43,115] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.784 seconds
[2022-04-28 19:45:20,316] {processor.py:163} INFO - Started process (PID=999) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:45:20,333] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:45:20,340] {logging_mixin.py:109} INFO - [2022-04-28 19:45:20,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:45:24,175] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:45:24,190] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:45:24,202] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:45:24,220] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:45:24,246] {logging_mixin.py:109} INFO - [2022-04-28 19:45:24,228] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:45:24,290] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:45:24,316] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.034 seconds
[2022-04-28 19:45:55,278] {processor.py:163} INFO - Started process (PID=1014) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:45:55,331] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:45:55,339] {logging_mixin.py:109} INFO - [2022-04-28 19:45:55,339] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:45:57,856] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:45:57,886] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:45:57,908] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:45:57,931] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:45:58,013] {logging_mixin.py:109} INFO - [2022-04-28 19:45:57,953] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:45:58,177] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:45:58,226] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.980 seconds
[2022-04-28 19:46:29,186] {processor.py:163} INFO - Started process (PID=1042) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:46:29,193] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:46:29,200] {logging_mixin.py:109} INFO - [2022-04-28 19:46:29,200] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:46:32,131] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:46:32,156] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:46:32,180] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:46:32,201] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:46:32,229] {logging_mixin.py:109} INFO - [2022-04-28 19:46:32,211] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:46:32,272] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:46:32,306] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.165 seconds
[2022-04-28 19:47:02,586] {processor.py:163} INFO - Started process (PID=1067) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:47:02,607] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:47:02,620] {logging_mixin.py:109} INFO - [2022-04-28 19:47:02,617] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:47:03,199] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:47:03,207] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:47:03,214] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:47:03,226] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:47:03,239] {logging_mixin.py:109} INFO - [2022-04-28 19:47:03,229] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:47:03,374] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:47:03,441] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.874 seconds
[2022-04-28 19:47:33,725] {processor.py:163} INFO - Started process (PID=1101) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:47:33,728] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:47:33,730] {logging_mixin.py:109} INFO - [2022-04-28 19:47:33,730] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:47:34,333] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:47:34,341] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:47:34,348] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:47:34,357] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:47:34,365] {logging_mixin.py:109} INFO - [2022-04-28 19:47:34,360] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:47:34,399] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:47:34,413] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.703 seconds
[2022-04-28 19:48:04,606] {processor.py:163} INFO - Started process (PID=1129) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:48:04,630] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:48:04,637] {logging_mixin.py:109} INFO - [2022-04-28 19:48:04,636] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:48:07,457] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:48:07,464] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:48:07,474] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:48:07,489] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:48:07,506] {logging_mixin.py:109} INFO - [2022-04-28 19:48:07,492] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:48:07,545] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:48:07,565] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.992 seconds
[2022-04-28 19:48:38,424] {processor.py:163} INFO - Started process (PID=1154) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:48:38,429] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:48:38,444] {logging_mixin.py:109} INFO - [2022-04-28 19:48:38,443] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:48:40,897] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:48:40,913] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:48:40,916] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:48:40,972] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:48:40,989] {logging_mixin.py:109} INFO - [2022-04-28 19:48:40,974] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:48:41,036] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:48:41,071] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.673 seconds
[2022-04-28 19:49:11,339] {processor.py:163} INFO - Started process (PID=1172) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:49:11,352] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:49:11,355] {logging_mixin.py:109} INFO - [2022-04-28 19:49:11,355] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:49:12,792] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:49:12,826] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:49:12,832] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:49:12,850] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:49:12,870] {logging_mixin.py:109} INFO - [2022-04-28 19:49:12,854] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:49:12,925] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:49:12,957] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.631 seconds
[2022-04-28 19:49:43,555] {processor.py:163} INFO - Started process (PID=1198) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:49:43,569] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:49:43,577] {logging_mixin.py:109} INFO - [2022-04-28 19:49:43,575] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:49:44,430] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:49:44,443] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:49:44,447] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:49:44,462] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:49:44,482] {logging_mixin.py:109} INFO - [2022-04-28 19:49:44,467] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:49:44,521] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:49:44,555] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.020 seconds
[2022-04-28 19:50:15,255] {processor.py:163} INFO - Started process (PID=1224) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:50:15,262] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:50:15,266] {logging_mixin.py:109} INFO - [2022-04-28 19:50:15,266] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:50:16,055] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:50:16,066] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:50:16,073] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:50:16,082] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:50:16,095] {logging_mixin.py:109} INFO - [2022-04-28 19:50:16,086] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:50:16,130] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:50:16,146] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.905 seconds
[2022-04-28 19:50:46,856] {processor.py:163} INFO - Started process (PID=1255) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:50:46,872] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:50:46,891] {logging_mixin.py:109} INFO - [2022-04-28 19:50:46,890] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:50:47,678] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:50:47,685] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:50:47,690] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:50:47,702] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:50:47,713] {logging_mixin.py:109} INFO - [2022-04-28 19:50:47,707] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:50:47,787] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:50:47,932] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.131 seconds
[2022-04-28 19:51:19,100] {processor.py:163} INFO - Started process (PID=1282) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:51:19,120] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:51:19,129] {logging_mixin.py:109} INFO - [2022-04-28 19:51:19,128] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:51:21,353] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:51:21,382] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:51:21,389] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:51:21,403] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:51:21,425] {logging_mixin.py:109} INFO - [2022-04-28 19:51:21,407] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:51:21,465] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:51:21,492] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.473 seconds
[2022-04-28 19:51:51,841] {processor.py:163} INFO - Started process (PID=1309) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:51:51,848] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:51:51,853] {logging_mixin.py:109} INFO - [2022-04-28 19:51:51,852] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:51:52,452] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:51:52,464] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:51:52,468] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:51:52,473] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:51:52,483] {logging_mixin.py:109} INFO - [2022-04-28 19:51:52,478] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:51:52,548] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:51:52,596] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.767 seconds
[2022-04-28 19:52:22,779] {processor.py:163} INFO - Started process (PID=1338) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:52:22,784] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:52:22,788] {logging_mixin.py:109} INFO - [2022-04-28 19:52:22,787] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:52:23,702] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:52:23,715] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:52:23,723] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:52:23,736] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:52:23,754] {logging_mixin.py:109} INFO - [2022-04-28 19:52:23,740] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:52:23,800] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:52:23,827] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.059 seconds
[2022-04-28 19:52:54,282] {processor.py:163} INFO - Started process (PID=1366) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:52:54,301] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:52:54,311] {logging_mixin.py:109} INFO - [2022-04-28 19:52:54,310] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:52:55,085] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:52:55,099] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:52:55,105] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:52:55,119] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:52:55,156] {logging_mixin.py:109} INFO - [2022-04-28 19:52:55,123] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:52:55,210] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:52:55,253] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.008 seconds
[2022-04-28 19:53:26,131] {processor.py:163} INFO - Started process (PID=1392) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:53:26,135] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:53:26,140] {logging_mixin.py:109} INFO - [2022-04-28 19:53:26,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:53:26,608] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:53:26,614] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:53:26,618] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:53:26,622] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:53:26,628] {logging_mixin.py:109} INFO - [2022-04-28 19:53:26,623] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:53:26,656] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:53:26,674] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.548 seconds
[2022-04-28 19:53:57,008] {processor.py:163} INFO - Started process (PID=1418) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:53:57,013] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:53:57,016] {logging_mixin.py:109} INFO - [2022-04-28 19:53:57,016] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:53:57,929] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:53:57,938] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:53:57,945] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:53:57,954] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:53:57,965] {logging_mixin.py:109} INFO - [2022-04-28 19:53:57,956] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:53:57,999] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:53:58,028] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.028 seconds
[2022-04-28 19:54:28,383] {processor.py:163} INFO - Started process (PID=1446) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:54:28,388] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:54:28,391] {logging_mixin.py:109} INFO - [2022-04-28 19:54:28,390] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:54:30,697] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:54:30,721] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:54:30,727] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:54:30,743] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:54:30,764] {logging_mixin.py:109} INFO - [2022-04-28 19:54:30,747] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:54:30,845] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:54:30,943] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.607 seconds
[2022-04-28 19:55:01,363] {processor.py:163} INFO - Started process (PID=1473) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:55:01,368] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:55:01,371] {logging_mixin.py:109} INFO - [2022-04-28 19:55:01,370] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:55:01,874] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:55:01,878] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:55:01,881] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:55:01,886] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:55:01,893] {logging_mixin.py:109} INFO - [2022-04-28 19:55:01,888] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:55:01,919] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:55:01,934] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.577 seconds
[2022-04-28 19:55:32,411] {processor.py:163} INFO - Started process (PID=1500) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:55:32,432] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:55:32,437] {logging_mixin.py:109} INFO - [2022-04-28 19:55:32,436] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:55:36,665] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:55:36,687] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:55:36,702] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:55:36,720] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:55:36,754] {logging_mixin.py:109} INFO - [2022-04-28 19:55:36,723] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:55:36,828] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:55:36,875] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.495 seconds
[2022-04-28 19:56:07,410] {processor.py:163} INFO - Started process (PID=1525) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:56:07,433] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:56:07,438] {logging_mixin.py:109} INFO - [2022-04-28 19:56:07,438] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:56:10,147] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:56:10,161] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:56:10,185] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:56:10,199] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:56:10,228] {logging_mixin.py:109} INFO - [2022-04-28 19:56:10,209] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:56:10,314] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:56:10,361] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.982 seconds
[2022-04-28 19:56:41,563] {processor.py:163} INFO - Started process (PID=1550) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:56:41,595] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:56:41,612] {logging_mixin.py:109} INFO - [2022-04-28 19:56:41,612] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:56:43,150] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:56:43,155] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:56:43,162] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:56:43,175] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:56:43,192] {logging_mixin.py:109} INFO - [2022-04-28 19:56:43,179] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:56:43,232] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:56:43,287] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.750 seconds
[2022-04-28 19:57:13,511] {processor.py:163} INFO - Started process (PID=1577) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:57:13,517] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:57:13,521] {logging_mixin.py:109} INFO - [2022-04-28 19:57:13,520] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:57:14,455] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:57:14,488] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:57:14,506] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:57:14,531] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:57:14,581] {logging_mixin.py:109} INFO - [2022-04-28 19:57:14,543] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:57:14,770] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:57:14,860] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.359 seconds
[2022-04-28 19:57:45,008] {processor.py:163} INFO - Started process (PID=1608) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:57:45,014] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:57:45,018] {logging_mixin.py:109} INFO - [2022-04-28 19:57:45,017] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:57:45,361] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:57:45,369] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:57:45,374] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:57:45,383] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:57:45,395] {logging_mixin.py:109} INFO - [2022-04-28 19:57:45,386] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:57:45,441] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:57:45,471] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.471 seconds
[2022-04-28 19:58:15,966] {processor.py:163} INFO - Started process (PID=1635) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:58:15,981] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:58:15,995] {logging_mixin.py:109} INFO - [2022-04-28 19:58:15,995] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:58:16,397] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:58:16,406] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:58:16,411] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:58:16,421] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:58:16,434] {logging_mixin.py:109} INFO - [2022-04-28 19:58:16,425] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:58:16,467] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:58:16,488] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.543 seconds
[2022-04-28 19:58:46,729] {processor.py:163} INFO - Started process (PID=1662) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:58:46,741] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:58:46,746] {logging_mixin.py:109} INFO - [2022-04-28 19:58:46,745] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:58:47,421] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:58:47,425] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:58:47,429] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:58:47,434] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:58:47,441] {logging_mixin.py:109} INFO - [2022-04-28 19:58:47,435] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:58:47,474] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:58:47,494] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.777 seconds
[2022-04-28 19:59:17,751] {processor.py:163} INFO - Started process (PID=1690) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:59:17,766] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:59:17,774] {logging_mixin.py:109} INFO - [2022-04-28 19:59:17,774] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:59:19,305] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:59:19,316] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:59:19,324] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:59:19,336] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:59:19,349] {logging_mixin.py:109} INFO - [2022-04-28 19:59:19,338] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:59:19,395] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:59:19,433] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.704 seconds
[2022-04-28 19:59:49,820] {processor.py:163} INFO - Started process (PID=1718) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:59:49,836] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 19:59:49,845] {logging_mixin.py:109} INFO - [2022-04-28 19:59:49,844] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:59:50,988] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 19:59:50,998] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 19:59:51,009] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 19:59:51,024] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 19:59:51,040] {logging_mixin.py:109} INFO - [2022-04-28 19:59:51,030] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 19:59:51,182] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 19:59:51,203] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.443 seconds
[2022-04-28 20:00:21,839] {processor.py:163} INFO - Started process (PID=1746) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:00:21,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:00:21,874] {logging_mixin.py:109} INFO - [2022-04-28 20:00:21,872] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:00:23,163] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:00:23,175] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:00:23,185] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:00:23,201] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:00:23,239] {logging_mixin.py:109} INFO - [2022-04-28 20:00:23,210] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:00:23,282] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:00:23,315] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.498 seconds
[2022-04-28 20:00:53,424] {processor.py:163} INFO - Started process (PID=1774) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:00:53,435] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:00:53,437] {logging_mixin.py:109} INFO - [2022-04-28 20:00:53,437] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:00:54,697] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:00:54,705] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:00:54,715] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:00:54,728] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:00:54,745] {logging_mixin.py:109} INFO - [2022-04-28 20:00:54,730] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:00:54,798] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:00:54,828] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.418 seconds
[2022-04-28 20:01:25,120] {processor.py:163} INFO - Started process (PID=1803) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:01:25,131] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:01:25,142] {logging_mixin.py:109} INFO - [2022-04-28 20:01:25,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:01:27,085] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:01:27,103] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:01:27,119] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:01:27,133] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:01:27,146] {logging_mixin.py:109} INFO - [2022-04-28 20:01:27,136] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:01:27,201] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:01:27,263] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.182 seconds
[2022-04-28 20:01:57,661] {processor.py:163} INFO - Started process (PID=1830) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:01:57,666] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:01:57,668] {logging_mixin.py:109} INFO - [2022-04-28 20:01:57,668] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:01:57,987] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:01:57,991] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:01:57,994] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:01:57,998] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:01:58,005] {logging_mixin.py:109} INFO - [2022-04-28 20:01:58,000] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:01:58,031] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:01:58,046] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.391 seconds
[2022-04-28 20:02:28,288] {processor.py:163} INFO - Started process (PID=1855) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:02:28,292] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:02:28,295] {logging_mixin.py:109} INFO - [2022-04-28 20:02:28,294] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:02:28,609] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:02:28,613] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:02:28,617] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:02:28,621] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:02:28,628] {logging_mixin.py:109} INFO - [2022-04-28 20:02:28,623] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:02:28,652] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:02:28,670] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.385 seconds
[2022-04-28 20:02:59,050] {processor.py:163} INFO - Started process (PID=1882) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:02:59,061] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:02:59,063] {logging_mixin.py:109} INFO - [2022-04-28 20:02:59,063] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:02:59,561] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:02:59,569] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:02:59,575] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:02:59,584] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:02:59,598] {logging_mixin.py:109} INFO - [2022-04-28 20:02:59,587] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:02:59,631] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:02:59,652] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.619 seconds
[2022-04-28 20:03:30,775] {processor.py:163} INFO - Started process (PID=1910) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:03:30,797] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:03:30,808] {logging_mixin.py:109} INFO - [2022-04-28 20:03:30,807] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:03:31,764] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:03:31,768] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:03:31,772] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:03:31,784] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:03:31,791] {logging_mixin.py:109} INFO - [2022-04-28 20:03:31,786] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:03:31,831] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:03:31,853] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.099 seconds
[2022-04-28 20:04:02,709] {processor.py:163} INFO - Started process (PID=1934) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:04:02,720] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:04:02,740] {logging_mixin.py:109} INFO - [2022-04-28 20:04:02,733] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:04:05,608] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:04:05,637] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:04:05,667] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:04:05,813] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:04:05,859] {logging_mixin.py:109} INFO - [2022-04-28 20:04:05,837] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:04:06,142] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:04:06,300] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.666 seconds
[2022-04-28 20:04:36,836] {processor.py:163} INFO - Started process (PID=1962) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:04:36,851] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:04:36,864] {logging_mixin.py:109} INFO - [2022-04-28 20:04:36,864] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:04:39,507] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:04:39,513] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:04:39,529] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:04:39,567] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:04:39,589] {logging_mixin.py:109} INFO - [2022-04-28 20:04:39,569] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:04:39,690] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:04:39,757] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.941 seconds
[2022-04-28 20:05:10,512] {processor.py:163} INFO - Started process (PID=1991) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:05:10,516] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:05:10,518] {logging_mixin.py:109} INFO - [2022-04-28 20:05:10,518] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:05:10,943] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:05:10,960] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:05:10,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:05:10,967] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:05:10,975] {logging_mixin.py:109} INFO - [2022-04-28 20:05:10,970] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:05:11,001] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:05:11,017] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.512 seconds
[2022-04-28 20:05:41,963] {processor.py:163} INFO - Started process (PID=2031) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:05:41,966] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:05:41,968] {logging_mixin.py:109} INFO - [2022-04-28 20:05:41,967] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:05:42,459] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:05:42,463] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:05:42,467] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:05:42,472] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:05:42,479] {logging_mixin.py:109} INFO - [2022-04-28 20:05:42,474] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:05:42,516] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:05:42,537] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.579 seconds
[2022-04-28 20:06:12,727] {processor.py:163} INFO - Started process (PID=2062) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:06:12,738] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:06:12,745] {logging_mixin.py:109} INFO - [2022-04-28 20:06:12,743] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:06:13,220] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:06:13,228] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:06:13,232] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:06:13,238] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:06:13,248] {logging_mixin.py:109} INFO - [2022-04-28 20:06:13,241] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:06:13,288] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:06:13,314] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.605 seconds
[2022-04-28 20:06:44,161] {processor.py:163} INFO - Started process (PID=2088) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:06:44,170] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:06:44,175] {logging_mixin.py:109} INFO - [2022-04-28 20:06:44,175] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:06:45,738] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:06:45,756] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:06:45,766] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:06:45,780] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:06:45,791] {logging_mixin.py:109} INFO - [2022-04-28 20:06:45,782] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:06:45,839] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:06:45,867] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.726 seconds
[2022-04-28 20:07:16,274] {processor.py:163} INFO - Started process (PID=2108) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:07:16,279] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:07:16,282] {logging_mixin.py:109} INFO - [2022-04-28 20:07:16,282] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:07:16,709] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:07:16,714] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:07:16,722] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:07:16,734] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:07:16,750] {logging_mixin.py:109} INFO - [2022-04-28 20:07:16,737] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:07:16,786] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:07:16,809] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.542 seconds
[2022-04-28 20:07:47,435] {processor.py:163} INFO - Started process (PID=2135) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:07:47,438] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:07:47,440] {logging_mixin.py:109} INFO - [2022-04-28 20:07:47,440] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:07:47,786] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:07:47,795] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:07:47,801] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:07:47,809] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:07:47,820] {logging_mixin.py:109} INFO - [2022-04-28 20:07:47,812] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:07:47,851] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:07:47,881] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.451 seconds
[2022-04-28 20:08:18,651] {processor.py:163} INFO - Started process (PID=2171) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:08:18,674] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:08:18,678] {logging_mixin.py:109} INFO - [2022-04-28 20:08:18,678] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:08:19,806] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:08:19,815] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:08:19,821] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:08:19,827] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:08:19,835] {logging_mixin.py:109} INFO - [2022-04-28 20:08:19,830] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:08:19,873] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:08:19,893] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.270 seconds
[2022-04-28 20:08:50,590] {processor.py:163} INFO - Started process (PID=2188) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:08:50,607] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:08:50,623] {logging_mixin.py:109} INFO - [2022-04-28 20:08:50,622] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:08:51,601] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:08:51,609] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:08:51,616] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:08:51,626] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:08:51,638] {logging_mixin.py:109} INFO - [2022-04-28 20:08:51,629] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:08:51,671] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:08:51,688] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.117 seconds
[2022-04-28 20:09:22,053] {processor.py:163} INFO - Started process (PID=2215) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:09:22,057] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:09:22,067] {logging_mixin.py:109} INFO - [2022-04-28 20:09:22,066] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:09:23,002] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:09:23,017] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:09:23,029] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:09:23,044] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:09:23,064] {logging_mixin.py:109} INFO - [2022-04-28 20:09:23,048] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:09:23,114] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:09:23,147] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.110 seconds
[2022-04-28 20:09:53,226] {processor.py:163} INFO - Started process (PID=2243) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:09:53,233] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:09:53,238] {logging_mixin.py:109} INFO - [2022-04-28 20:09:53,238] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:09:53,604] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:09:53,614] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:09:53,621] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:09:53,631] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:09:53,646] {logging_mixin.py:109} INFO - [2022-04-28 20:09:53,636] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:09:53,696] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:09:53,729] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.517 seconds
[2022-04-28 20:10:24,075] {processor.py:163} INFO - Started process (PID=2270) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:10:24,090] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:10:24,103] {logging_mixin.py:109} INFO - [2022-04-28 20:10:24,103] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:10:24,975] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:10:24,993] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:10:25,005] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:10:25,022] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:10:25,046] {logging_mixin.py:109} INFO - [2022-04-28 20:10:25,026] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:10:25,088] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:10:25,111] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.057 seconds
[2022-04-28 20:10:55,521] {processor.py:163} INFO - Started process (PID=2295) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:10:55,528] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:10:55,534] {logging_mixin.py:109} INFO - [2022-04-28 20:10:55,534] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:10:56,714] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:10:56,736] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:10:56,747] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:10:56,771] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:10:56,802] {logging_mixin.py:109} INFO - [2022-04-28 20:10:56,778] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:10:56,874] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:10:56,989] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.492 seconds
[2022-04-28 20:11:27,178] {processor.py:163} INFO - Started process (PID=2322) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:11:27,182] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:11:27,185] {logging_mixin.py:109} INFO - [2022-04-28 20:11:27,185] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:11:27,529] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:11:27,533] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:11:27,536] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:11:27,541] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:11:27,549] {logging_mixin.py:109} INFO - [2022-04-28 20:11:27,543] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:11:27,575] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:11:27,597] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.425 seconds
[2022-04-28 20:11:57,736] {processor.py:163} INFO - Started process (PID=2350) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:11:57,742] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:11:57,745] {logging_mixin.py:109} INFO - [2022-04-28 20:11:57,745] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:11:58,251] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:11:58,260] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:11:58,271] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:11:58,280] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:11:58,300] {logging_mixin.py:109} INFO - [2022-04-28 20:11:58,287] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:11:58,336] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:11:58,362] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.637 seconds
[2022-04-28 20:12:29,034] {processor.py:163} INFO - Started process (PID=2376) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:12:29,040] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:12:29,045] {logging_mixin.py:109} INFO - [2022-04-28 20:12:29,044] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:12:30,314] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:12:30,331] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:12:30,344] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:12:30,359] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:12:30,379] {logging_mixin.py:109} INFO - [2022-04-28 20:12:30,367] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:12:30,428] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:12:30,453] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.430 seconds
[2022-04-28 20:13:00,747] {processor.py:163} INFO - Started process (PID=2410) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:13:00,750] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:13:00,754] {logging_mixin.py:109} INFO - [2022-04-28 20:13:00,754] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:13:01,114] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:13:01,121] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:13:01,125] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:13:01,133] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:13:01,145] {logging_mixin.py:109} INFO - [2022-04-28 20:13:01,136] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:13:01,187] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:13:01,208] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.472 seconds
[2022-04-28 20:13:31,843] {processor.py:163} INFO - Started process (PID=2434) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:13:31,848] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:13:31,853] {logging_mixin.py:109} INFO - [2022-04-28 20:13:31,853] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:13:35,068] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:13:35,086] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:13:35,114] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:13:35,172] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:13:35,211] {logging_mixin.py:109} INFO - [2022-04-28 20:13:35,180] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:13:35,382] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:13:35,615] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.787 seconds
[2022-04-28 20:14:05,858] {processor.py:163} INFO - Started process (PID=2456) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:14:05,880] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:14:05,884] {logging_mixin.py:109} INFO - [2022-04-28 20:14:05,883] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:14:06,731] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:14:06,736] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:14:06,740] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:14:06,745] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:14:06,752] {logging_mixin.py:109} INFO - [2022-04-28 20:14:06,747] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:14:06,780] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:14:06,793] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.949 seconds
[2022-04-28 20:14:37,121] {processor.py:163} INFO - Started process (PID=2483) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:14:37,128] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:14:37,132] {logging_mixin.py:109} INFO - [2022-04-28 20:14:37,131] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:14:37,520] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:14:37,525] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:14:37,532] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:14:37,540] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:14:37,552] {logging_mixin.py:109} INFO - [2022-04-28 20:14:37,544] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:14:37,596] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:14:37,611] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.500 seconds
[2022-04-28 20:15:07,733] {processor.py:163} INFO - Started process (PID=2511) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:15:07,736] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:15:07,740] {logging_mixin.py:109} INFO - [2022-04-28 20:15:07,739] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:15:08,128] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:15:08,137] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:15:08,145] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:15:08,157] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:15:08,169] {logging_mixin.py:109} INFO - [2022-04-28 20:15:08,160] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:15:08,199] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:15:08,222] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.499 seconds
[2022-04-28 20:15:38,591] {processor.py:163} INFO - Started process (PID=2538) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:15:38,594] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:15:38,597] {logging_mixin.py:109} INFO - [2022-04-28 20:15:38,596] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:15:38,902] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:15:38,906] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:15:38,910] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:15:38,914] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:15:38,920] {logging_mixin.py:109} INFO - [2022-04-28 20:15:38,916] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:15:38,948] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:15:38,969] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.386 seconds
[2022-04-28 20:16:09,645] {processor.py:163} INFO - Started process (PID=2569) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:16:09,658] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:16:09,669] {logging_mixin.py:109} INFO - [2022-04-28 20:16:09,669] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:16:10,407] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:16:10,429] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:16:10,439] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:16:10,460] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:16:10,479] {logging_mixin.py:109} INFO - [2022-04-28 20:16:10,463] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:16:10,535] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:16:10,565] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.935 seconds
[2022-04-28 20:16:40,915] {processor.py:163} INFO - Started process (PID=2591) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:16:40,952] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:16:41,079] {logging_mixin.py:109} INFO - [2022-04-28 20:16:40,979] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:16:44,230] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:16:44,259] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:16:44,271] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:16:44,301] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:16:44,322] {logging_mixin.py:109} INFO - [2022-04-28 20:16:44,306] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:16:44,415] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:16:44,504] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.662 seconds
[2022-04-28 20:17:14,745] {processor.py:163} INFO - Started process (PID=2608) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:17:14,749] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:17:14,752] {logging_mixin.py:109} INFO - [2022-04-28 20:17:14,752] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:17:15,184] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:17:15,189] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:17:15,193] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:17:15,198] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:17:15,209] {logging_mixin.py:109} INFO - [2022-04-28 20:17:15,201] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:17:15,249] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:17:15,267] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.529 seconds
[2022-04-28 20:17:46,203] {processor.py:163} INFO - Started process (PID=2634) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:17:46,211] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:17:46,226] {logging_mixin.py:109} INFO - [2022-04-28 20:17:46,225] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:17:48,507] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:17:48,530] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:17:48,549] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:17:48,569] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:17:48,596] {logging_mixin.py:109} INFO - [2022-04-28 20:17:48,576] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:17:48,694] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:17:48,722] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.554 seconds
[2022-04-28 20:18:19,117] {processor.py:163} INFO - Started process (PID=2659) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:18:19,125] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:18:19,135] {logging_mixin.py:109} INFO - [2022-04-28 20:18:19,135] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:18:20,391] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:18:20,397] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:18:20,405] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:18:20,413] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:18:20,428] {logging_mixin.py:109} INFO - [2022-04-28 20:18:20,417] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:18:20,473] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:18:20,505] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.414 seconds
[2022-04-28 20:18:50,757] {processor.py:163} INFO - Started process (PID=2684) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:18:50,764] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:18:50,770] {logging_mixin.py:109} INFO - [2022-04-28 20:18:50,769] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:18:51,336] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:18:51,341] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:18:51,344] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:18:51,349] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:18:51,356] {logging_mixin.py:109} INFO - [2022-04-28 20:18:51,351] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:18:51,392] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:18:51,470] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.727 seconds
[2022-04-28 20:19:21,755] {processor.py:163} INFO - Started process (PID=2713) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:19:21,764] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:19:21,767] {logging_mixin.py:109} INFO - [2022-04-28 20:19:21,767] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:19:22,099] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:19:22,103] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:19:22,106] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:19:22,110] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:19:22,116] {logging_mixin.py:109} INFO - [2022-04-28 20:19:22,112] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:19:22,144] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:19:22,163] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.439 seconds
[2022-04-28 20:19:52,515] {processor.py:163} INFO - Started process (PID=2741) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:19:52,521] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:19:52,529] {logging_mixin.py:109} INFO - [2022-04-28 20:19:52,529] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:19:53,194] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:19:53,199] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:19:53,206] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:19:53,216] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:19:53,229] {logging_mixin.py:109} INFO - [2022-04-28 20:19:53,222] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:19:53,262] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:19:53,280] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.779 seconds
[2022-04-28 20:20:23,578] {processor.py:163} INFO - Started process (PID=2760) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:20:23,597] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:20:23,606] {logging_mixin.py:109} INFO - [2022-04-28 20:20:23,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:20:24,702] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:20:24,706] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:20:24,712] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:20:24,718] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:20:24,725] {logging_mixin.py:109} INFO - [2022-04-28 20:20:24,720] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:20:24,767] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:20:24,802] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.321 seconds
[2022-04-28 20:20:55,049] {processor.py:163} INFO - Started process (PID=2787) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:20:55,055] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:20:55,061] {logging_mixin.py:109} INFO - [2022-04-28 20:20:55,060] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:20:55,997] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:20:56,014] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:20:56,049] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:20:56,076] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:20:56,107] {logging_mixin.py:109} INFO - [2022-04-28 20:20:56,079] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:20:56,160] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:20:56,188] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.149 seconds
[2022-04-28 20:21:27,212] {processor.py:163} INFO - Started process (PID=2815) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:21:27,228] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:21:27,243] {logging_mixin.py:109} INFO - [2022-04-28 20:21:27,243] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:21:28,930] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:21:28,960] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:21:29,074] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:21:29,131] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:21:29,230] {logging_mixin.py:109} INFO - [2022-04-28 20:21:29,139] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:21:29,429] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:21:29,483] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.325 seconds
[2022-04-28 20:21:59,965] {processor.py:163} INFO - Started process (PID=2843) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:21:59,972] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:21:59,977] {logging_mixin.py:109} INFO - [2022-04-28 20:21:59,977] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:22:02,121] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:22:02,132] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:22:02,136] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:22:02,140] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:22:02,153] {logging_mixin.py:109} INFO - [2022-04-28 20:22:02,143] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:22:02,186] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:22:02,229] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.274 seconds
[2022-04-28 20:22:32,704] {processor.py:163} INFO - Started process (PID=2869) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:22:32,708] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:22:32,717] {logging_mixin.py:109} INFO - [2022-04-28 20:22:32,717] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:22:33,909] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:22:33,922] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:22:33,926] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:22:33,931] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:22:33,944] {logging_mixin.py:109} INFO - [2022-04-28 20:22:33,939] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:22:33,987] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:22:34,013] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.335 seconds
[2022-04-28 20:23:04,517] {processor.py:163} INFO - Started process (PID=2894) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:23:04,526] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:23:04,529] {logging_mixin.py:109} INFO - [2022-04-28 20:23:04,529] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:23:05,881] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:23:05,888] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:23:05,892] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:23:05,899] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:23:05,909] {logging_mixin.py:109} INFO - [2022-04-28 20:23:05,903] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:23:05,938] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:23:05,953] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.454 seconds
[2022-04-28 20:23:36,473] {processor.py:163} INFO - Started process (PID=2923) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:23:36,486] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:23:36,489] {logging_mixin.py:109} INFO - [2022-04-28 20:23:36,489] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:23:37,677] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:23:37,685] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:23:37,689] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:23:37,705] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:23:37,716] {logging_mixin.py:109} INFO - [2022-04-28 20:23:37,707] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:23:37,759] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:23:37,790] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.334 seconds
[2022-04-28 20:24:08,007] {processor.py:163} INFO - Started process (PID=2950) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:24:08,016] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:24:08,018] {logging_mixin.py:109} INFO - [2022-04-28 20:24:08,018] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:24:09,706] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:24:09,712] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:24:09,719] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:24:09,726] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:24:09,744] {logging_mixin.py:109} INFO - [2022-04-28 20:24:09,736] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:24:09,835] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:24:09,864] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.889 seconds
[2022-04-28 20:24:40,902] {processor.py:163} INFO - Started process (PID=2967) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:24:40,916] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:24:40,921] {logging_mixin.py:109} INFO - [2022-04-28 20:24:40,921] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:24:42,674] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:24:42,685] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:24:42,699] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:24:42,714] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:24:42,737] {logging_mixin.py:109} INFO - [2022-04-28 20:24:42,719] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:24:42,873] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:24:42,959] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.087 seconds
[2022-04-28 20:25:15,325] {processor.py:163} INFO - Started process (PID=2996) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:25:15,331] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:25:15,336] {logging_mixin.py:109} INFO - [2022-04-28 20:25:15,335] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:25:15,726] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:25:15,731] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:25:15,734] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:25:15,739] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:25:15,745] {logging_mixin.py:109} INFO - [2022-04-28 20:25:15,741] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:25:15,775] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:25:15,793] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.480 seconds
[2022-04-28 20:25:47,845] {processor.py:163} INFO - Started process (PID=3031) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:25:47,850] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:25:47,855] {logging_mixin.py:109} INFO - [2022-04-28 20:25:47,855] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:25:48,474] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:25:48,482] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:25:48,486] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:25:48,494] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:25:48,503] {logging_mixin.py:109} INFO - [2022-04-28 20:25:48,496] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:25:48,542] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:25:48,558] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.725 seconds
[2022-04-28 20:26:19,297] {processor.py:163} INFO - Started process (PID=3057) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:26:19,317] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:26:19,325] {logging_mixin.py:109} INFO - [2022-04-28 20:26:19,324] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:26:20,426] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:26:20,435] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:26:20,442] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:26:20,449] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:26:20,462] {logging_mixin.py:109} INFO - [2022-04-28 20:26:20,452] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:26:20,496] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:26:20,518] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.249 seconds
[2022-04-28 20:26:50,687] {processor.py:163} INFO - Started process (PID=3073) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:26:50,695] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-28 20:26:50,712] {logging_mixin.py:109} INFO - [2022-04-28 20:26:50,711] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:26:51,098] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-28 20:26:51,105] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-28 20:26:51,112] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-28 20:26:51,120] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-28 20:26:51,132] {logging_mixin.py:109} INFO - [2022-04-28 20:26:51,123] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-28 20:26:51,156] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-28 20:26:51,186] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.505 seconds
