[2022-04-29 01:58:12,143] {processor.py:163} INFO - Started process (PID=122) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:58:12,159] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 01:58:12,165] {logging_mixin.py:109} INFO - [2022-04-29 01:58:12,164] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:58:14,694] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 01:58:14,708] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 01:58:14,721] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 01:58:14,726] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 01:58:14,742] {logging_mixin.py:109} INFO - [2022-04-29 01:58:14,734] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 01:58:14,798] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:58:14,852] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.764 seconds
[2022-04-29 01:58:45,764] {processor.py:163} INFO - Started process (PID=148) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:58:45,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 01:58:45,771] {logging_mixin.py:109} INFO - [2022-04-29 01:58:45,770] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:58:46,196] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 01:58:46,199] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 01:58:46,202] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 01:58:46,206] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 01:58:46,212] {logging_mixin.py:109} INFO - [2022-04-29 01:58:46,207] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 01:58:46,232] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:58:46,244] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.485 seconds
[2022-04-29 01:59:16,565] {processor.py:163} INFO - Started process (PID=176) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:59:16,572] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 01:59:16,578] {logging_mixin.py:109} INFO - [2022-04-29 01:59:16,577] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:59:17,031] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 01:59:17,043] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 01:59:17,049] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 01:59:17,060] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 01:59:17,073] {logging_mixin.py:109} INFO - [2022-04-29 01:59:17,063] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 01:59:17,112] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:59:17,128] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.574 seconds
[2022-04-29 01:59:47,401] {processor.py:163} INFO - Started process (PID=216) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:59:47,415] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 01:59:47,418] {logging_mixin.py:109} INFO - [2022-04-29 01:59:47,418] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:59:48,466] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 01:59:48,473] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 01:59:48,479] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 01:59:48,487] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 01:59:48,498] {logging_mixin.py:109} INFO - [2022-04-29 01:59:48,491] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 01:59:48,546] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 01:59:48,580] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.184 seconds
[2022-04-29 02:00:18,960] {processor.py:163} INFO - Started process (PID=240) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:00:18,966] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:00:18,969] {logging_mixin.py:109} INFO - [2022-04-29 02:00:18,969] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:00:19,512] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:00:19,516] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:00:19,520] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:00:19,526] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:00:19,542] {logging_mixin.py:109} INFO - [2022-04-29 02:00:19,531] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:00:19,666] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:00:19,730] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.782 seconds
[2022-04-29 02:00:49,914] {processor.py:163} INFO - Started process (PID=267) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:00:49,917] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:00:49,920] {logging_mixin.py:109} INFO - [2022-04-29 02:00:49,919] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:00:50,533] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:00:50,537] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:00:50,541] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:00:50,545] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:00:50,550] {logging_mixin.py:109} INFO - [2022-04-29 02:00:50,546] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:00:50,571] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:00:50,583] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.684 seconds
[2022-04-29 02:01:21,362] {processor.py:163} INFO - Started process (PID=306) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:01:21,371] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:01:21,380] {logging_mixin.py:109} INFO - [2022-04-29 02:01:21,379] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:01:22,261] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:01:22,270] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:01:22,277] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:01:22,289] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:01:22,305] {logging_mixin.py:109} INFO - [2022-04-29 02:01:22,294] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:01:22,341] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:01:22,365] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.028 seconds
[2022-04-29 02:01:52,846] {processor.py:163} INFO - Started process (PID=333) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:01:52,857] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:01:52,861] {logging_mixin.py:109} INFO - [2022-04-29 02:01:52,861] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:01:54,279] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:01:54,296] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:01:54,311] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:01:54,329] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:01:54,341] {logging_mixin.py:109} INFO - [2022-04-29 02:01:54,332] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:01:54,420] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:01:54,491] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.683 seconds
[2022-04-29 02:02:25,530] {processor.py:163} INFO - Started process (PID=361) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:02:25,538] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:02:25,546] {logging_mixin.py:109} INFO - [2022-04-29 02:02:25,545] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:02:26,247] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:02:26,253] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:02:26,256] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:02:26,261] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:02:26,270] {logging_mixin.py:109} INFO - [2022-04-29 02:02:26,263] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:02:26,303] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:02:26,319] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.804 seconds
[2022-04-29 02:02:56,793] {processor.py:163} INFO - Started process (PID=387) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:02:56,799] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:02:56,804] {logging_mixin.py:109} INFO - [2022-04-29 02:02:56,804] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:02:57,666] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:02:57,671] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:02:57,676] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:02:57,683] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:02:57,691] {logging_mixin.py:109} INFO - [2022-04-29 02:02:57,686] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:02:57,719] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:02:57,789] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.010 seconds
[2022-04-29 02:03:28,008] {processor.py:163} INFO - Started process (PID=406) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:03:28,028] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:03:28,047] {logging_mixin.py:109} INFO - [2022-04-29 02:03:28,047] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:03:29,183] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:03:29,187] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:03:29,191] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:03:29,195] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:03:29,202] {logging_mixin.py:109} INFO - [2022-04-29 02:03:29,197] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:03:29,234] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:03:29,259] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.261 seconds
[2022-04-29 02:03:59,455] {processor.py:163} INFO - Started process (PID=432) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:03:59,460] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:03:59,462] {logging_mixin.py:109} INFO - [2022-04-29 02:03:59,462] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:04:02,044] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:04:02,069] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:04:02,098] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:04:02,157] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:04:02,179] {logging_mixin.py:109} INFO - [2022-04-29 02:04:02,165] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:04:02,280] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:04:02,321] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.901 seconds
[2022-04-29 02:04:32,521] {processor.py:163} INFO - Started process (PID=458) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:04:32,527] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:04:32,529] {logging_mixin.py:109} INFO - [2022-04-29 02:04:32,529] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:04:34,212] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:04:34,216] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:04:34,220] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:04:34,227] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:04:34,245] {logging_mixin.py:109} INFO - [2022-04-29 02:04:34,230] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:04:34,334] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:04:34,396] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.885 seconds
[2022-04-29 02:05:05,310] {processor.py:163} INFO - Started process (PID=486) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:05:05,316] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:05:05,319] {logging_mixin.py:109} INFO - [2022-04-29 02:05:05,319] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:05:05,778] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:05:05,785] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:05:05,790] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:05:05,799] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:05:05,809] {logging_mixin.py:109} INFO - [2022-04-29 02:05:05,801] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:05:05,839] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:05:05,855] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.551 seconds
[2022-04-29 02:05:36,148] {processor.py:163} INFO - Started process (PID=514) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:05:36,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:05:36,154] {logging_mixin.py:109} INFO - [2022-04-29 02:05:36,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:05:36,612] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:05:36,615] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:05:36,618] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:05:36,622] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:05:36,628] {logging_mixin.py:109} INFO - [2022-04-29 02:05:36,623] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:05:36,653] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:05:36,670] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.527 seconds
[2022-04-29 02:06:07,162] {processor.py:163} INFO - Started process (PID=540) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:06:07,165] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:06:07,168] {logging_mixin.py:109} INFO - [2022-04-29 02:06:07,168] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:06:08,181] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:06:08,188] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:06:08,193] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:06:08,197] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:06:08,227] {logging_mixin.py:109} INFO - [2022-04-29 02:06:08,201] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:06:08,295] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:06:08,322] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.165 seconds
[2022-04-29 02:06:38,958] {processor.py:163} INFO - Started process (PID=577) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:06:38,964] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:06:38,969] {logging_mixin.py:109} INFO - [2022-04-29 02:06:38,968] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:06:39,725] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:06:39,739] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:06:39,753] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:06:39,782] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:06:39,808] {logging_mixin.py:109} INFO - [2022-04-29 02:06:39,789] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:06:39,878] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:06:39,911] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.965 seconds
[2022-04-29 02:07:10,802] {processor.py:163} INFO - Started process (PID=606) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:07:10,812] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:07:10,814] {logging_mixin.py:109} INFO - [2022-04-29 02:07:10,814] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:07:12,058] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:07:12,072] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:07:12,085] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:07:12,090] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:07:12,195] {logging_mixin.py:109} INFO - [2022-04-29 02:07:12,095] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:07:12,324] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:07:12,383] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.620 seconds
[2022-04-29 02:07:43,502] {processor.py:163} INFO - Started process (PID=634) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:07:43,508] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:07:43,512] {logging_mixin.py:109} INFO - [2022-04-29 02:07:43,512] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:07:44,672] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:07:44,681] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:07:44,686] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:07:44,696] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:07:44,730] {logging_mixin.py:109} INFO - [2022-04-29 02:07:44,703] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:07:44,865] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:07:44,984] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.498 seconds
[2022-04-29 02:08:15,493] {processor.py:163} INFO - Started process (PID=666) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:08:15,498] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:08:15,500] {logging_mixin.py:109} INFO - [2022-04-29 02:08:15,500] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:08:16,211] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:08:16,219] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:08:16,222] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:08:16,227] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:08:16,234] {logging_mixin.py:109} INFO - [2022-04-29 02:08:16,229] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:08:16,261] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:08:16,280] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.794 seconds
[2022-04-29 02:08:46,744] {processor.py:163} INFO - Started process (PID=694) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:08:46,752] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:08:46,759] {logging_mixin.py:109} INFO - [2022-04-29 02:08:46,757] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:08:47,399] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:08:47,403] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:08:47,406] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:08:47,411] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:08:47,417] {logging_mixin.py:109} INFO - [2022-04-29 02:08:47,412] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:08:47,438] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:08:47,451] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.717 seconds
[2022-04-29 02:09:17,831] {processor.py:163} INFO - Started process (PID=721) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:09:17,834] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:09:17,837] {logging_mixin.py:109} INFO - [2022-04-29 02:09:17,837] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:09:18,500] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:09:18,508] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:09:18,515] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:09:18,525] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:09:18,531] {logging_mixin.py:109} INFO - [2022-04-29 02:09:18,527] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:09:18,557] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:09:18,575] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.756 seconds
[2022-04-29 02:09:48,885] {processor.py:163} INFO - Started process (PID=750) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:09:48,895] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:09:48,899] {logging_mixin.py:109} INFO - [2022-04-29 02:09:48,898] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:09:49,777] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:09:49,794] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:09:49,808] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:09:49,822] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:09:49,839] {logging_mixin.py:109} INFO - [2022-04-29 02:09:49,825] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:09:49,887] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:09:49,914] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.035 seconds
[2022-04-29 02:10:20,732] {processor.py:163} INFO - Started process (PID=777) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:10:20,751] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:10:20,778] {logging_mixin.py:109} INFO - [2022-04-29 02:10:20,766] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:10:21,909] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:10:21,920] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:10:21,926] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:10:21,931] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:10:21,946] {logging_mixin.py:109} INFO - [2022-04-29 02:10:21,936] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:10:21,981] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:10:22,000] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.303 seconds
[2022-04-29 02:10:52,461] {processor.py:163} INFO - Started process (PID=803) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:10:52,468] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:10:52,473] {logging_mixin.py:109} INFO - [2022-04-29 02:10:52,471] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:10:53,242] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:10:53,253] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:10:53,256] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:10:53,262] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:10:53,270] {logging_mixin.py:109} INFO - [2022-04-29 02:10:53,266] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:10:53,296] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:10:53,312] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.863 seconds
[2022-04-29 02:11:23,803] {processor.py:163} INFO - Started process (PID=830) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:11:23,809] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:11:23,814] {logging_mixin.py:109} INFO - [2022-04-29 02:11:23,812] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:11:24,545] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:11:24,551] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:11:24,554] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:11:24,560] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:11:24,567] {logging_mixin.py:109} INFO - [2022-04-29 02:11:24,562] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:11:24,593] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:11:24,612] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.828 seconds
[2022-04-29 02:11:54,885] {processor.py:163} INFO - Started process (PID=855) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:11:54,895] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:11:54,908] {logging_mixin.py:109} INFO - [2022-04-29 02:11:54,907] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:11:57,210] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:11:57,220] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:11:57,229] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:11:57,241] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:11:57,260] {logging_mixin.py:109} INFO - [2022-04-29 02:11:57,247] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:11:57,332] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:11:57,405] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.572 seconds
[2022-04-29 02:12:28,154] {processor.py:163} INFO - Started process (PID=883) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:12:28,161] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:12:28,164] {logging_mixin.py:109} INFO - [2022-04-29 02:12:28,164] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:12:30,367] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:12:30,392] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:12:30,403] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:12:30,416] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:12:30,435] {logging_mixin.py:109} INFO - [2022-04-29 02:12:30,421] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:12:30,520] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:12:30,549] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.401 seconds
[2022-04-29 02:13:00,693] {processor.py:163} INFO - Started process (PID=901) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:13:00,697] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:13:00,700] {logging_mixin.py:109} INFO - [2022-04-29 02:13:00,700] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:13:01,943] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:13:01,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:13:01,976] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:13:02,003] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:13:02,021] {logging_mixin.py:109} INFO - [2022-04-29 02:13:02,005] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:13:02,088] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:13:02,120] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.432 seconds
[2022-04-29 02:13:32,866] {processor.py:163} INFO - Started process (PID=928) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:13:32,871] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:13:32,876] {logging_mixin.py:109} INFO - [2022-04-29 02:13:32,875] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:13:34,893] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:13:34,906] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:13:34,920] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:13:34,945] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:13:34,969] {logging_mixin.py:109} INFO - [2022-04-29 02:13:34,951] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:13:35,011] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:13:35,045] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.208 seconds
[2022-04-29 02:14:05,907] {processor.py:163} INFO - Started process (PID=954) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:14:05,910] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:14:05,913] {logging_mixin.py:109} INFO - [2022-04-29 02:14:05,912] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:14:06,630] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:14:06,638] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:14:06,643] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:14:06,654] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:14:06,666] {logging_mixin.py:109} INFO - [2022-04-29 02:14:06,657] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:14:06,710] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:14:06,725] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.824 seconds
[2022-04-29 02:14:38,632] {processor.py:163} INFO - Started process (PID=983) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:14:38,640] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:14:38,643] {logging_mixin.py:109} INFO - [2022-04-29 02:14:38,642] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:14:41,684] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:14:41,699] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:14:41,712] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:14:41,746] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:14:41,773] {logging_mixin.py:109} INFO - [2022-04-29 02:14:41,757] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:14:41,813] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:14:41,841] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.295 seconds
[2022-04-29 02:15:12,240] {processor.py:163} INFO - Started process (PID=1009) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:15:12,243] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:15:12,245] {logging_mixin.py:109} INFO - [2022-04-29 02:15:12,245] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:15:14,667] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:15:14,678] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:15:14,686] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:15:14,700] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:15:14,715] {logging_mixin.py:109} INFO - [2022-04-29 02:15:14,703] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:15:14,787] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:15:14,843] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.619 seconds
[2022-04-29 02:15:45,060] {processor.py:163} INFO - Started process (PID=1037) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:15:45,066] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:15:45,071] {logging_mixin.py:109} INFO - [2022-04-29 02:15:45,071] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:15:45,776] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:15:45,782] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:15:45,791] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:15:45,807] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:15:45,825] {logging_mixin.py:109} INFO - [2022-04-29 02:15:45,811] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:15:45,857] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:15:45,880] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.827 seconds
[2022-04-29 02:16:16,213] {processor.py:163} INFO - Started process (PID=1064) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:16:16,237] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:16:16,246] {logging_mixin.py:109} INFO - [2022-04-29 02:16:16,244] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:16:18,643] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:16:18,665] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:16:18,716] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:16:18,736] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:16:18,761] {logging_mixin.py:109} INFO - [2022-04-29 02:16:18,744] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:16:18,925] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:16:18,990] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.796 seconds
[2022-04-29 02:16:49,704] {processor.py:163} INFO - Started process (PID=1082) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:16:49,718] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:16:49,730] {logging_mixin.py:109} INFO - [2022-04-29 02:16:49,728] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:16:55,450] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:16:55,464] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:16:55,477] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:16:55,501] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:16:55,534] {logging_mixin.py:109} INFO - [2022-04-29 02:16:55,513] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:16:55,667] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:16:55,714] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 6.033 seconds
[2022-04-29 02:17:27,411] {processor.py:163} INFO - Started process (PID=1108) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:17:27,429] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:17:27,446] {logging_mixin.py:109} INFO - [2022-04-29 02:17:27,445] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:17:30,320] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:17:30,376] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:17:30,410] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:17:30,453] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:17:30,521] {logging_mixin.py:109} INFO - [2022-04-29 02:17:30,479] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:17:30,869] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:17:30,984] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.749 seconds
[2022-04-29 02:18:02,371] {processor.py:163} INFO - Started process (PID=1134) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:18:02,416] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:18:02,426] {logging_mixin.py:109} INFO - [2022-04-29 02:18:02,426] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:18:08,653] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:18:08,715] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:18:08,742] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:18:08,766] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:18:08,900] {logging_mixin.py:109} INFO - [2022-04-29 02:18:08,783] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:18:09,214] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:18:09,489] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 7.264 seconds
[2022-04-29 02:18:48,700] {processor.py:163} INFO - Started process (PID=1161) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:18:48,727] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:18:48,754] {logging_mixin.py:109} INFO - [2022-04-29 02:18:48,754] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:18:55,949] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:18:56,026] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:18:56,060] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:18:56,108] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:18:56,185] {logging_mixin.py:109} INFO - [2022-04-29 02:18:56,128] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:18:56,366] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:18:56,456] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 7.892 seconds
[2022-04-29 02:19:26,956] {processor.py:163} INFO - Started process (PID=1188) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:19:26,970] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:19:26,982] {logging_mixin.py:109} INFO - [2022-04-29 02:19:26,982] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:19:29,279] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:19:29,284] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:19:29,290] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:19:29,305] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:19:29,319] {logging_mixin.py:109} INFO - [2022-04-29 02:19:29,308] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:19:29,355] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:19:29,379] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.447 seconds
[2022-04-29 02:19:59,753] {processor.py:163} INFO - Started process (PID=1220) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:19:59,780] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:19:59,806] {logging_mixin.py:109} INFO - [2022-04-29 02:19:59,805] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:20:01,795] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:20:01,810] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:20:01,823] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:20:01,840] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:20:01,855] {logging_mixin.py:109} INFO - [2022-04-29 02:20:01,844] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:20:01,914] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:20:01,957] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.236 seconds
[2022-04-29 02:20:33,202] {processor.py:163} INFO - Started process (PID=1239) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:20:33,225] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:20:33,238] {logging_mixin.py:109} INFO - [2022-04-29 02:20:33,238] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:20:36,939] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:20:36,952] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:20:36,969] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:20:36,978] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:20:36,990] {logging_mixin.py:109} INFO - [2022-04-29 02:20:36,985] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:20:37,039] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:20:37,085] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.022 seconds
[2022-04-29 02:21:09,387] {processor.py:163} INFO - Started process (PID=1264) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:21:09,412] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:21:09,416] {logging_mixin.py:109} INFO - [2022-04-29 02:21:09,415] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:21:14,530] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:21:14,548] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:21:14,585] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:21:14,615] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:21:14,685] {logging_mixin.py:109} INFO - [2022-04-29 02:21:14,639] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:21:14,823] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:21:14,898] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 5.598 seconds
[2022-04-29 02:21:45,159] {processor.py:163} INFO - Started process (PID=1287) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:21:45,163] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:21:45,166] {logging_mixin.py:109} INFO - [2022-04-29 02:21:45,165] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:21:46,011] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:21:46,015] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:21:46,019] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:21:46,024] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:21:46,031] {logging_mixin.py:109} INFO - [2022-04-29 02:21:46,027] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:21:46,065] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:21:46,082] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.931 seconds
[2022-04-29 02:22:16,437] {processor.py:163} INFO - Started process (PID=1315) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:22:16,443] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:22:16,448] {logging_mixin.py:109} INFO - [2022-04-29 02:22:16,447] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:22:18,892] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:22:18,895] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:22:18,910] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:22:18,937] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:22:18,970] {logging_mixin.py:109} INFO - [2022-04-29 02:22:18,938] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:22:19,053] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:22:19,108] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.690 seconds
[2022-04-29 02:22:49,758] {processor.py:163} INFO - Started process (PID=1343) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:22:49,773] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:22:49,779] {logging_mixin.py:109} INFO - [2022-04-29 02:22:49,778] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:22:51,748] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:22:51,767] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:22:51,788] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:22:51,810] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:22:51,869] {logging_mixin.py:109} INFO - [2022-04-29 02:22:51,815] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:22:51,977] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:22:52,024] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.275 seconds
[2022-04-29 02:23:22,342] {processor.py:163} INFO - Started process (PID=1371) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:23:22,354] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:23:22,365] {logging_mixin.py:109} INFO - [2022-04-29 02:23:22,362] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:23:24,083] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:23:24,092] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:23:24,119] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:23:24,136] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:23:24,166] {logging_mixin.py:109} INFO - [2022-04-29 02:23:24,145] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:23:24,215] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:23:24,239] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.920 seconds
[2022-04-29 02:23:54,328] {processor.py:163} INFO - Started process (PID=1398) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:23:54,332] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:23:54,334] {logging_mixin.py:109} INFO - [2022-04-29 02:23:54,333] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:23:55,843] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:23:55,863] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:23:55,875] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:23:55,891] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:23:55,904] {logging_mixin.py:109} INFO - [2022-04-29 02:23:55,894] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:23:55,934] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:23:55,948] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.633 seconds
[2022-04-29 02:24:26,199] {processor.py:163} INFO - Started process (PID=1425) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:24:26,210] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:24:26,229] {logging_mixin.py:109} INFO - [2022-04-29 02:24:26,228] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:24:26,808] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:24:26,812] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:24:26,818] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:24:26,828] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:24:26,841] {logging_mixin.py:109} INFO - [2022-04-29 02:24:26,831] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:24:26,880] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:24:26,899] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.714 seconds
[2022-04-29 02:24:57,483] {processor.py:163} INFO - Started process (PID=1453) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:24:57,487] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:24:57,489] {logging_mixin.py:109} INFO - [2022-04-29 02:24:57,489] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:24:57,942] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:24:57,955] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:24:57,960] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:24:57,964] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:24:57,970] {logging_mixin.py:109} INFO - [2022-04-29 02:24:57,966] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:24:57,994] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:24:58,015] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.538 seconds
[2022-04-29 02:25:28,244] {processor.py:163} INFO - Started process (PID=1480) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:25:28,249] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:25:28,251] {logging_mixin.py:109} INFO - [2022-04-29 02:25:28,251] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:25:28,736] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:25:28,739] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:25:28,742] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:25:28,747] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:25:28,756] {logging_mixin.py:109} INFO - [2022-04-29 02:25:28,749] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:25:28,836] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:25:28,861] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.624 seconds
[2022-04-29 02:25:59,114] {processor.py:163} INFO - Started process (PID=1517) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:25:59,121] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:25:59,125] {logging_mixin.py:109} INFO - [2022-04-29 02:25:59,125] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:25:59,793] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:25:59,801] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:25:59,806] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:25:59,814] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:25:59,825] {logging_mixin.py:109} INFO - [2022-04-29 02:25:59,817] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:25:59,865] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:25:59,881] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.773 seconds
[2022-04-29 02:26:30,224] {processor.py:163} INFO - Started process (PID=1544) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:26:30,228] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:26:30,231] {logging_mixin.py:109} INFO - [2022-04-29 02:26:30,230] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:26:30,905] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:26:30,909] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:26:30,912] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:26:30,917] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:26:30,924] {logging_mixin.py:109} INFO - [2022-04-29 02:26:30,920] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:26:30,952] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:26:30,974] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.755 seconds
[2022-04-29 02:27:01,120] {processor.py:163} INFO - Started process (PID=1570) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:27:01,131] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:27:01,135] {logging_mixin.py:109} INFO - [2022-04-29 02:27:01,135] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:27:03,470] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:27:03,490] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:27:03,517] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:27:03,535] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:27:03,553] {logging_mixin.py:109} INFO - [2022-04-29 02:27:03,538] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:27:03,591] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:27:03,635] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.528 seconds
[2022-04-29 02:27:34,138] {processor.py:163} INFO - Started process (PID=1597) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:27:34,161] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:27:34,169] {logging_mixin.py:109} INFO - [2022-04-29 02:27:34,168] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:27:38,213] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:27:38,220] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:27:38,233] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:27:38,244] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:27:38,253] {logging_mixin.py:109} INFO - [2022-04-29 02:27:38,246] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:27:38,305] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:27:38,346] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.236 seconds
[2022-04-29 02:28:09,356] {processor.py:163} INFO - Started process (PID=1628) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:28:09,360] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:28:09,366] {logging_mixin.py:109} INFO - [2022-04-29 02:28:09,365] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:28:10,554] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:28:10,559] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:28:10,562] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:28:10,570] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:28:10,578] {logging_mixin.py:109} INFO - [2022-04-29 02:28:10,572] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:28:10,607] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:28:10,633] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.293 seconds
[2022-04-29 02:28:40,868] {processor.py:163} INFO - Started process (PID=1646) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:28:40,876] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:28:40,879] {logging_mixin.py:109} INFO - [2022-04-29 02:28:40,879] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:28:43,076] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:28:43,102] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:28:43,123] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:28:43,129] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:28:43,153] {logging_mixin.py:109} INFO - [2022-04-29 02:28:43,137] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:28:43,199] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:28:43,224] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.404 seconds
[2022-04-29 02:29:14,179] {processor.py:163} INFO - Started process (PID=1673) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:29:14,203] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:29:14,219] {logging_mixin.py:109} INFO - [2022-04-29 02:29:14,218] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:29:15,202] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:29:15,220] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:29:15,234] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:29:15,248] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:29:15,278] {logging_mixin.py:109} INFO - [2022-04-29 02:29:15,259] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:29:15,327] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:29:15,344] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.175 seconds
[2022-04-29 02:29:46,247] {processor.py:163} INFO - Started process (PID=1699) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:29:46,306] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:29:46,356] {logging_mixin.py:109} INFO - [2022-04-29 02:29:46,356] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:29:47,814] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:29:47,836] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:29:47,844] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:29:47,857] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:29:47,866] {logging_mixin.py:109} INFO - [2022-04-29 02:29:47,860] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:29:47,930] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:29:47,971] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.776 seconds
[2022-04-29 02:30:21,781] {processor.py:163} INFO - Started process (PID=1728) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:30:21,793] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:30:21,803] {logging_mixin.py:109} INFO - [2022-04-29 02:30:21,803] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:30:23,579] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:30:23,591] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:30:23,596] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:30:23,609] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:30:23,629] {logging_mixin.py:109} INFO - [2022-04-29 02:30:23,614] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:30:23,709] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:30:23,740] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.976 seconds
[2022-04-29 02:30:59,391] {processor.py:163} INFO - Started process (PID=1754) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:30:59,404] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:30:59,435] {logging_mixin.py:109} INFO - [2022-04-29 02:30:59,433] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:31:01,930] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:31:01,945] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:31:01,952] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:31:01,966] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:31:01,984] {logging_mixin.py:109} INFO - [2022-04-29 02:31:01,969] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:31:02,043] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:31:02,069] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.704 seconds
[2022-04-29 02:31:37,975] {processor.py:163} INFO - Started process (PID=1781) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:31:37,980] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:31:37,994] {logging_mixin.py:109} INFO - [2022-04-29 02:31:37,994] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:31:40,437] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:31:40,459] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:31:40,470] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:31:40,477] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:31:40,495] {logging_mixin.py:109} INFO - [2022-04-29 02:31:40,480] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:31:40,555] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:31:40,600] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.699 seconds
[2022-04-29 02:32:12,229] {processor.py:163} INFO - Started process (PID=1810) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:32:12,238] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:32:12,249] {logging_mixin.py:109} INFO - [2022-04-29 02:32:12,249] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:32:14,496] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:32:14,510] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:32:14,523] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:32:14,529] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:32:14,558] {logging_mixin.py:109} INFO - [2022-04-29 02:32:14,539] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:32:14,780] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:32:14,995] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.828 seconds
[2022-04-29 02:32:49,033] {processor.py:163} INFO - Started process (PID=1838) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:32:49,042] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:32:49,055] {logging_mixin.py:109} INFO - [2022-04-29 02:32:49,051] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:32:50,127] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:32:50,137] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:32:50,145] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:32:50,159] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:32:50,181] {logging_mixin.py:109} INFO - [2022-04-29 02:32:50,163] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:32:50,240] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:32:50,283] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.270 seconds
[2022-04-29 02:33:27,186] {processor.py:163} INFO - Started process (PID=1865) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:33:27,203] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:33:27,207] {logging_mixin.py:109} INFO - [2022-04-29 02:33:27,207] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:33:29,396] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:33:29,416] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:33:29,429] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:33:29,437] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:33:29,449] {logging_mixin.py:109} INFO - [2022-04-29 02:33:29,440] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:33:29,515] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:33:29,543] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.369 seconds
[2022-04-29 02:34:26,447] {processor.py:163} INFO - Started process (PID=1898) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:34:26,475] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:34:26,531] {logging_mixin.py:109} INFO - [2022-04-29 02:34:26,531] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:34:36,708] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:34:36,724] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:34:36,746] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:34:36,813] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:34:36,865] {logging_mixin.py:109} INFO - [2022-04-29 02:34:36,833] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:34:37,146] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:34:37,279] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 12.355 seconds
[2022-04-29 02:35:11,290] {processor.py:163} INFO - Started process (PID=1926) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:35:11,308] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:35:11,319] {logging_mixin.py:109} INFO - [2022-04-29 02:35:11,316] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:35:14,216] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:35:14,244] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:35:14,269] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:35:14,292] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:35:14,329] {logging_mixin.py:109} INFO - [2022-04-29 02:35:14,308] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:35:14,543] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:35:14,668] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.388 seconds
[2022-04-29 02:35:45,288] {processor.py:163} INFO - Started process (PID=1953) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:35:45,298] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:35:45,301] {logging_mixin.py:109} INFO - [2022-04-29 02:35:45,301] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:35:46,281] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:35:46,292] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:35:46,309] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:35:46,315] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:35:46,329] {logging_mixin.py:109} INFO - [2022-04-29 02:35:46,323] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:35:46,412] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:35:46,463] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.184 seconds
[2022-04-29 02:36:16,804] {processor.py:163} INFO - Started process (PID=1980) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:36:16,824] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:36:16,841] {logging_mixin.py:109} INFO - [2022-04-29 02:36:16,840] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:36:18,065] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:36:18,117] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:36:18,125] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:36:18,142] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:36:18,171] {logging_mixin.py:109} INFO - [2022-04-29 02:36:18,157] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:36:18,225] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:36:18,255] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.469 seconds
[2022-04-29 02:36:48,859] {processor.py:163} INFO - Started process (PID=2006) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:36:48,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:36:48,873] {logging_mixin.py:109} INFO - [2022-04-29 02:36:48,873] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:36:50,294] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:36:50,298] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:36:50,302] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:36:50,308] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:36:50,322] {logging_mixin.py:109} INFO - [2022-04-29 02:36:50,311] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:36:50,347] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:36:50,366] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.524 seconds
[2022-04-29 02:37:22,976] {processor.py:163} INFO - Started process (PID=2032) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:37:23,002] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:37:23,013] {logging_mixin.py:109} INFO - [2022-04-29 02:37:23,013] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:37:25,051] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:37:25,066] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:37:25,090] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:37:25,097] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:37:25,127] {logging_mixin.py:109} INFO - [2022-04-29 02:37:25,099] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:37:25,183] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:37:25,220] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.272 seconds
[2022-04-29 02:37:55,923] {processor.py:163} INFO - Started process (PID=2058) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:37:55,952] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:37:55,976] {logging_mixin.py:109} INFO - [2022-04-29 02:37:55,976] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:37:59,430] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:37:59,451] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:37:59,458] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:37:59,481] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:37:59,499] {logging_mixin.py:109} INFO - [2022-04-29 02:37:59,486] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:37:59,583] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:37:59,645] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.781 seconds
[2022-04-29 02:38:30,218] {processor.py:163} INFO - Started process (PID=2087) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:38:30,231] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:38:30,235] {logging_mixin.py:109} INFO - [2022-04-29 02:38:30,235] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:38:30,799] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:38:30,804] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:38:30,811] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:38:30,823] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:38:30,831] {logging_mixin.py:109} INFO - [2022-04-29 02:38:30,826] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:38:30,872] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:38:30,906] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.700 seconds
[2022-04-29 02:39:01,033] {processor.py:163} INFO - Started process (PID=2116) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:39:01,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:39:01,041] {logging_mixin.py:109} INFO - [2022-04-29 02:39:01,041] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:39:01,460] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:39:01,475] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:39:01,493] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:39:01,507] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:39:01,527] {logging_mixin.py:109} INFO - [2022-04-29 02:39:01,510] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:39:01,581] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:39:01,632] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.609 seconds
[2022-04-29 02:39:32,500] {processor.py:163} INFO - Started process (PID=2151) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:39:32,514] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:39:32,529] {logging_mixin.py:109} INFO - [2022-04-29 02:39:32,529] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:39:35,051] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:39:35,058] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:39:35,064] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:39:35,070] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:39:35,086] {logging_mixin.py:109} INFO - [2022-04-29 02:39:35,080] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:39:35,190] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:39:35,240] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.804 seconds
[2022-04-29 02:40:08,816] {processor.py:163} INFO - Started process (PID=2171) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:40:08,826] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:40:08,835] {logging_mixin.py:109} INFO - [2022-04-29 02:40:08,835] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:40:13,693] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:40:13,756] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:40:13,790] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:40:13,855] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:40:13,917] {logging_mixin.py:109} INFO - [2022-04-29 02:40:13,866] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:40:14,284] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:40:14,390] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 5.632 seconds
[2022-04-29 02:40:45,277] {processor.py:163} INFO - Started process (PID=2197) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:40:45,298] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:40:45,303] {logging_mixin.py:109} INFO - [2022-04-29 02:40:45,303] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:40:46,367] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:40:46,372] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:40:46,377] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:40:46,389] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:40:46,412] {logging_mixin.py:109} INFO - [2022-04-29 02:40:46,392] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:40:46,557] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:40:46,605] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.481 seconds
[2022-04-29 02:41:16,890] {processor.py:163} INFO - Started process (PID=2225) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:41:16,900] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:41:16,906] {logging_mixin.py:109} INFO - [2022-04-29 02:41:16,905] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:41:17,279] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:41:17,288] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:41:17,294] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:41:17,303] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:41:17,316] {logging_mixin.py:109} INFO - [2022-04-29 02:41:17,305] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:41:17,353] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:41:17,378] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.499 seconds
[2022-04-29 02:41:48,264] {processor.py:163} INFO - Started process (PID=2249) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:41:48,273] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:41:48,327] {logging_mixin.py:109} INFO - [2022-04-29 02:41:48,318] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:41:52,911] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:41:53,727] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:41:53,794] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:41:53,987] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:41:54,047] {logging_mixin.py:109} INFO - [2022-04-29 02:41:53,992] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:41:54,559] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:41:54,690] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 6.499 seconds
[2022-04-29 02:42:25,208] {processor.py:163} INFO - Started process (PID=2274) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:42:25,233] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:42:25,247] {logging_mixin.py:109} INFO - [2022-04-29 02:42:25,247] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:42:26,702] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:42:26,718] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:42:26,733] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:42:26,740] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:42:26,751] {logging_mixin.py:109} INFO - [2022-04-29 02:42:26,746] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:42:26,806] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:42:26,839] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.677 seconds
[2022-04-29 02:42:57,104] {processor.py:163} INFO - Started process (PID=2293) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:42:57,109] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:42:57,113] {logging_mixin.py:109} INFO - [2022-04-29 02:42:57,113] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:42:57,634] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:42:57,645] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:42:57,649] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:42:57,657] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:42:57,676] {logging_mixin.py:109} INFO - [2022-04-29 02:42:57,663] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:42:57,725] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:42:57,750] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.661 seconds
[2022-04-29 02:43:28,071] {processor.py:163} INFO - Started process (PID=2320) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:43:28,085] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:43:28,088] {logging_mixin.py:109} INFO - [2022-04-29 02:43:28,088] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:43:29,544] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:43:29,552] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:43:29,561] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:43:29,569] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:43:29,577] {logging_mixin.py:109} INFO - [2022-04-29 02:43:29,571] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:43:29,627] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:43:29,644] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.600 seconds
[2022-04-29 02:44:00,606] {processor.py:163} INFO - Started process (PID=2346) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:44:00,621] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:44:00,624] {logging_mixin.py:109} INFO - [2022-04-29 02:44:00,624] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:44:01,372] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:44:01,384] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:44:01,400] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:44:01,416] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:44:01,430] {logging_mixin.py:109} INFO - [2022-04-29 02:44:01,420] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:44:01,472] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:44:01,493] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.908 seconds
[2022-04-29 02:44:31,887] {processor.py:163} INFO - Started process (PID=2372) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:44:31,895] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:44:31,905] {logging_mixin.py:109} INFO - [2022-04-29 02:44:31,904] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:44:32,699] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:44:32,705] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:44:32,708] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:44:32,712] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:44:32,722] {logging_mixin.py:109} INFO - [2022-04-29 02:44:32,714] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:44:32,749] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:44:32,767] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.895 seconds
[2022-04-29 02:45:03,696] {processor.py:163} INFO - Started process (PID=2398) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:45:03,789] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:45:03,842] {logging_mixin.py:109} INFO - [2022-04-29 02:45:03,841] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:45:06,378] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:45:06,385] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:45:06,396] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:45:06,408] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:45:06,425] {logging_mixin.py:109} INFO - [2022-04-29 02:45:06,412] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:45:06,492] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:45:06,536] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.877 seconds
[2022-04-29 02:45:37,023] {processor.py:163} INFO - Started process (PID=2415) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:45:37,027] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:45:37,032] {logging_mixin.py:109} INFO - [2022-04-29 02:45:37,031] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:45:41,112] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:45:41,125] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:45:41,160] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:45:41,235] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:45:41,372] {logging_mixin.py:109} INFO - [2022-04-29 02:45:41,283] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:45:41,502] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:45:41,887] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.919 seconds
[2022-04-29 02:46:12,914] {processor.py:163} INFO - Started process (PID=2441) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:46:12,919] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:46:12,923] {logging_mixin.py:109} INFO - [2022-04-29 02:46:12,923] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:46:13,401] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:46:13,406] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:46:13,410] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:46:13,418] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:46:13,434] {logging_mixin.py:109} INFO - [2022-04-29 02:46:13,424] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:46:13,481] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:46:13,514] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.605 seconds
[2022-04-29 02:46:44,272] {processor.py:163} INFO - Started process (PID=2470) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:46:44,283] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:46:44,288] {logging_mixin.py:109} INFO - [2022-04-29 02:46:44,288] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:46:45,338] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:46:45,346] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:46:45,359] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:46:45,367] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:46:45,385] {logging_mixin.py:109} INFO - [2022-04-29 02:46:45,375] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:46:45,443] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:46:45,464] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.247 seconds
[2022-04-29 02:47:15,743] {processor.py:163} INFO - Started process (PID=2497) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:47:15,759] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:47:15,779] {logging_mixin.py:109} INFO - [2022-04-29 02:47:15,779] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:47:16,566] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:47:16,572] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:47:16,582] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:47:16,595] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:47:16,609] {logging_mixin.py:109} INFO - [2022-04-29 02:47:16,597] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:47:16,667] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:47:16,692] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.026 seconds
[2022-04-29 02:47:47,183] {processor.py:163} INFO - Started process (PID=2525) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:47:47,195] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:47:47,205] {logging_mixin.py:109} INFO - [2022-04-29 02:47:47,203] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:47:47,781] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:47:47,786] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:47:47,793] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:47:47,800] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:47:47,815] {logging_mixin.py:109} INFO - [2022-04-29 02:47:47,804] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:47:47,856] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:47:47,877] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.713 seconds
[2022-04-29 02:48:18,697] {processor.py:163} INFO - Started process (PID=2553) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:48:18,703] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:48:18,709] {logging_mixin.py:109} INFO - [2022-04-29 02:48:18,708] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:48:20,125] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:48:20,135] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:48:20,140] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:48:20,150] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:48:20,166] {logging_mixin.py:109} INFO - [2022-04-29 02:48:20,158] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:48:20,194] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:48:20,208] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.534 seconds
[2022-04-29 02:48:50,464] {processor.py:163} INFO - Started process (PID=2584) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:48:50,472] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:48:50,477] {logging_mixin.py:109} INFO - [2022-04-29 02:48:50,477] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:48:51,350] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:48:51,364] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:48:51,378] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:48:51,389] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:48:51,409] {logging_mixin.py:109} INFO - [2022-04-29 02:48:51,394] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:48:51,621] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:48:51,689] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.231 seconds
[2022-04-29 02:49:22,626] {processor.py:163} INFO - Started process (PID=2609) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:49:22,637] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:49:22,642] {logging_mixin.py:109} INFO - [2022-04-29 02:49:22,642] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:49:27,713] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:49:27,758] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:49:27,774] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:49:27,806] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:49:27,832] {logging_mixin.py:109} INFO - [2022-04-29 02:49:27,811] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:49:27,865] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:49:27,885] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 5.292 seconds
[2022-04-29 02:49:58,200] {processor.py:163} INFO - Started process (PID=2629) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:49:58,206] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:49:58,226] {logging_mixin.py:109} INFO - [2022-04-29 02:49:58,226] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:49:58,925] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:49:58,939] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:49:58,950] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:49:58,961] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:49:58,973] {logging_mixin.py:109} INFO - [2022-04-29 02:49:58,964] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:49:59,019] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:49:59,047] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.912 seconds
[2022-04-29 02:50:29,462] {processor.py:163} INFO - Started process (PID=2656) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:50:29,469] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:50:29,473] {logging_mixin.py:109} INFO - [2022-04-29 02:50:29,473] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:50:30,829] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:50:30,842] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:50:30,851] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:50:30,863] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:50:30,881] {logging_mixin.py:109} INFO - [2022-04-29 02:50:30,870] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:50:30,956] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:50:31,006] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.566 seconds
[2022-04-29 02:51:03,641] {processor.py:163} INFO - Started process (PID=2681) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:51:03,647] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:51:03,652] {logging_mixin.py:109} INFO - [2022-04-29 02:51:03,651] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:51:04,416] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:51:04,431] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:51:04,445] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:51:04,466] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:51:04,489] {logging_mixin.py:109} INFO - [2022-04-29 02:51:04,470] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:51:04,543] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:51:04,569] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.942 seconds
[2022-04-29 02:51:37,167] {processor.py:163} INFO - Started process (PID=2708) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:51:37,172] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:51:37,175] {logging_mixin.py:109} INFO - [2022-04-29 02:51:37,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:51:37,828] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:51:37,834] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:51:37,841] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:51:37,852] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:51:37,864] {logging_mixin.py:109} INFO - [2022-04-29 02:51:37,856] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:51:37,894] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:51:37,918] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.756 seconds
[2022-04-29 02:52:19,386] {processor.py:163} INFO - Started process (PID=2734) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:52:19,455] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:52:19,473] {logging_mixin.py:109} INFO - [2022-04-29 02:52:19,472] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:52:22,858] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:52:22,872] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:52:22,884] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:52:22,903] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:52:22,920] {logging_mixin.py:109} INFO - [2022-04-29 02:52:22,910] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:52:23,024] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:52:23,099] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.779 seconds
[2022-04-29 02:52:53,673] {processor.py:163} INFO - Started process (PID=2763) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:52:53,678] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:52:53,685] {logging_mixin.py:109} INFO - [2022-04-29 02:52:53,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:52:54,411] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:52:54,440] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:52:54,451] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:52:54,486] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:52:54,532] {logging_mixin.py:109} INFO - [2022-04-29 02:52:54,494] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:52:54,618] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:52:54,682] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.025 seconds
[2022-04-29 02:53:25,183] {processor.py:163} INFO - Started process (PID=2790) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:53:25,186] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:53:25,199] {logging_mixin.py:109} INFO - [2022-04-29 02:53:25,198] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:53:25,751] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:53:25,755] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:53:25,759] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:53:25,770] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:53:25,781] {logging_mixin.py:109} INFO - [2022-04-29 02:53:25,773] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:53:25,812] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:53:25,830] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.654 seconds
[2022-04-29 02:53:56,436] {processor.py:163} INFO - Started process (PID=2816) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:53:56,439] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:53:56,443] {logging_mixin.py:109} INFO - [2022-04-29 02:53:56,443] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:53:57,636] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:53:57,648] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:53:57,668] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:53:57,686] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:53:57,726] {logging_mixin.py:109} INFO - [2022-04-29 02:53:57,702] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:53:57,781] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:53:57,804] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.374 seconds
[2022-04-29 02:54:30,807] {processor.py:163} INFO - Started process (PID=2842) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:54:30,821] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:54:30,826] {logging_mixin.py:109} INFO - [2022-04-29 02:54:30,825] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:54:32,080] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:54:32,091] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:54:32,099] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:54:32,120] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:54:32,149] {logging_mixin.py:109} INFO - [2022-04-29 02:54:32,126] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:54:32,328] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:54:32,371] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.582 seconds
[2022-04-29 02:55:07,372] {processor.py:163} INFO - Started process (PID=2869) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:55:07,401] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:55:07,429] {logging_mixin.py:109} INFO - [2022-04-29 02:55:07,428] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:55:08,711] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:55:08,752] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:55:08,771] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:55:08,823] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:55:08,844] {logging_mixin.py:109} INFO - [2022-04-29 02:55:08,831] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:55:08,937] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:55:09,078] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.765 seconds
[2022-04-29 02:55:43,095] {processor.py:163} INFO - Started process (PID=2895) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:55:43,104] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:55:43,116] {logging_mixin.py:109} INFO - [2022-04-29 02:55:43,109] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:55:44,059] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:55:44,116] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:55:44,121] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:55:44,143] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:55:44,167] {logging_mixin.py:109} INFO - [2022-04-29 02:55:44,153] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:55:44,284] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:55:44,338] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.252 seconds
[2022-04-29 02:56:16,800] {processor.py:163} INFO - Started process (PID=2920) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:56:16,815] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:56:16,829] {logging_mixin.py:109} INFO - [2022-04-29 02:56:16,829] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:56:19,017] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:56:19,021] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:56:19,027] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:56:19,037] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:56:19,050] {logging_mixin.py:109} INFO - [2022-04-29 02:56:19,039] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:56:19,082] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:56:19,109] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.336 seconds
[2022-04-29 02:56:49,844] {processor.py:163} INFO - Started process (PID=2947) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:56:49,849] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:56:49,853] {logging_mixin.py:109} INFO - [2022-04-29 02:56:49,852] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:56:50,460] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:56:50,466] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:56:50,470] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:56:50,474] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:56:50,486] {logging_mixin.py:109} INFO - [2022-04-29 02:56:50,476] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:56:50,517] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:56:50,535] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.710 seconds
[2022-04-29 02:57:20,893] {processor.py:163} INFO - Started process (PID=2973) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:57:20,897] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:57:20,900] {logging_mixin.py:109} INFO - [2022-04-29 02:57:20,899] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:57:21,439] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:57:21,451] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:57:21,465] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:57:21,485] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:57:21,516] {logging_mixin.py:109} INFO - [2022-04-29 02:57:21,500] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:57:21,551] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:57:21,573] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.687 seconds
[2022-04-29 02:57:52,618] {processor.py:163} INFO - Started process (PID=2997) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:57:52,648] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:57:52,669] {logging_mixin.py:109} INFO - [2022-04-29 02:57:52,668] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:58:00,923] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:58:00,930] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:58:00,946] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:58:00,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:58:00,997] {logging_mixin.py:109} INFO - [2022-04-29 02:58:00,977] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:58:01,161] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:58:01,273] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 8.767 seconds
[2022-04-29 02:58:31,633] {processor.py:163} INFO - Started process (PID=3024) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:58:31,639] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:58:31,649] {logging_mixin.py:109} INFO - [2022-04-29 02:58:31,649] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:58:32,688] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:58:32,694] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:58:32,706] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:58:32,714] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:58:32,726] {logging_mixin.py:109} INFO - [2022-04-29 02:58:32,720] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:58:32,758] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:58:32,778] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.159 seconds
[2022-04-29 02:59:03,257] {processor.py:163} INFO - Started process (PID=3053) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:59:03,263] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:59:03,271] {logging_mixin.py:109} INFO - [2022-04-29 02:59:03,271] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:59:04,487] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:59:04,512] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:59:04,534] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:59:04,563] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:59:04,597] {logging_mixin.py:109} INFO - [2022-04-29 02:59:04,583] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:59:04,703] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:59:04,825] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.573 seconds
[2022-04-29 02:59:35,229] {processor.py:163} INFO - Started process (PID=3081) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:59:35,239] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 02:59:35,243] {logging_mixin.py:109} INFO - [2022-04-29 02:59:35,242] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:59:35,787] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 02:59:35,793] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 02:59:35,805] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 02:59:35,818] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 02:59:35,830] {logging_mixin.py:109} INFO - [2022-04-29 02:59:35,822] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 02:59:35,904] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 02:59:35,940] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.730 seconds
[2022-04-29 03:00:06,259] {processor.py:163} INFO - Started process (PID=3110) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:00:06,265] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:00:06,271] {logging_mixin.py:109} INFO - [2022-04-29 03:00:06,270] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:00:06,862] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:00:06,871] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:00:06,877] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:00:06,887] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:00:06,903] {logging_mixin.py:109} INFO - [2022-04-29 03:00:06,890] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:00:06,951] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:00:06,971] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.718 seconds
[2022-04-29 03:00:37,454] {processor.py:163} INFO - Started process (PID=3138) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:00:37,459] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:00:37,465] {logging_mixin.py:109} INFO - [2022-04-29 03:00:37,464] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:00:38,193] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:00:38,201] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:00:38,205] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:00:38,214] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:00:38,236] {logging_mixin.py:109} INFO - [2022-04-29 03:00:38,223] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:00:38,284] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:00:38,308] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.873 seconds
[2022-04-29 03:01:08,775] {processor.py:163} INFO - Started process (PID=3166) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:01:08,783] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:01:08,786] {logging_mixin.py:109} INFO - [2022-04-29 03:01:08,786] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:01:10,275] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:01:10,300] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:01:10,311] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:01:10,333] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:01:10,362] {logging_mixin.py:109} INFO - [2022-04-29 03:01:10,342] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:01:10,405] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:01:10,437] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.727 seconds
[2022-04-29 03:01:40,571] {processor.py:163} INFO - Started process (PID=3183) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:01:40,576] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:01:40,578] {logging_mixin.py:109} INFO - [2022-04-29 03:01:40,578] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:01:41,066] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:01:41,073] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:01:41,076] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:01:41,081] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:01:41,097] {logging_mixin.py:109} INFO - [2022-04-29 03:01:41,083] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:01:41,200] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:01:41,241] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.676 seconds
[2022-04-29 03:02:11,616] {processor.py:163} INFO - Started process (PID=3211) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:02:11,622] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:02:11,625] {logging_mixin.py:109} INFO - [2022-04-29 03:02:11,625] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:02:12,206] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:02:12,213] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:02:12,220] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:02:12,232] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:02:12,249] {logging_mixin.py:109} INFO - [2022-04-29 03:02:12,235] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:02:12,281] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:02:12,302] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.694 seconds
[2022-04-29 03:02:42,757] {processor.py:163} INFO - Started process (PID=3240) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:02:42,770] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:02:42,780] {logging_mixin.py:109} INFO - [2022-04-29 03:02:42,780] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:02:44,836] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:02:44,849] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:02:44,870] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:02:44,896] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:02:44,929] {logging_mixin.py:109} INFO - [2022-04-29 03:02:44,905] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:02:45,062] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:02:45,148] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.406 seconds
[2022-04-29 03:03:15,950] {processor.py:163} INFO - Started process (PID=3253) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:03:15,959] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:03:15,968] {logging_mixin.py:109} INFO - [2022-04-29 03:03:15,968] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:03:17,861] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:03:17,905] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:03:17,913] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:03:17,938] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:03:18,024] {logging_mixin.py:109} INFO - [2022-04-29 03:03:17,959] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:03:18,235] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:03:18,349] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.426 seconds
[2022-04-29 03:03:49,170] {processor.py:163} INFO - Started process (PID=3279) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:03:49,207] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:03:49,217] {logging_mixin.py:109} INFO - [2022-04-29 03:03:49,217] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:03:52,678] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:03:52,723] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:03:52,736] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:03:52,769] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:03:52,804] {logging_mixin.py:109} INFO - [2022-04-29 03:03:52,778] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:03:52,909] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:03:52,980] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.847 seconds
[2022-04-29 03:04:23,336] {processor.py:163} INFO - Started process (PID=3303) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:04:23,340] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:04:23,345] {logging_mixin.py:109} INFO - [2022-04-29 03:04:23,345] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:04:23,732] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:04:23,736] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:04:23,741] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:04:23,745] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:04:23,753] {logging_mixin.py:109} INFO - [2022-04-29 03:04:23,748] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:04:23,783] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:04:23,806] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.477 seconds
[2022-04-29 03:04:53,869] {processor.py:163} INFO - Started process (PID=3330) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:04:53,873] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:04:53,875] {logging_mixin.py:109} INFO - [2022-04-29 03:04:53,875] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:04:54,265] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:04:54,272] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:04:54,277] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:04:54,283] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:04:54,297] {logging_mixin.py:109} INFO - [2022-04-29 03:04:54,285] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:04:54,333] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:04:54,349] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.488 seconds
[2022-04-29 03:05:24,554] {processor.py:163} INFO - Started process (PID=3358) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:05:24,558] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:05:24,560] {logging_mixin.py:109} INFO - [2022-04-29 03:05:24,560] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:05:25,347] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:05:25,365] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:05:25,373] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:05:25,415] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:05:25,559] {logging_mixin.py:109} INFO - [2022-04-29 03:05:25,548] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:05:25,665] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:05:25,714] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.169 seconds
[2022-04-29 03:05:56,415] {processor.py:163} INFO - Started process (PID=3386) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:05:56,423] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:05:56,428] {logging_mixin.py:109} INFO - [2022-04-29 03:05:56,428] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:05:56,819] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:05:56,823] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:05:56,827] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:05:56,834] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:05:56,841] {logging_mixin.py:109} INFO - [2022-04-29 03:05:56,836] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:05:56,868] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:05:56,888] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.484 seconds
[2022-04-29 03:06:27,962] {processor.py:163} INFO - Started process (PID=3413) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:06:27,976] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:06:28,020] {logging_mixin.py:109} INFO - [2022-04-29 03:06:28,003] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:06:32,471] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:06:32,516] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:06:32,608] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:06:32,690] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:06:32,840] {logging_mixin.py:109} INFO - [2022-04-29 03:06:32,702] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:06:33,177] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:06:33,259] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 5.377 seconds
[2022-04-29 03:07:03,971] {processor.py:163} INFO - Started process (PID=3441) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:07:04,057] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:07:04,069] {logging_mixin.py:109} INFO - [2022-04-29 03:07:04,068] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:07:07,402] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:07:07,419] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:07:07,428] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:07:07,444] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:07:07,476] {logging_mixin.py:109} INFO - [2022-04-29 03:07:07,458] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:07:08,070] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:07:08,214] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.295 seconds
[2022-04-29 03:07:39,161] {processor.py:163} INFO - Started process (PID=3460) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:07:39,196] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:07:39,216] {logging_mixin.py:109} INFO - [2022-04-29 03:07:39,215] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:07:48,712] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:07:48,775] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:07:48,856] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:07:49,040] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:07:49,211] {logging_mixin.py:109} INFO - [2022-04-29 03:07:49,051] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:07:49,345] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:07:49,704] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 10.598 seconds
[2022-04-29 03:08:20,767] {processor.py:163} INFO - Started process (PID=3485) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:08:20,861] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:08:20,993] {logging_mixin.py:109} INFO - [2022-04-29 03:08:20,935] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:08:30,076] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:08:30,100] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:08:30,121] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:08:30,165] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:08:30,195] {logging_mixin.py:109} INFO - [2022-04-29 03:08:30,177] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:08:30,334] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:08:30,706] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 10.032 seconds
[2022-04-29 03:09:01,799] {processor.py:163} INFO - Started process (PID=3512) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:09:01,812] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:09:01,816] {logging_mixin.py:109} INFO - [2022-04-29 03:09:01,816] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:09:02,778] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:09:02,785] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:09:02,793] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:09:02,807] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:09:02,823] {logging_mixin.py:109} INFO - [2022-04-29 03:09:02,811] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:09:02,872] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:09:02,893] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.106 seconds
[2022-04-29 03:09:33,300] {processor.py:163} INFO - Started process (PID=3538) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:09:33,305] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:09:33,314] {logging_mixin.py:109} INFO - [2022-04-29 03:09:33,314] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:09:34,014] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:09:34,019] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:09:34,023] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:09:34,030] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:09:34,038] {logging_mixin.py:109} INFO - [2022-04-29 03:09:34,032] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:09:34,079] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:09:34,164] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.877 seconds
[2022-04-29 03:10:06,045] {processor.py:163} INFO - Started process (PID=3562) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:10:06,067] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:10:06,085] {logging_mixin.py:109} INFO - [2022-04-29 03:10:06,085] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:10:08,521] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:10:08,543] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:10:08,546] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:10:08,561] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:10:08,573] {logging_mixin.py:109} INFO - [2022-04-29 03:10:08,564] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:10:08,627] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:10:08,663] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.654 seconds
[2022-04-29 03:10:39,085] {processor.py:163} INFO - Started process (PID=3585) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:10:39,090] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:10:39,092] {logging_mixin.py:109} INFO - [2022-04-29 03:10:39,092] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:10:40,072] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:10:40,085] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:10:40,090] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:10:40,101] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:10:40,110] {logging_mixin.py:109} INFO - [2022-04-29 03:10:40,104] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:10:40,157] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:10:40,180] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.109 seconds
[2022-04-29 03:11:11,133] {processor.py:163} INFO - Started process (PID=3602) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:11:11,137] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:11:11,143] {logging_mixin.py:109} INFO - [2022-04-29 03:11:11,141] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:11:12,343] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:11:12,349] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:11:12,355] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:11:12,365] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:11:12,383] {logging_mixin.py:109} INFO - [2022-04-29 03:11:12,368] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:11:12,426] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:11:12,452] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.325 seconds
[2022-04-29 03:11:42,911] {processor.py:163} INFO - Started process (PID=3638) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:11:42,924] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:11:42,926] {logging_mixin.py:109} INFO - [2022-04-29 03:11:42,926] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:11:43,934] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:11:43,943] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:11:43,949] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:11:43,958] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:11:43,970] {logging_mixin.py:109} INFO - [2022-04-29 03:11:43,962] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:11:44,036] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:11:44,068] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.169 seconds
[2022-04-29 03:12:14,332] {processor.py:163} INFO - Started process (PID=3667) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:12:14,336] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:12:14,338] {logging_mixin.py:109} INFO - [2022-04-29 03:12:14,338] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:12:14,688] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:12:14,693] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:12:14,711] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:12:14,717] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:12:14,726] {logging_mixin.py:109} INFO - [2022-04-29 03:12:14,719] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:12:14,786] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:12:14,806] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.479 seconds
[2022-04-29 03:12:45,484] {processor.py:163} INFO - Started process (PID=3694) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:12:45,488] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:12:45,491] {logging_mixin.py:109} INFO - [2022-04-29 03:12:45,491] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:12:45,869] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:12:45,877] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:12:45,882] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:12:45,886] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:12:45,892] {logging_mixin.py:109} INFO - [2022-04-29 03:12:45,887] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:12:45,921] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:12:45,938] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.460 seconds
[2022-04-29 03:13:16,300] {processor.py:163} INFO - Started process (PID=3726) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:13:16,304] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:13:16,308] {logging_mixin.py:109} INFO - [2022-04-29 03:13:16,307] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:13:16,742] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:13:16,756] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:13:16,760] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:13:16,765] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:13:16,782] {logging_mixin.py:109} INFO - [2022-04-29 03:13:16,769] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:13:16,815] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:13:16,839] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.543 seconds
[2022-04-29 03:13:47,536] {processor.py:163} INFO - Started process (PID=3753) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:13:47,544] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:13:47,548] {logging_mixin.py:109} INFO - [2022-04-29 03:13:47,547] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:13:48,180] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:13:48,188] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:13:48,191] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:13:48,218] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:13:48,237] {logging_mixin.py:109} INFO - [2022-04-29 03:13:48,226] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:13:48,295] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:13:48,326] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.794 seconds
[2022-04-29 03:14:18,580] {processor.py:163} INFO - Started process (PID=3781) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:14:18,588] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:14:18,591] {logging_mixin.py:109} INFO - [2022-04-29 03:14:18,591] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:14:19,114] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:14:19,128] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:14:19,139] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:14:19,155] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:14:19,180] {logging_mixin.py:109} INFO - [2022-04-29 03:14:19,159] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:14:19,248] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:14:19,287] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.716 seconds
[2022-04-29 03:14:49,539] {processor.py:163} INFO - Started process (PID=3808) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:14:49,545] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:14:49,547] {logging_mixin.py:109} INFO - [2022-04-29 03:14:49,547] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:14:50,032] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:14:50,044] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:14:50,050] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:14:50,055] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:14:50,065] {logging_mixin.py:109} INFO - [2022-04-29 03:14:50,058] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:14:50,090] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:14:50,105] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.581 seconds
[2022-04-29 03:15:20,968] {processor.py:163} INFO - Started process (PID=3834) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:15:20,990] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:15:21,010] {logging_mixin.py:109} INFO - [2022-04-29 03:15:21,004] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:15:21,500] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:15:21,508] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:15:21,515] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:15:21,523] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:15:21,529] {logging_mixin.py:109} INFO - [2022-04-29 03:15:21,525] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:15:21,590] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:15:21,668] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.720 seconds
[2022-04-29 03:15:52,190] {processor.py:163} INFO - Started process (PID=3860) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:15:52,199] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:15:52,208] {logging_mixin.py:109} INFO - [2022-04-29 03:15:52,207] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:15:53,331] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:15:53,347] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:15:53,362] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:15:53,376] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:15:53,400] {logging_mixin.py:109} INFO - [2022-04-29 03:15:53,381] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:15:53,514] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:15:53,564] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.380 seconds
[2022-04-29 03:16:23,949] {processor.py:163} INFO - Started process (PID=3877) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:16:23,956] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:16:23,959] {logging_mixin.py:109} INFO - [2022-04-29 03:16:23,959] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:16:24,347] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:16:24,352] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:16:24,355] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:16:24,359] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:16:24,366] {logging_mixin.py:109} INFO - [2022-04-29 03:16:24,361] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:16:24,402] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:16:24,422] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.478 seconds
[2022-04-29 03:17:00,158] {processor.py:163} INFO - Started process (PID=3906) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:17:00,177] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:17:00,199] {logging_mixin.py:109} INFO - [2022-04-29 03:17:00,199] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:17:00,910] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:17:00,915] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:17:00,920] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:17:00,925] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:17:00,936] {logging_mixin.py:109} INFO - [2022-04-29 03:17:00,929] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:17:00,981] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:17:01,010] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.860 seconds
[2022-04-29 03:17:37,004] {processor.py:163} INFO - Started process (PID=3933) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:17:37,036] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:17:37,043] {logging_mixin.py:109} INFO - [2022-04-29 03:17:37,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:17:38,909] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:17:38,926] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:17:38,943] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:17:38,958] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:17:38,991] {logging_mixin.py:109} INFO - [2022-04-29 03:17:38,965] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:17:39,039] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:17:39,063] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.106 seconds
[2022-04-29 03:18:21,533] {processor.py:163} INFO - Started process (PID=3962) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:18:21,565] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:18:21,574] {logging_mixin.py:109} INFO - [2022-04-29 03:18:21,573] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:18:27,535] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:18:27,579] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:18:27,661] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:18:27,727] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:18:27,791] {logging_mixin.py:109} INFO - [2022-04-29 03:18:27,751] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:18:27,923] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:18:27,984] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 6.534 seconds
[2022-04-29 03:18:58,411] {processor.py:163} INFO - Started process (PID=3987) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:18:58,418] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:18:58,428] {logging_mixin.py:109} INFO - [2022-04-29 03:18:58,428] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:18:59,490] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:18:59,504] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:18:59,507] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:18:59,512] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:18:59,520] {logging_mixin.py:109} INFO - [2022-04-29 03:18:59,515] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:18:59,550] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:18:59,565] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.190 seconds
[2022-04-29 03:19:29,891] {processor.py:163} INFO - Started process (PID=4013) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:19:29,912] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:19:29,914] {logging_mixin.py:109} INFO - [2022-04-29 03:19:29,914] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:19:31,458] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:19:31,479] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:19:31,484] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:19:31,514] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:19:31,541] {logging_mixin.py:109} INFO - [2022-04-29 03:19:31,533] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:19:31,676] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:19:31,740] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.855 seconds
[2022-04-29 03:20:02,878] {processor.py:163} INFO - Started process (PID=4040) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:20:02,892] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:20:02,909] {logging_mixin.py:109} INFO - [2022-04-29 03:20:02,906] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:20:04,889] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:20:04,904] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:20:04,919] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:20:04,926] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:20:04,953] {logging_mixin.py:109} INFO - [2022-04-29 03:20:04,933] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:20:05,365] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:20:05,567] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.820 seconds
[2022-04-29 03:20:36,261] {processor.py:163} INFO - Started process (PID=4067) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:20:36,268] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:20:36,273] {logging_mixin.py:109} INFO - [2022-04-29 03:20:36,272] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:20:38,603] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:20:38,617] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:20:38,631] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:20:38,656] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:20:38,692] {logging_mixin.py:109} INFO - [2022-04-29 03:20:38,666] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:20:38,802] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:20:38,854] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.631 seconds
[2022-04-29 03:21:09,459] {processor.py:163} INFO - Started process (PID=4094) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:21:09,475] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:21:09,484] {logging_mixin.py:109} INFO - [2022-04-29 03:21:09,482] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:21:10,681] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:21:10,690] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:21:10,694] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:21:10,700] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:21:10,708] {logging_mixin.py:109} INFO - [2022-04-29 03:21:10,702] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:21:10,776] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:21:10,842] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.405 seconds
[2022-04-29 03:21:41,288] {processor.py:163} INFO - Started process (PID=4124) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:21:41,294] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:21:41,301] {logging_mixin.py:109} INFO - [2022-04-29 03:21:41,301] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:21:44,209] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:21:44,245] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:21:44,264] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:21:44,288] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:21:44,315] {logging_mixin.py:109} INFO - [2022-04-29 03:21:44,296] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:21:44,403] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:21:44,468] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.203 seconds
[2022-04-29 03:22:15,183] {processor.py:163} INFO - Started process (PID=4139) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:22:15,186] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:22:15,188] {logging_mixin.py:109} INFO - [2022-04-29 03:22:15,188] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:22:15,549] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:22:15,558] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:22:15,565] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:22:15,577] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:22:15,589] {logging_mixin.py:109} INFO - [2022-04-29 03:22:15,580] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:22:15,650] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:22:15,689] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.511 seconds
[2022-04-29 03:22:46,494] {processor.py:163} INFO - Started process (PID=4164) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:22:46,506] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:22:46,510] {logging_mixin.py:109} INFO - [2022-04-29 03:22:46,510] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:22:47,266] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:22:47,279] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:22:47,290] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:22:47,303] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:22:47,315] {logging_mixin.py:109} INFO - [2022-04-29 03:22:47,309] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:22:47,353] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:22:47,380] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.893 seconds
[2022-04-29 03:23:17,776] {processor.py:163} INFO - Started process (PID=4191) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:23:17,785] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:23:17,792] {logging_mixin.py:109} INFO - [2022-04-29 03:23:17,791] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:23:18,133] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:23:18,137] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:23:18,140] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:23:18,144] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:23:18,150] {logging_mixin.py:109} INFO - [2022-04-29 03:23:18,146] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:23:18,178] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:23:18,194] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.432 seconds
[2022-04-29 03:23:48,288] {processor.py:163} INFO - Started process (PID=4219) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:23:48,294] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:23:48,297] {logging_mixin.py:109} INFO - [2022-04-29 03:23:48,296] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:23:48,939] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:23:48,955] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:23:48,967] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:23:48,981] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:23:49,002] {logging_mixin.py:109} INFO - [2022-04-29 03:23:48,988] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:23:49,049] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:23:49,076] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.798 seconds
[2022-04-29 03:24:19,838] {processor.py:163} INFO - Started process (PID=4257) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:24:19,844] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:24:19,855] {logging_mixin.py:109} INFO - [2022-04-29 03:24:19,854] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:24:21,494] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:24:21,499] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:24:21,508] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:24:21,533] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:24:21,542] {logging_mixin.py:109} INFO - [2022-04-29 03:24:21,536] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:24:21,615] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:24:21,648] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.857 seconds
[2022-04-29 03:24:52,270] {processor.py:163} INFO - Started process (PID=4286) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:24:52,278] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:24:52,284] {logging_mixin.py:109} INFO - [2022-04-29 03:24:52,284] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:24:53,528] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:24:53,627] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:24:53,639] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:24:53,666] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:24:53,718] {logging_mixin.py:109} INFO - [2022-04-29 03:24:53,678] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:24:53,886] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:24:53,965] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.710 seconds
[2022-04-29 03:25:24,593] {processor.py:163} INFO - Started process (PID=4312) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:25:24,605] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:25:24,607] {logging_mixin.py:109} INFO - [2022-04-29 03:25:24,607] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:25:25,322] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:25:25,349] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:25:25,372] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:25:25,385] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:25:25,404] {logging_mixin.py:109} INFO - [2022-04-29 03:25:25,389] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:25:25,481] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:25:25,504] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.932 seconds
[2022-04-29 03:25:55,926] {processor.py:163} INFO - Started process (PID=4340) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:25:55,931] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:25:55,935] {logging_mixin.py:109} INFO - [2022-04-29 03:25:55,934] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:25:56,354] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:25:56,359] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:25:56,365] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:25:56,373] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:25:56,397] {logging_mixin.py:109} INFO - [2022-04-29 03:25:56,376] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:25:56,438] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:25:56,477] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.561 seconds
[2022-04-29 03:26:26,809] {processor.py:163} INFO - Started process (PID=4368) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:26:26,813] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:26:26,815] {logging_mixin.py:109} INFO - [2022-04-29 03:26:26,815] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:26:27,219] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:26:27,223] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:26:27,226] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:26:27,230] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:26:27,237] {logging_mixin.py:109} INFO - [2022-04-29 03:26:27,232] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:26:27,266] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:26:27,286] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.487 seconds
[2022-04-29 03:26:57,508] {processor.py:163} INFO - Started process (PID=4395) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:26:57,512] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:26:57,514] {logging_mixin.py:109} INFO - [2022-04-29 03:26:57,513] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:26:57,813] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:26:57,820] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:26:57,826] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:26:57,830] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:26:57,835] {logging_mixin.py:109} INFO - [2022-04-29 03:26:57,832] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:26:57,862] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:26:57,878] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.381 seconds
[2022-04-29 03:27:28,089] {processor.py:163} INFO - Started process (PID=4430) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:27:28,094] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:27:28,097] {logging_mixin.py:109} INFO - [2022-04-29 03:27:28,097] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:27:28,419] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:27:28,427] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:27:28,433] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:27:28,443] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:27:28,455] {logging_mixin.py:109} INFO - [2022-04-29 03:27:28,446] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:27:28,491] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:27:28,515] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.436 seconds
[2022-04-29 03:27:58,654] {processor.py:163} INFO - Started process (PID=4457) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:27:58,658] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:27:58,662] {logging_mixin.py:109} INFO - [2022-04-29 03:27:58,661] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:27:58,961] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:27:58,964] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:27:58,967] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:27:58,971] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:27:58,977] {logging_mixin.py:109} INFO - [2022-04-29 03:27:58,973] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:27:58,998] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:27:59,010] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.362 seconds
[2022-04-29 03:28:29,224] {processor.py:163} INFO - Started process (PID=4482) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:28:29,229] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:28:29,232] {logging_mixin.py:109} INFO - [2022-04-29 03:28:29,232] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:28:29,622] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:28:29,629] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:28:29,635] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:28:29,643] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:28:29,654] {logging_mixin.py:109} INFO - [2022-04-29 03:28:29,645] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:28:29,686] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:28:29,704] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.492 seconds
[2022-04-29 03:28:59,898] {processor.py:163} INFO - Started process (PID=4508) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:28:59,903] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:28:59,906] {logging_mixin.py:109} INFO - [2022-04-29 03:28:59,906] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:29:00,474] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:29:00,486] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:29:00,490] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:29:00,498] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:29:00,511] {logging_mixin.py:109} INFO - [2022-04-29 03:29:00,501] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:29:00,543] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:29:00,565] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.677 seconds
[2022-04-29 03:29:30,933] {processor.py:163} INFO - Started process (PID=4543) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:29:30,950] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:29:30,960] {logging_mixin.py:109} INFO - [2022-04-29 03:29:30,958] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:29:31,546] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:29:31,559] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:29:31,563] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:29:31,577] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:29:31,585] {logging_mixin.py:109} INFO - [2022-04-29 03:29:31,580] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:29:31,636] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:29:31,661] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.751 seconds
[2022-04-29 03:30:01,853] {processor.py:163} INFO - Started process (PID=4571) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:30:01,858] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:30:01,861] {logging_mixin.py:109} INFO - [2022-04-29 03:30:01,861] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:30:02,407] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:30:02,417] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:30:02,423] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:30:02,430] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:30:02,441] {logging_mixin.py:109} INFO - [2022-04-29 03:30:02,433] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:30:02,470] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:30:02,490] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.644 seconds
[2022-04-29 03:30:32,909] {processor.py:163} INFO - Started process (PID=4601) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:30:32,917] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:30:32,920] {logging_mixin.py:109} INFO - [2022-04-29 03:30:32,920] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:30:33,305] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:30:33,311] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:30:33,314] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:30:33,322] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:30:33,329] {logging_mixin.py:109} INFO - [2022-04-29 03:30:33,324] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:30:33,380] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:30:33,403] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.500 seconds
[2022-04-29 03:31:03,488] {processor.py:163} INFO - Started process (PID=4637) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:31:03,494] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:31:03,507] {logging_mixin.py:109} INFO - [2022-04-29 03:31:03,505] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:31:03,863] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:31:03,873] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:31:03,878] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:31:03,888] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:31:03,903] {logging_mixin.py:109} INFO - [2022-04-29 03:31:03,892] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:31:03,939] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:31:03,958] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.483 seconds
[2022-04-29 03:31:34,522] {processor.py:163} INFO - Started process (PID=4663) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:31:34,526] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:31:34,528] {logging_mixin.py:109} INFO - [2022-04-29 03:31:34,528] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:31:34,933] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:31:34,937] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:31:34,941] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:31:34,945] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:31:34,954] {logging_mixin.py:109} INFO - [2022-04-29 03:31:34,950] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:31:34,987] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:31:35,021] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.509 seconds
[2022-04-29 03:32:05,285] {processor.py:163} INFO - Started process (PID=4690) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:32:05,290] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:32:05,297] {logging_mixin.py:109} INFO - [2022-04-29 03:32:05,295] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:32:05,834] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:32:05,839] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:32:05,843] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:32:05,847] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:32:05,853] {logging_mixin.py:109} INFO - [2022-04-29 03:32:05,849] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:32:05,879] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:32:05,894] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.629 seconds
[2022-04-29 03:32:36,536] {processor.py:163} INFO - Started process (PID=4725) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:32:36,540] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:32:36,542] {logging_mixin.py:109} INFO - [2022-04-29 03:32:36,542] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:32:37,009] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:32:37,015] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:32:37,020] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:32:37,025] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:32:37,034] {logging_mixin.py:109} INFO - [2022-04-29 03:32:37,027] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:32:37,065] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:32:37,083] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.551 seconds
[2022-04-29 03:33:07,876] {processor.py:163} INFO - Started process (PID=4755) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:33:07,879] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:33:07,881] {logging_mixin.py:109} INFO - [2022-04-29 03:33:07,881] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:33:08,209] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:33:08,213] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:33:08,216] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:33:08,220] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:33:08,227] {logging_mixin.py:109} INFO - [2022-04-29 03:33:08,222] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:33:08,271] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:33:08,287] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.415 seconds
[2022-04-29 03:33:38,529] {processor.py:163} INFO - Started process (PID=4785) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:33:38,532] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:33:38,535] {logging_mixin.py:109} INFO - [2022-04-29 03:33:38,535] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:33:38,832] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:33:38,836] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:33:38,839] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:33:38,843] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:33:38,850] {logging_mixin.py:109} INFO - [2022-04-29 03:33:38,845] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:33:38,875] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:33:38,890] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.367 seconds
[2022-04-29 03:34:09,877] {processor.py:163} INFO - Started process (PID=4810) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:34:09,881] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:34:09,882] {logging_mixin.py:109} INFO - [2022-04-29 03:34:09,882] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:34:10,242] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:34:10,250] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:34:10,255] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:34:10,264] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:34:10,274] {logging_mixin.py:109} INFO - [2022-04-29 03:34:10,267] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:34:10,309] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:34:10,327] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.454 seconds
[2022-04-29 03:34:40,890] {processor.py:163} INFO - Started process (PID=4845) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:34:40,900] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:34:40,907] {logging_mixin.py:109} INFO - [2022-04-29 03:34:40,906] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:34:42,008] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:34:42,031] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:34:42,040] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:34:42,054] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:34:42,084] {logging_mixin.py:109} INFO - [2022-04-29 03:34:42,066] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:34:42,151] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:34:42,194] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.325 seconds
[2022-04-29 03:35:12,461] {processor.py:163} INFO - Started process (PID=4871) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:35:12,469] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:35:12,483] {logging_mixin.py:109} INFO - [2022-04-29 03:35:12,482] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:35:13,607] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:35:13,611] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:35:13,617] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:35:13,629] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:35:13,641] {logging_mixin.py:109} INFO - [2022-04-29 03:35:13,631] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:35:13,678] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:35:13,703] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.259 seconds
[2022-04-29 03:35:44,081] {processor.py:163} INFO - Started process (PID=4898) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:35:44,089] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:35:44,091] {logging_mixin.py:109} INFO - [2022-04-29 03:35:44,091] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:35:44,528] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:35:44,533] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:35:44,536] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:35:44,540] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:35:44,549] {logging_mixin.py:109} INFO - [2022-04-29 03:35:44,544] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:35:44,584] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:35:44,602] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.530 seconds
[2022-04-29 03:36:15,133] {processor.py:163} INFO - Started process (PID=4926) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:36:15,137] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:36:15,140] {logging_mixin.py:109} INFO - [2022-04-29 03:36:15,140] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:36:15,436] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:36:15,441] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:36:15,444] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:36:15,448] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:36:15,454] {logging_mixin.py:109} INFO - [2022-04-29 03:36:15,449] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:36:15,478] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:36:15,493] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.371 seconds
[2022-04-29 03:36:45,754] {processor.py:163} INFO - Started process (PID=4951) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:36:45,760] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:36:45,773] {logging_mixin.py:109} INFO - [2022-04-29 03:36:45,771] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:36:47,072] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:36:47,093] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:36:47,099] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:36:47,109] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:36:47,125] {logging_mixin.py:109} INFO - [2022-04-29 03:36:47,112] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:36:47,173] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:36:47,208] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.485 seconds
[2022-04-29 03:37:17,315] {processor.py:163} INFO - Started process (PID=4976) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:37:17,319] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:37:17,322] {logging_mixin.py:109} INFO - [2022-04-29 03:37:17,322] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:37:17,640] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:37:17,649] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:37:17,653] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:37:17,658] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:37:17,667] {logging_mixin.py:109} INFO - [2022-04-29 03:37:17,661] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:37:17,701] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:37:17,721] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.411 seconds
[2022-04-29 03:37:47,802] {processor.py:163} INFO - Started process (PID=5005) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:37:47,805] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:37:47,807] {logging_mixin.py:109} INFO - [2022-04-29 03:37:47,807] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:37:48,213] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:37:48,216] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:37:48,219] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:37:48,224] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:37:48,230] {logging_mixin.py:109} INFO - [2022-04-29 03:37:48,225] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:37:48,260] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:37:48,273] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.476 seconds
[2022-04-29 03:38:18,937] {processor.py:163} INFO - Started process (PID=5039) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:38:18,941] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:38:18,944] {logging_mixin.py:109} INFO - [2022-04-29 03:38:18,943] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:38:19,268] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:38:19,275] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:38:19,280] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:38:19,287] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:38:19,300] {logging_mixin.py:109} INFO - [2022-04-29 03:38:19,291] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:38:19,327] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:38:19,346] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.414 seconds
[2022-04-29 03:38:49,641] {processor.py:163} INFO - Started process (PID=5067) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:38:49,648] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:38:49,651] {logging_mixin.py:109} INFO - [2022-04-29 03:38:49,651] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:38:50,509] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:38:50,514] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:38:50,519] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:38:50,525] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:38:50,534] {logging_mixin.py:109} INFO - [2022-04-29 03:38:50,527] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:38:50,572] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:38:50,593] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.988 seconds
[2022-04-29 03:39:21,055] {processor.py:163} INFO - Started process (PID=5086) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:39:21,124] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:39:21,143] {logging_mixin.py:109} INFO - [2022-04-29 03:39:21,143] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:39:24,222] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:39:24,241] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:39:24,251] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:39:24,257] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:39:24,284] {logging_mixin.py:109} INFO - [2022-04-29 03:39:24,276] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:39:24,549] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:39:24,599] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.592 seconds
[2022-04-29 03:39:54,815] {processor.py:163} INFO - Started process (PID=5123) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:39:54,819] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:39:54,821] {logging_mixin.py:109} INFO - [2022-04-29 03:39:54,821] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:39:55,434] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:39:55,445] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:39:55,452] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:39:55,474] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:39:55,499] {logging_mixin.py:109} INFO - [2022-04-29 03:39:55,479] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:39:55,538] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:39:55,560] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.750 seconds
[2022-04-29 03:40:25,900] {processor.py:163} INFO - Started process (PID=5148) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:40:25,904] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:40:25,912] {logging_mixin.py:109} INFO - [2022-04-29 03:40:25,912] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:40:26,934] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:40:26,980] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:40:27,000] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:40:27,016] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:40:27,030] {logging_mixin.py:109} INFO - [2022-04-29 03:40:27,019] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:40:27,069] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:40:27,093] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.201 seconds
[2022-04-29 03:40:57,390] {processor.py:163} INFO - Started process (PID=5171) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:40:57,406] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:40:57,422] {logging_mixin.py:109} INFO - [2022-04-29 03:40:57,422] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:40:59,579] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:40:59,595] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:40:59,615] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:40:59,639] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:40:59,686] {logging_mixin.py:109} INFO - [2022-04-29 03:40:59,642] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:40:59,774] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:40:59,844] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.480 seconds
[2022-04-29 03:41:30,250] {processor.py:163} INFO - Started process (PID=5202) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:41:30,254] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:41:30,259] {logging_mixin.py:109} INFO - [2022-04-29 03:41:30,259] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:41:30,979] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:41:31,000] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:41:31,006] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:41:31,017] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:41:31,039] {logging_mixin.py:109} INFO - [2022-04-29 03:41:31,021] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:41:31,081] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:41:31,126] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.881 seconds
[2022-04-29 03:42:01,812] {processor.py:163} INFO - Started process (PID=5232) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:42:01,816] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:42:01,818] {logging_mixin.py:109} INFO - [2022-04-29 03:42:01,818] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:42:02,721] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:42:02,732] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:42:02,736] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:42:02,743] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:42:02,761] {logging_mixin.py:109} INFO - [2022-04-29 03:42:02,751] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:42:02,820] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:42:02,848] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.049 seconds
[2022-04-29 03:42:33,286] {processor.py:163} INFO - Started process (PID=5250) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:42:33,293] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:42:33,299] {logging_mixin.py:109} INFO - [2022-04-29 03:42:33,299] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:42:33,794] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:42:33,810] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:42:33,821] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:42:33,835] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:42:33,847] {logging_mixin.py:109} INFO - [2022-04-29 03:42:33,841] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:42:33,877] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:42:33,900] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.625 seconds
[2022-04-29 03:43:04,554] {processor.py:163} INFO - Started process (PID=5275) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:43:04,559] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:43:04,567] {logging_mixin.py:109} INFO - [2022-04-29 03:43:04,566] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:43:05,403] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:43:05,409] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:43:05,416] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:43:05,424] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:43:05,439] {logging_mixin.py:109} INFO - [2022-04-29 03:43:05,427] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:43:05,493] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:43:05,527] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.985 seconds
[2022-04-29 03:43:36,283] {processor.py:163} INFO - Started process (PID=5304) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:43:36,290] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:43:36,293] {logging_mixin.py:109} INFO - [2022-04-29 03:43:36,293] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:43:37,107] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:43:37,113] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:43:37,116] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:43:37,131] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:43:37,151] {logging_mixin.py:109} INFO - [2022-04-29 03:43:37,140] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:43:37,177] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:43:37,212] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.968 seconds
[2022-04-29 03:44:07,711] {processor.py:163} INFO - Started process (PID=5333) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:44:07,720] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:44:07,725] {logging_mixin.py:109} INFO - [2022-04-29 03:44:07,724] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:44:08,526] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:44:08,531] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:44:08,536] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:44:08,543] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:44:08,551] {logging_mixin.py:109} INFO - [2022-04-29 03:44:08,545] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:44:08,591] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:44:08,617] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.969 seconds
[2022-04-29 03:44:38,881] {processor.py:163} INFO - Started process (PID=5361) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:44:38,886] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:44:38,889] {logging_mixin.py:109} INFO - [2022-04-29 03:44:38,889] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:44:39,600] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:44:39,642] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:44:39,663] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:44:39,683] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:44:39,702] {logging_mixin.py:109} INFO - [2022-04-29 03:44:39,688] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:44:39,790] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:44:39,819] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.952 seconds
[2022-04-29 03:45:09,971] {processor.py:163} INFO - Started process (PID=5387) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:45:09,988] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:45:09,998] {logging_mixin.py:109} INFO - [2022-04-29 03:45:09,997] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:45:10,455] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:45:10,468] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:45:10,475] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:45:10,485] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:45:10,497] {logging_mixin.py:109} INFO - [2022-04-29 03:45:10,488] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:45:10,543] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:45:10,565] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.616 seconds
[2022-04-29 03:45:41,034] {processor.py:163} INFO - Started process (PID=5427) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:45:41,040] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:45:41,044] {logging_mixin.py:109} INFO - [2022-04-29 03:45:41,043] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:45:41,944] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:45:41,960] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:45:41,976] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:45:41,998] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:45:42,021] {logging_mixin.py:109} INFO - [2022-04-29 03:45:42,001] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:45:42,076] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:45:42,098] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.085 seconds
[2022-04-29 03:46:12,399] {processor.py:163} INFO - Started process (PID=5446) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:46:12,402] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:46:12,405] {logging_mixin.py:109} INFO - [2022-04-29 03:46:12,404] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:46:12,707] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:46:12,714] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:46:12,719] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:46:12,727] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:46:12,738] {logging_mixin.py:109} INFO - [2022-04-29 03:46:12,729] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:46:12,764] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:46:12,777] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.385 seconds
[2022-04-29 03:46:43,070] {processor.py:163} INFO - Started process (PID=5476) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:46:43,077] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:46:43,079] {logging_mixin.py:109} INFO - [2022-04-29 03:46:43,079] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:46:43,444] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:46:43,451] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:46:43,454] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:46:43,458] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:46:43,464] {logging_mixin.py:109} INFO - [2022-04-29 03:46:43,460] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:46:43,492] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:46:43,511] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.451 seconds
[2022-04-29 03:47:14,027] {processor.py:163} INFO - Started process (PID=5510) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:47:14,031] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:47:14,040] {logging_mixin.py:109} INFO - [2022-04-29 03:47:14,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:47:14,505] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:47:14,515] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:47:14,523] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:47:14,533] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:47:14,548] {logging_mixin.py:109} INFO - [2022-04-29 03:47:14,536] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:47:14,580] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:47:14,601] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.581 seconds
[2022-04-29 03:47:45,298] {processor.py:163} INFO - Started process (PID=5539) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:47:45,415] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:47:45,421] {logging_mixin.py:109} INFO - [2022-04-29 03:47:45,420] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:47:50,547] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:47:50,632] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:47:50,724] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:47:50,901] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:47:51,381] {logging_mixin.py:109} INFO - [2022-04-29 03:47:51,063] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:47:52,286] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:47:52,337] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 7.085 seconds
[2022-04-29 03:48:22,537] {processor.py:163} INFO - Started process (PID=5567) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:48:22,542] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:48:22,545] {logging_mixin.py:109} INFO - [2022-04-29 03:48:22,545] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:48:23,065] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:48:23,070] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:48:23,074] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:48:23,080] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:48:23,088] {logging_mixin.py:109} INFO - [2022-04-29 03:48:23,084] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:48:23,130] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:48:23,160] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.629 seconds
[2022-04-29 03:48:53,720] {processor.py:163} INFO - Started process (PID=5595) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:48:53,732] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:48:53,736] {logging_mixin.py:109} INFO - [2022-04-29 03:48:53,736] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:48:54,442] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:48:54,451] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:48:54,457] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:48:54,462] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:48:54,468] {logging_mixin.py:109} INFO - [2022-04-29 03:48:54,464] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:48:54,490] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:48:54,502] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.796 seconds
[2022-04-29 03:49:25,330] {processor.py:163} INFO - Started process (PID=5621) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:49:25,341] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:49:25,344] {logging_mixin.py:109} INFO - [2022-04-29 03:49:25,344] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:49:26,520] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:49:26,537] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:49:26,541] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:49:26,546] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:49:26,560] {logging_mixin.py:109} INFO - [2022-04-29 03:49:26,554] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:49:26,606] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:49:26,626] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.317 seconds
[2022-04-29 03:49:57,031] {processor.py:163} INFO - Started process (PID=5638) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:49:57,043] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:49:57,049] {logging_mixin.py:109} INFO - [2022-04-29 03:49:57,049] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:49:57,827] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:49:57,839] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:49:57,848] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:49:57,852] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:49:57,870] {logging_mixin.py:109} INFO - [2022-04-29 03:49:57,858] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:49:57,924] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:49:58,062] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.053 seconds
[2022-04-29 03:50:29,216] {processor.py:163} INFO - Started process (PID=5667) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:50:29,233] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:50:29,250] {logging_mixin.py:109} INFO - [2022-04-29 03:50:29,249] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:50:30,368] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:50:30,374] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:50:30,385] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:50:30,399] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:50:30,408] {logging_mixin.py:109} INFO - [2022-04-29 03:50:30,401] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:50:30,461] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:50:30,492] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.339 seconds
[2022-04-29 03:51:00,917] {processor.py:163} INFO - Started process (PID=5693) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:51:00,921] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:51:00,935] {logging_mixin.py:109} INFO - [2022-04-29 03:51:00,934] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:51:03,260] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:51:03,320] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:51:03,343] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:51:03,380] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:51:03,400] {logging_mixin.py:109} INFO - [2022-04-29 03:51:03,383] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:51:03,549] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:51:03,697] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.816 seconds
[2022-04-29 03:51:34,426] {processor.py:163} INFO - Started process (PID=5716) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:51:34,431] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:51:34,433] {logging_mixin.py:109} INFO - [2022-04-29 03:51:34,433] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:51:34,963] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:51:34,969] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:51:34,973] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:51:34,977] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:51:34,987] {logging_mixin.py:109} INFO - [2022-04-29 03:51:34,981] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:51:35,033] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:51:35,062] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.647 seconds
[2022-04-29 03:52:05,240] {processor.py:163} INFO - Started process (PID=5742) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:52:05,245] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:52:05,252] {logging_mixin.py:109} INFO - [2022-04-29 03:52:05,251] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:52:05,710] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:52:05,716] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:52:05,723] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:52:05,730] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:52:05,742] {logging_mixin.py:109} INFO - [2022-04-29 03:52:05,733] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:52:05,770] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:52:05,793] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.564 seconds
[2022-04-29 03:52:36,827] {processor.py:163} INFO - Started process (PID=5768) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:52:36,839] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:52:36,860] {logging_mixin.py:109} INFO - [2022-04-29 03:52:36,859] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:52:38,317] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:52:38,331] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:52:38,344] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:52:38,352] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:52:38,374] {logging_mixin.py:109} INFO - [2022-04-29 03:52:38,362] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:52:38,464] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:52:38,499] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.685 seconds
[2022-04-29 03:53:08,712] {processor.py:163} INFO - Started process (PID=5794) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:53:08,732] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:53:08,736] {logging_mixin.py:109} INFO - [2022-04-29 03:53:08,735] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:53:09,406] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:53:09,413] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:53:09,417] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:53:09,424] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:53:09,445] {logging_mixin.py:109} INFO - [2022-04-29 03:53:09,434] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:53:09,487] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:53:09,518] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.825 seconds
[2022-04-29 03:53:40,501] {processor.py:163} INFO - Started process (PID=5808) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:53:40,561] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:53:40,583] {logging_mixin.py:109} INFO - [2022-04-29 03:53:40,568] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:53:43,001] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:53:43,016] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:53:43,020] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:53:43,032] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:53:43,049] {logging_mixin.py:109} INFO - [2022-04-29 03:53:43,038] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:53:43,122] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:53:43,168] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.724 seconds
[2022-04-29 03:54:13,723] {processor.py:163} INFO - Started process (PID=5833) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:54:13,737] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:54:13,747] {logging_mixin.py:109} INFO - [2022-04-29 03:54:13,746] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:54:15,060] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:54:15,065] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:54:15,074] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:54:15,081] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:54:15,091] {logging_mixin.py:109} INFO - [2022-04-29 03:54:15,083] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:54:15,127] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:54:15,143] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.436 seconds
[2022-04-29 03:54:45,563] {processor.py:163} INFO - Started process (PID=5858) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:54:45,572] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:54:45,611] {logging_mixin.py:109} INFO - [2022-04-29 03:54:45,606] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:54:46,011] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:54:46,017] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:54:46,023] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:54:46,036] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:54:46,046] {logging_mixin.py:109} INFO - [2022-04-29 03:54:46,039] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:54:46,089] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:54:46,110] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.555 seconds
[2022-04-29 03:55:16,639] {processor.py:163} INFO - Started process (PID=5886) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:55:16,666] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:55:16,675] {logging_mixin.py:109} INFO - [2022-04-29 03:55:16,674] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:55:19,595] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:55:19,612] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:55:19,627] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:55:19,644] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:55:19,666] {logging_mixin.py:109} INFO - [2022-04-29 03:55:19,656] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:55:19,732] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:55:19,754] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.196 seconds
[2022-04-29 03:55:50,150] {processor.py:163} INFO - Started process (PID=5904) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:55:50,160] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:55:50,165] {logging_mixin.py:109} INFO - [2022-04-29 03:55:50,164] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:55:52,718] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:55:52,758] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:55:52,777] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:55:52,784] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:55:52,835] {logging_mixin.py:109} INFO - [2022-04-29 03:55:52,817] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:55:53,496] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:55:53,581] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.443 seconds
[2022-04-29 03:56:24,375] {processor.py:163} INFO - Started process (PID=5931) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:56:24,381] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:56:24,385] {logging_mixin.py:109} INFO - [2022-04-29 03:56:24,384] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:56:24,909] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:56:24,921] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:56:24,933] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:56:24,942] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:56:24,955] {logging_mixin.py:109} INFO - [2022-04-29 03:56:24,947] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:56:25,003] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:56:25,029] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.661 seconds
[2022-04-29 03:56:55,502] {processor.py:163} INFO - Started process (PID=5957) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:56:55,536] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:56:55,602] {logging_mixin.py:109} INFO - [2022-04-29 03:56:55,601] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:56:56,605] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:56:56,614] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:56:56,628] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:56:56,638] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:56:56,646] {logging_mixin.py:109} INFO - [2022-04-29 03:56:56,640] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:56:56,685] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:56:56,712] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.282 seconds
[2022-04-29 03:57:27,270] {processor.py:163} INFO - Started process (PID=5983) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:57:27,274] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:57:27,277] {logging_mixin.py:109} INFO - [2022-04-29 03:57:27,277] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:57:28,702] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:57:28,708] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:57:28,716] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:57:28,730] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:57:28,744] {logging_mixin.py:109} INFO - [2022-04-29 03:57:28,734] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:57:28,782] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:57:28,811] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.559 seconds
[2022-04-29 03:57:59,733] {processor.py:163} INFO - Started process (PID=6001) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:57:59,829] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:57:59,835] {logging_mixin.py:109} INFO - [2022-04-29 03:57:59,835] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:58:01,237] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:58:01,243] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:58:01,250] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:58:01,256] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:58:01,266] {logging_mixin.py:109} INFO - [2022-04-29 03:58:01,261] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:58:01,322] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:58:01,352] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.631 seconds
[2022-04-29 03:58:32,138] {processor.py:163} INFO - Started process (PID=6031) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:58:32,145] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:58:32,150] {logging_mixin.py:109} INFO - [2022-04-29 03:58:32,149] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:58:32,609] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:58:32,624] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:58:32,627] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:58:32,645] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:58:32,669] {logging_mixin.py:109} INFO - [2022-04-29 03:58:32,661] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:58:32,727] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:58:32,764] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.636 seconds
[2022-04-29 03:59:02,871] {processor.py:163} INFO - Started process (PID=6058) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:59:02,880] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:59:02,884] {logging_mixin.py:109} INFO - [2022-04-29 03:59:02,883] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:59:03,614] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:59:03,626] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:59:03,639] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:59:03,647] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:59:03,667] {logging_mixin.py:109} INFO - [2022-04-29 03:59:03,655] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:59:03,703] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:59:03,738] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.878 seconds
[2022-04-29 03:59:34,593] {processor.py:163} INFO - Started process (PID=6084) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:59:34,598] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 03:59:34,602] {logging_mixin.py:109} INFO - [2022-04-29 03:59:34,601] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:59:35,027] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 03:59:35,036] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 03:59:35,039] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 03:59:35,045] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 03:59:35,054] {logging_mixin.py:109} INFO - [2022-04-29 03:59:35,048] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 03:59:35,086] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 03:59:35,110] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.525 seconds
[2022-04-29 04:00:07,867] {processor.py:163} INFO - Started process (PID=6109) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:00:07,879] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:00:07,883] {logging_mixin.py:109} INFO - [2022-04-29 04:00:07,883] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:00:08,810] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:00:08,818] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:00:08,823] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:00:08,828] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:00:08,839] {logging_mixin.py:109} INFO - [2022-04-29 04:00:08,831] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:00:08,888] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:00:08,910] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.063 seconds
[2022-04-29 04:00:40,435] {processor.py:163} INFO - Started process (PID=6135) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:00:40,450] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:00:40,455] {logging_mixin.py:109} INFO - [2022-04-29 04:00:40,455] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:00:41,048] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:00:41,055] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:00:41,062] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:00:41,066] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:00:41,076] {logging_mixin.py:109} INFO - [2022-04-29 04:00:41,069] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:00:41,107] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:00:41,125] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.703 seconds
[2022-04-29 04:01:13,979] {processor.py:163} INFO - Started process (PID=6162) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:01:13,986] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:01:13,991] {logging_mixin.py:109} INFO - [2022-04-29 04:01:13,991] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:01:16,490] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:01:16,504] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:01:16,514] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:01:16,529] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:01:16,556] {logging_mixin.py:109} INFO - [2022-04-29 04:01:16,533] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:01:16,732] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:01:16,764] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.833 seconds
[2022-04-29 04:01:47,172] {processor.py:163} INFO - Started process (PID=6188) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:01:47,176] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:01:47,187] {logging_mixin.py:109} INFO - [2022-04-29 04:01:47,186] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:01:48,269] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:01:48,288] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:01:48,299] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:01:48,316] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:01:48,336] {logging_mixin.py:109} INFO - [2022-04-29 04:01:48,321] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:01:48,424] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:01:48,487] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.327 seconds
[2022-04-29 04:02:19,967] {processor.py:163} INFO - Started process (PID=6215) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:02:19,981] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:02:19,987] {logging_mixin.py:109} INFO - [2022-04-29 04:02:19,986] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:02:21,112] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:02:21,127] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:02:21,132] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:02:21,142] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:02:21,158] {logging_mixin.py:109} INFO - [2022-04-29 04:02:21,146] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:02:21,243] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:02:21,312] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.361 seconds
[2022-04-29 04:02:56,272] {processor.py:163} INFO - Started process (PID=6240) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:02:56,280] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:02:56,282] {logging_mixin.py:109} INFO - [2022-04-29 04:02:56,282] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:02:57,304] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:02:57,331] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:02:57,339] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:02:57,347] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:02:57,367] {logging_mixin.py:109} INFO - [2022-04-29 04:02:57,352] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:02:57,476] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:02:57,718] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.451 seconds
[2022-04-29 04:03:30,238] {processor.py:163} INFO - Started process (PID=6267) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:03:30,246] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:03:30,253] {logging_mixin.py:109} INFO - [2022-04-29 04:03:30,253] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:03:31,235] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:03:31,250] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:03:31,261] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:03:31,271] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:03:31,302] {logging_mixin.py:109} INFO - [2022-04-29 04:03:31,275] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:03:31,364] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:03:31,399] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.173 seconds
[2022-04-29 04:04:06,007] {processor.py:163} INFO - Started process (PID=6293) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:04:06,011] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:04:06,013] {logging_mixin.py:109} INFO - [2022-04-29 04:04:06,013] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:04:07,330] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:04:07,353] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:04:07,436] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:04:07,493] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:04:07,711] {logging_mixin.py:109} INFO - [2022-04-29 04:04:07,497] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:04:07,931] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:04:08,126] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.132 seconds
[2022-04-29 04:04:41,024] {processor.py:163} INFO - Started process (PID=6321) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:04:41,035] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:04:41,048] {logging_mixin.py:109} INFO - [2022-04-29 04:04:41,047] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:04:42,439] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:04:42,473] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:04:42,478] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:04:42,486] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:04:42,507] {logging_mixin.py:109} INFO - [2022-04-29 04:04:42,491] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:04:42,573] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:04:42,612] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.627 seconds
[2022-04-29 04:05:18,020] {processor.py:163} INFO - Started process (PID=6346) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:05:18,066] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:05:18,076] {logging_mixin.py:109} INFO - [2022-04-29 04:05:18,075] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:05:20,102] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:05:20,127] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:05:20,141] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:05:20,165] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:05:20,189] {logging_mixin.py:109} INFO - [2022-04-29 04:05:20,168] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:05:20,259] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:05:20,304] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.300 seconds
[2022-04-29 04:05:51,124] {processor.py:163} INFO - Started process (PID=6373) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:05:51,132] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:05:51,143] {logging_mixin.py:109} INFO - [2022-04-29 04:05:51,143] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:05:52,225] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:05:52,230] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:05:52,238] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:05:52,274] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:05:52,288] {logging_mixin.py:109} INFO - [2022-04-29 04:05:52,277] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:05:52,387] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:05:52,442] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.333 seconds
[2022-04-29 04:06:23,329] {processor.py:163} INFO - Started process (PID=6400) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:06:23,336] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:06:23,344] {logging_mixin.py:109} INFO - [2022-04-29 04:06:23,344] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:06:25,613] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:06:25,648] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:06:25,662] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:06:25,683] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:06:25,710] {logging_mixin.py:109} INFO - [2022-04-29 04:06:25,686] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:06:25,752] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:06:25,781] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.462 seconds
[2022-04-29 04:06:56,058] {processor.py:163} INFO - Started process (PID=6426) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:06:56,102] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:06:56,136] {logging_mixin.py:109} INFO - [2022-04-29 04:06:56,136] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:06:57,769] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:06:57,890] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:06:57,966] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:06:57,980] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:06:58,010] {logging_mixin.py:109} INFO - [2022-04-29 04:06:57,993] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:06:58,114] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:06:58,190] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.221 seconds
[2022-04-29 04:07:29,090] {processor.py:163} INFO - Started process (PID=6444) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:07:29,094] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:07:29,097] {logging_mixin.py:109} INFO - [2022-04-29 04:07:29,097] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:07:29,653] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:07:29,659] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:07:29,663] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:07:29,668] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:07:29,675] {logging_mixin.py:109} INFO - [2022-04-29 04:07:29,670] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:07:29,708] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:07:29,731] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.651 seconds
[2022-04-29 04:08:00,653] {processor.py:163} INFO - Started process (PID=6470) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:08:00,673] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:08:00,684] {logging_mixin.py:109} INFO - [2022-04-29 04:08:00,684] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:08:03,774] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:08:03,797] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:08:03,805] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:08:03,821] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:08:03,856] {logging_mixin.py:109} INFO - [2022-04-29 04:08:03,829] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:08:03,958] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:08:04,025] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.376 seconds
[2022-04-29 04:08:34,481] {processor.py:163} INFO - Started process (PID=6493) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:08:34,488] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:08:34,505] {logging_mixin.py:109} INFO - [2022-04-29 04:08:34,505] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:08:36,239] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:08:36,258] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:08:36,273] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:08:36,291] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:08:36,342] {logging_mixin.py:109} INFO - [2022-04-29 04:08:36,320] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:08:36,399] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:08:36,449] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.022 seconds
[2022-04-29 04:09:07,020] {processor.py:163} INFO - Started process (PID=6520) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:09:07,033] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:09:07,040] {logging_mixin.py:109} INFO - [2022-04-29 04:09:07,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:09:08,671] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:09:08,716] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:09:08,733] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:09:08,750] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:09:08,784] {logging_mixin.py:109} INFO - [2022-04-29 04:09:08,770] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:09:08,870] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:09:08,927] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.935 seconds
[2022-04-29 04:09:39,413] {processor.py:163} INFO - Started process (PID=6549) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:09:39,421] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:09:39,431] {logging_mixin.py:109} INFO - [2022-04-29 04:09:39,430] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:09:39,987] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:09:39,991] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:09:39,994] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:09:39,999] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:09:40,005] {logging_mixin.py:109} INFO - [2022-04-29 04:09:40,000] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:09:40,027] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:09:40,039] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.649 seconds
[2022-04-29 04:10:10,334] {processor.py:163} INFO - Started process (PID=6575) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:10:10,338] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:10:10,342] {logging_mixin.py:109} INFO - [2022-04-29 04:10:10,342] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:10:10,682] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:10:10,688] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:10:10,693] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:10:10,699] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:10:10,709] {logging_mixin.py:109} INFO - [2022-04-29 04:10:10,703] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:10:10,757] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:10:10,788] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.459 seconds
[2022-04-29 04:10:40,976] {processor.py:163} INFO - Started process (PID=6601) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:10:40,981] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:10:40,983] {logging_mixin.py:109} INFO - [2022-04-29 04:10:40,983] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:10:42,165] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:10:42,173] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:10:42,179] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:10:42,185] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:10:42,196] {logging_mixin.py:109} INFO - [2022-04-29 04:10:42,187] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:10:42,240] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:10:42,281] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.312 seconds
[2022-04-29 04:11:12,806] {processor.py:163} INFO - Started process (PID=6632) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:11:12,812] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:11:12,817] {logging_mixin.py:109} INFO - [2022-04-29 04:11:12,816] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:11:13,287] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:11:13,292] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:11:13,297] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:11:13,302] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:11:13,309] {logging_mixin.py:109} INFO - [2022-04-29 04:11:13,304] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:11:13,357] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:11:13,414] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.616 seconds
[2022-04-29 04:11:43,866] {processor.py:163} INFO - Started process (PID=6658) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:11:43,877] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:11:43,879] {logging_mixin.py:109} INFO - [2022-04-29 04:11:43,879] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:11:44,875] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:11:44,883] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:11:44,901] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:11:44,908] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:11:44,928] {logging_mixin.py:109} INFO - [2022-04-29 04:11:44,915] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:11:45,019] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:11:45,077] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.220 seconds
[2022-04-29 04:12:15,931] {processor.py:163} INFO - Started process (PID=6686) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:12:15,939] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:12:15,942] {logging_mixin.py:109} INFO - [2022-04-29 04:12:15,942] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:12:16,922] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:12:16,937] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:12:16,942] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:12:16,951] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:12:16,963] {logging_mixin.py:109} INFO - [2022-04-29 04:12:16,958] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:12:17,024] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:12:17,046] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.125 seconds
[2022-04-29 04:12:47,155] {processor.py:163} INFO - Started process (PID=6712) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:12:47,162] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:12:47,180] {logging_mixin.py:109} INFO - [2022-04-29 04:12:47,180] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:12:48,703] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:12:48,709] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:12:48,715] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:12:48,726] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:12:48,765] {logging_mixin.py:109} INFO - [2022-04-29 04:12:48,730] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:12:48,823] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:12:48,893] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.754 seconds
[2022-04-29 04:13:19,416] {processor.py:163} INFO - Started process (PID=6730) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:13:19,437] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:13:19,442] {logging_mixin.py:109} INFO - [2022-04-29 04:13:19,441] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:13:20,546] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:13:20,560] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:13:20,567] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:13:20,582] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:13:20,600] {logging_mixin.py:109} INFO - [2022-04-29 04:13:20,586] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:13:20,669] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:13:20,698] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.324 seconds
[2022-04-29 04:13:53,234] {processor.py:163} INFO - Started process (PID=6760) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:13:53,240] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:13:53,251] {logging_mixin.py:109} INFO - [2022-04-29 04:13:53,250] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:13:54,725] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:13:54,740] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:13:54,750] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:13:54,773] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:13:54,792] {logging_mixin.py:109} INFO - [2022-04-29 04:13:54,776] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:13:54,853] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:13:54,887] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.658 seconds
[2022-04-29 04:14:25,319] {processor.py:163} INFO - Started process (PID=6783) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:14:25,328] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:14:25,341] {logging_mixin.py:109} INFO - [2022-04-29 04:14:25,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:14:26,873] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:14:26,918] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:14:26,925] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:14:26,941] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:14:26,964] {logging_mixin.py:109} INFO - [2022-04-29 04:14:26,944] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:14:27,035] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:14:27,136] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.827 seconds
[2022-04-29 04:14:57,444] {processor.py:163} INFO - Started process (PID=6801) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:14:57,454] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:14:57,456] {logging_mixin.py:109} INFO - [2022-04-29 04:14:57,456] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:14:58,679] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:14:58,692] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:14:58,696] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:14:58,706] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:14:58,727] {logging_mixin.py:109} INFO - [2022-04-29 04:14:58,722] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:14:58,773] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:14:58,797] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.370 seconds
[2022-04-29 04:15:29,025] {processor.py:163} INFO - Started process (PID=6828) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:15:29,056] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:15:29,061] {logging_mixin.py:109} INFO - [2022-04-29 04:15:29,060] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:15:29,982] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:15:29,989] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:15:30,000] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:15:30,008] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:15:30,057] {logging_mixin.py:109} INFO - [2022-04-29 04:15:30,017] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:15:30,118] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:15:30,144] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.126 seconds
[2022-04-29 04:16:01,026] {processor.py:163} INFO - Started process (PID=6855) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:16:01,057] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:16:01,062] {logging_mixin.py:109} INFO - [2022-04-29 04:16:01,062] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:16:02,586] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:16:02,593] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:16:02,605] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:16:02,643] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:16:02,701] {logging_mixin.py:109} INFO - [2022-04-29 04:16:02,654] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:16:02,815] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:16:02,866] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.849 seconds
[2022-04-29 04:16:33,258] {processor.py:163} INFO - Started process (PID=6881) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:16:33,280] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:16:33,313] {logging_mixin.py:109} INFO - [2022-04-29 04:16:33,312] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:16:34,648] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:16:34,661] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:16:34,670] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:16:34,682] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:16:34,695] {logging_mixin.py:109} INFO - [2022-04-29 04:16:34,685] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:16:34,731] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:16:34,792] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.548 seconds
[2022-04-29 04:17:05,411] {processor.py:163} INFO - Started process (PID=6910) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:17:05,420] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:17:05,441] {logging_mixin.py:109} INFO - [2022-04-29 04:17:05,441] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:17:06,898] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:17:06,967] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:17:06,985] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:17:07,050] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:17:07,084] {logging_mixin.py:109} INFO - [2022-04-29 04:17:07,054] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:17:07,145] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:17:07,207] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.828 seconds
[2022-04-29 04:17:37,901] {processor.py:163} INFO - Started process (PID=6936) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:17:37,905] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:17:37,908] {logging_mixin.py:109} INFO - [2022-04-29 04:17:37,908] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:17:38,696] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:17:38,705] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:17:38,715] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:17:38,723] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:17:38,741] {logging_mixin.py:109} INFO - [2022-04-29 04:17:38,726] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:17:38,784] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:17:38,811] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.920 seconds
[2022-04-29 04:18:09,100] {processor.py:163} INFO - Started process (PID=6963) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:18:09,103] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:18:09,105] {logging_mixin.py:109} INFO - [2022-04-29 04:18:09,104] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:18:10,609] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:18:10,633] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:18:10,643] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:18:10,665] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:18:10,679] {logging_mixin.py:109} INFO - [2022-04-29 04:18:10,672] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:18:10,720] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:18:10,753] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.660 seconds
[2022-04-29 04:18:41,678] {processor.py:163} INFO - Started process (PID=6988) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:18:41,710] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:18:41,730] {logging_mixin.py:109} INFO - [2022-04-29 04:18:41,729] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:18:44,153] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:18:44,184] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:18:44,202] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:18:44,226] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:18:44,252] {logging_mixin.py:109} INFO - [2022-04-29 04:18:44,232] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:18:44,354] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:18:44,409] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.745 seconds
[2022-04-29 04:19:14,604] {processor.py:163} INFO - Started process (PID=7012) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:19:14,627] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:19:14,636] {logging_mixin.py:109} INFO - [2022-04-29 04:19:14,634] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:19:17,284] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:19:17,289] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:19:17,294] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:19:17,312] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:19:17,326] {logging_mixin.py:109} INFO - [2022-04-29 04:19:17,322] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:19:17,389] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:19:17,428] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.859 seconds
[2022-04-29 04:19:47,654] {processor.py:163} INFO - Started process (PID=7030) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:19:47,666] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:19:47,678] {logging_mixin.py:109} INFO - [2022-04-29 04:19:47,678] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:19:48,861] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:19:48,874] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:19:48,878] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:19:48,890] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:19:48,902] {logging_mixin.py:109} INFO - [2022-04-29 04:19:48,892] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:19:48,936] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:19:48,959] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.311 seconds
[2022-04-29 04:20:19,750] {processor.py:163} INFO - Started process (PID=7056) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:20:19,760] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:20:19,764] {logging_mixin.py:109} INFO - [2022-04-29 04:20:19,764] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:20:20,270] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:20:20,276] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:20:20,282] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:20:20,291] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:20:20,307] {logging_mixin.py:109} INFO - [2022-04-29 04:20:20,298] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:20:20,363] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:20:20,385] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.642 seconds
[2022-04-29 04:20:50,578] {processor.py:163} INFO - Started process (PID=7085) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:20:50,583] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:20:50,586] {logging_mixin.py:109} INFO - [2022-04-29 04:20:50,585] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:20:51,114] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:20:51,117] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:20:51,120] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:20:51,124] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:20:51,131] {logging_mixin.py:109} INFO - [2022-04-29 04:20:51,127] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:20:51,164] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:20:51,188] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.617 seconds
[2022-04-29 04:21:21,309] {processor.py:163} INFO - Started process (PID=7111) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:21:21,315] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:21:21,318] {logging_mixin.py:109} INFO - [2022-04-29 04:21:21,318] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:21:21,704] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:21:21,716] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:21:21,726] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:21:21,734] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:21:21,753] {logging_mixin.py:109} INFO - [2022-04-29 04:21:21,737] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:21:21,791] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:21:21,815] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.518 seconds
[2022-04-29 04:21:52,069] {processor.py:163} INFO - Started process (PID=7143) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:21:52,074] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:21:52,078] {logging_mixin.py:109} INFO - [2022-04-29 04:21:52,077] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:21:52,540] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:21:52,548] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:21:52,553] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:21:52,561] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:21:52,571] {logging_mixin.py:109} INFO - [2022-04-29 04:21:52,564] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:21:52,602] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:21:52,620] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.561 seconds
[2022-04-29 04:22:23,101] {processor.py:163} INFO - Started process (PID=7170) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:22:23,105] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:22:23,108] {logging_mixin.py:109} INFO - [2022-04-29 04:22:23,108] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:22:23,518] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:22:23,523] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:22:23,530] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:22:23,536] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:22:23,554] {logging_mixin.py:109} INFO - [2022-04-29 04:22:23,538] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:22:23,594] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:22:23,648] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.547 seconds
[2022-04-29 04:22:53,892] {processor.py:163} INFO - Started process (PID=7210) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:22:53,939] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:22:53,943] {logging_mixin.py:109} INFO - [2022-04-29 04:22:53,942] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:22:55,618] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:22:55,637] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:22:55,643] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:22:55,656] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:22:55,678] {logging_mixin.py:109} INFO - [2022-04-29 04:22:55,661] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:22:55,741] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:22:55,783] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.921 seconds
[2022-04-29 04:23:26,470] {processor.py:163} INFO - Started process (PID=7237) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:23:26,484] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:23:26,488] {logging_mixin.py:109} INFO - [2022-04-29 04:23:26,487] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:23:27,496] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:23:27,508] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:23:27,519] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:23:27,533] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:23:27,550] {logging_mixin.py:109} INFO - [2022-04-29 04:23:27,538] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:23:27,586] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:23:27,606] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.163 seconds
[2022-04-29 04:23:58,568] {processor.py:163} INFO - Started process (PID=7261) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:23:58,577] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:23:58,582] {logging_mixin.py:109} INFO - [2022-04-29 04:23:58,582] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:23:59,555] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:23:59,558] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:23:59,562] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:23:59,567] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:23:59,572] {logging_mixin.py:109} INFO - [2022-04-29 04:23:59,569] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:23:59,604] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:23:59,634] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.077 seconds
[2022-04-29 04:24:30,810] {processor.py:163} INFO - Started process (PID=7287) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:24:30,861] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:24:30,873] {logging_mixin.py:109} INFO - [2022-04-29 04:24:30,873] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:24:35,673] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:24:35,725] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:24:35,729] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:24:35,778] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:24:35,885] {logging_mixin.py:109} INFO - [2022-04-29 04:24:35,801] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:24:36,041] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:24:36,103] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 5.409 seconds
[2022-04-29 04:25:06,879] {processor.py:163} INFO - Started process (PID=7317) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:25:06,894] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:25:06,910] {logging_mixin.py:109} INFO - [2022-04-29 04:25:06,908] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:25:08,039] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:25:08,044] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:25:08,048] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:25:08,054] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:25:08,063] {logging_mixin.py:109} INFO - [2022-04-29 04:25:08,057] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:25:08,092] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:25:08,121] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.256 seconds
[2022-04-29 04:25:39,714] {processor.py:163} INFO - Started process (PID=7334) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:25:39,782] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:25:39,795] {logging_mixin.py:109} INFO - [2022-04-29 04:25:39,792] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:25:44,566] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:25:44,582] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:25:44,610] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:25:44,663] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:25:44,688] {logging_mixin.py:109} INFO - [2022-04-29 04:25:44,672] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:25:44,855] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:25:44,934] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 5.234 seconds
[2022-04-29 04:26:15,823] {processor.py:163} INFO - Started process (PID=7359) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:26:15,879] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:26:15,895] {logging_mixin.py:109} INFO - [2022-04-29 04:26:15,895] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:26:19,568] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:26:19,578] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:26:19,586] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:26:19,610] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:26:19,620] {logging_mixin.py:109} INFO - [2022-04-29 04:26:19,612] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:26:19,715] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:26:19,865] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.134 seconds
[2022-04-29 04:26:50,521] {processor.py:163} INFO - Started process (PID=7387) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:26:50,542] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:26:50,546] {logging_mixin.py:109} INFO - [2022-04-29 04:26:50,546] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:26:51,251] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:26:51,265] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:26:51,291] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:26:51,300] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:26:51,311] {logging_mixin.py:109} INFO - [2022-04-29 04:26:51,304] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:26:51,359] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:26:51,381] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.873 seconds
[2022-04-29 04:27:21,967] {processor.py:163} INFO - Started process (PID=7415) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:27:22,007] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:27:22,015] {logging_mixin.py:109} INFO - [2022-04-29 04:27:22,013] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:27:23,114] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:27:23,120] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:27:23,124] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:27:23,129] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:27:23,138] {logging_mixin.py:109} INFO - [2022-04-29 04:27:23,133] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:27:23,166] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:27:23,181] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.231 seconds
[2022-04-29 04:27:53,685] {processor.py:163} INFO - Started process (PID=7443) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:27:53,690] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:27:53,704] {logging_mixin.py:109} INFO - [2022-04-29 04:27:53,704] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:27:54,435] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:27:54,447] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:27:54,452] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:27:54,466] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:27:54,482] {logging_mixin.py:109} INFO - [2022-04-29 04:27:54,473] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:27:54,545] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:27:54,610] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.931 seconds
[2022-04-29 04:28:24,806] {processor.py:163} INFO - Started process (PID=7469) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:28:24,811] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:28:24,814] {logging_mixin.py:109} INFO - [2022-04-29 04:28:24,814] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:28:25,479] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:28:25,484] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:28:25,489] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:28:25,494] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:28:25,504] {logging_mixin.py:109} INFO - [2022-04-29 04:28:25,498] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:28:25,543] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:28:25,571] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.773 seconds
[2022-04-29 04:28:56,213] {processor.py:163} INFO - Started process (PID=7494) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:28:56,216] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:28:56,228] {logging_mixin.py:109} INFO - [2022-04-29 04:28:56,227] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:28:56,759] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:28:56,765] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:28:56,768] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:28:56,773] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:28:56,780] {logging_mixin.py:109} INFO - [2022-04-29 04:28:56,776] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:28:56,830] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:28:56,860] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.654 seconds
[2022-04-29 04:29:28,250] {processor.py:163} INFO - Started process (PID=7522) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:29:28,255] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:29:28,262] {logging_mixin.py:109} INFO - [2022-04-29 04:29:28,261] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:29:31,390] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:29:31,412] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:29:31,422] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:29:31,442] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:29:31,469] {logging_mixin.py:109} INFO - [2022-04-29 04:29:31,452] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:29:31,592] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:29:31,678] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.451 seconds
[2022-04-29 04:30:02,086] {processor.py:163} INFO - Started process (PID=7544) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:30:02,102] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:30:02,121] {logging_mixin.py:109} INFO - [2022-04-29 04:30:02,121] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:30:03,997] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:30:04,018] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:30:04,081] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:30:04,141] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:30:04,235] {logging_mixin.py:109} INFO - [2022-04-29 04:30:04,152] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:30:04,316] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:30:04,373] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.294 seconds
[2022-04-29 04:30:35,129] {processor.py:163} INFO - Started process (PID=7570) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:30:35,132] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:30:35,144] {logging_mixin.py:109} INFO - [2022-04-29 04:30:35,143] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:30:37,986] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:30:37,995] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:30:38,001] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:30:38,007] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:30:38,021] {logging_mixin.py:109} INFO - [2022-04-29 04:30:38,013] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:30:38,076] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:30:38,097] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 3.018 seconds
[2022-04-29 04:31:08,551] {processor.py:163} INFO - Started process (PID=7603) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:31:08,564] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:31:08,570] {logging_mixin.py:109} INFO - [2022-04-29 04:31:08,569] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:31:09,403] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:31:09,422] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:31:09,437] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:31:09,463] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:31:09,494] {logging_mixin.py:109} INFO - [2022-04-29 04:31:09,476] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:31:09,558] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:31:09,664] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.168 seconds
[2022-04-29 04:31:39,904] {processor.py:163} INFO - Started process (PID=7630) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:31:39,912] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:31:39,915] {logging_mixin.py:109} INFO - [2022-04-29 04:31:39,914] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:31:41,418] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:31:41,428] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:31:41,435] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:31:41,441] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:31:41,594] {logging_mixin.py:109} INFO - [2022-04-29 04:31:41,458] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:31:41,698] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:31:41,740] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.849 seconds
[2022-04-29 04:32:12,039] {processor.py:163} INFO - Started process (PID=7661) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:32:12,050] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:32:12,053] {logging_mixin.py:109} INFO - [2022-04-29 04:32:12,052] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:32:13,346] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:32:13,352] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:32:13,355] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:32:13,360] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:32:13,366] {logging_mixin.py:109} INFO - [2022-04-29 04:32:13,361] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:32:13,398] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:32:13,418] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.393 seconds
[2022-04-29 04:32:43,887] {processor.py:163} INFO - Started process (PID=7691) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:32:43,896] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:32:43,906] {logging_mixin.py:109} INFO - [2022-04-29 04:32:43,906] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:32:45,404] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:32:45,418] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:32:45,430] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:32:45,434] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:32:45,449] {logging_mixin.py:109} INFO - [2022-04-29 04:32:45,442] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:32:45,481] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:32:45,505] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.640 seconds
[2022-04-29 04:33:15,735] {processor.py:163} INFO - Started process (PID=7716) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:33:15,745] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:33:15,747] {logging_mixin.py:109} INFO - [2022-04-29 04:33:15,747] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:33:17,956] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:33:17,964] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:33:17,973] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:33:17,984] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:33:18,013] {logging_mixin.py:109} INFO - [2022-04-29 04:33:18,001] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:33:18,067] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:33:18,103] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 2.374 seconds
[2022-04-29 04:33:48,460] {processor.py:163} INFO - Started process (PID=7735) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:33:48,474] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:33:48,477] {logging_mixin.py:109} INFO - [2022-04-29 04:33:48,477] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:33:49,195] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:33:49,210] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:33:49,232] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:33:49,248] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:33:49,270] {logging_mixin.py:109} INFO - [2022-04-29 04:33:49,253] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:33:49,342] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:33:49,368] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.921 seconds
[2022-04-29 04:34:19,966] {processor.py:163} INFO - Started process (PID=7761) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:34:19,974] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:34:19,978] {logging_mixin.py:109} INFO - [2022-04-29 04:34:19,978] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:34:20,474] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:34:20,483] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:34:20,490] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:34:20,498] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:34:20,509] {logging_mixin.py:109} INFO - [2022-04-29 04:34:20,502] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:34:20,593] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:34:20,691] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.737 seconds
[2022-04-29 04:34:50,993] {processor.py:163} INFO - Started process (PID=7786) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:34:51,004] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:34:51,008] {logging_mixin.py:109} INFO - [2022-04-29 04:34:51,007] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:34:52,031] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:34:52,054] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:34:52,059] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:34:52,076] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:34:52,108] {logging_mixin.py:109} INFO - [2022-04-29 04:34:52,087] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:34:52,263] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:34:52,340] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.362 seconds
[2022-04-29 04:35:22,458] {processor.py:163} INFO - Started process (PID=7813) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:35:22,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:35:22,468] {logging_mixin.py:109} INFO - [2022-04-29 04:35:22,467] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:35:23,808] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:35:23,816] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:35:23,828] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:35:23,848] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:35:23,872] {logging_mixin.py:109} INFO - [2022-04-29 04:35:23,858] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:35:23,916] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:35:23,947] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.500 seconds
[2022-04-29 04:35:54,466] {processor.py:163} INFO - Started process (PID=7839) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:35:54,471] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:35:54,475] {logging_mixin.py:109} INFO - [2022-04-29 04:35:54,475] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:35:55,322] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:35:55,331] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:35:55,346] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:35:55,365] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:35:55,387] {logging_mixin.py:109} INFO - [2022-04-29 04:35:55,371] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:35:55,428] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:35:55,456] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.005 seconds
[2022-04-29 04:36:26,155] {processor.py:163} INFO - Started process (PID=7867) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:36:26,166] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:36:26,174] {logging_mixin.py:109} INFO - [2022-04-29 04:36:26,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:36:26,958] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:36:26,970] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:36:26,975] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:36:26,987] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:36:27,007] {logging_mixin.py:109} INFO - [2022-04-29 04:36:26,990] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:36:27,061] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:36:27,128] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.984 seconds
[2022-04-29 04:36:57,478] {processor.py:163} INFO - Started process (PID=7893) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:36:57,495] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:36:57,498] {logging_mixin.py:109} INFO - [2022-04-29 04:36:57,498] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:36:58,332] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:36:58,338] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:36:58,351] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:36:58,361] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:36:58,369] {logging_mixin.py:109} INFO - [2022-04-29 04:36:58,364] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:36:58,502] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:36:58,606] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.153 seconds
[2022-04-29 04:37:29,430] {processor.py:163} INFO - Started process (PID=7918) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:37:29,454] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:37:29,461] {logging_mixin.py:109} INFO - [2022-04-29 04:37:29,460] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:37:29,987] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:37:30,007] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:37:30,024] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:37:30,034] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:37:30,057] {logging_mixin.py:109} INFO - [2022-04-29 04:37:30,046] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:37:30,120] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:37:30,143] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.742 seconds
[2022-04-29 04:38:00,308] {processor.py:163} INFO - Started process (PID=7945) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:38:00,315] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:38:00,319] {logging_mixin.py:109} INFO - [2022-04-29 04:38:00,319] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:38:01,206] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:38:01,220] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:38:01,227] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:38:01,236] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:38:01,279] {logging_mixin.py:109} INFO - [2022-04-29 04:38:01,271] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:38:01,379] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:38:01,426] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.134 seconds
[2022-04-29 04:38:32,166] {processor.py:163} INFO - Started process (PID=7962) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:38:32,185] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:38:32,200] {logging_mixin.py:109} INFO - [2022-04-29 04:38:32,200] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:38:36,199] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:38:36,217] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:38:36,235] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:38:36,279] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:38:36,419] {logging_mixin.py:109} INFO - [2022-04-29 04:38:36,367] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:38:36,466] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:38:36,492] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 4.394 seconds
[2022-04-29 04:39:06,731] {processor.py:163} INFO - Started process (PID=7985) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:39:06,736] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:39:06,739] {logging_mixin.py:109} INFO - [2022-04-29 04:39:06,739] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:39:07,127] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:39:07,131] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:39:07,136] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:39:07,142] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:39:07,150] {logging_mixin.py:109} INFO - [2022-04-29 04:39:07,144] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:39:07,178] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:39:07,193] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.468 seconds
[2022-04-29 04:39:37,414] {processor.py:163} INFO - Started process (PID=8011) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:39:37,419] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:39:37,429] {logging_mixin.py:109} INFO - [2022-04-29 04:39:37,428] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:39:38,365] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:39:38,377] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:39:38,384] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:39:38,394] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:39:38,407] {logging_mixin.py:109} INFO - [2022-04-29 04:39:38,397] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:39:38,453] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:39:38,496] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 1.105 seconds
[2022-04-29 04:40:08,776] {processor.py:163} INFO - Started process (PID=8037) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:40:08,808] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:40:08,814] {logging_mixin.py:109} INFO - [2022-04-29 04:40:08,814] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:40:09,284] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:40:09,289] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:40:09,292] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:40:09,297] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:40:09,314] {logging_mixin.py:109} INFO - [2022-04-29 04:40:09,299] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:40:09,345] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:40:09,369] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.598 seconds
[2022-04-29 04:40:39,572] {processor.py:163} INFO - Started process (PID=8068) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:40:39,575] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:40:39,578] {logging_mixin.py:109} INFO - [2022-04-29 04:40:39,578] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:40:39,900] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:40:39,904] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:40:39,907] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:40:39,911] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:40:39,916] {logging_mixin.py:109} INFO - [2022-04-29 04:40:39,912] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:40:39,938] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:40:39,951] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.385 seconds
[2022-04-29 04:41:10,068] {processor.py:163} INFO - Started process (PID=8095) to work on /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:41:10,074] {processor.py:642} INFO - Processing file /opt/airflow/dags/dataproc_spark_dag.py for tasks to queue
[2022-04-29 04:41:10,080] {logging_mixin.py:109} INFO - [2022-04-29 04:41:10,079] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:41:10,543] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2022-04-29 04:41:10,547] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py:57 DeprecationWarning: Default region value `global` will be deprecated. Please, provide region value.
[2022-04-29 04:41:10,551] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: Passing cluster parameters by keywords to `DataprocClusterCreateOperator` will be deprecated. Please provide cluster_config object using `cluster_config` parameter. You can use `airflow.dataproc.ClusterGenerator.generate_cluster` method to obtain cluster object.
[2022-04-29 04:41:10,556] {logging_mixin.py:109} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py:188 DeprecationWarning: The `PatchedDataProcSparkOperator` operator is deprecated, please use `DataprocSubmitJobOperator` instead. You can use `generate_job` method of `PatchedDataProcSparkOperator` to generate dictionary representing your job and use it with the new operator.
[2022-04-29 04:41:10,564] {logging_mixin.py:109} INFO - [2022-04-29 04:41:10,558] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/dataproc_spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 111, in <module>
    dataproc_spark_jars=['gs://spark-lib/bigquery/spark-bigquery-latest.jar']
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/opt/airflow/dags/dataproc_spark_dag.py", line 85, in __init__
    super(PatchedDataProcSparkOperator, self).__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/contrib/operators/dataproc_operator.py", line 189, in __init__
    super().__init__(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1398, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1013, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 537, in __init__
    "arguments were:\n**kwargs: {k}".format(c=self.__class__.__name__, k=kwargs, t=task_id),
airflow.exceptions.AirflowException: Invalid arguments were passed to PatchedDataProcSparkOperator (task_id: run_job). Invalid arguments were:
**kwargs: {'dataproc_spark_jars': ['gs://spark-lib/bigquery/spark-bigquery-latest.jar']}
[2022-04-29 04:41:10,606] {processor.py:656} WARNING - No viable dags retrieved from /opt/airflow/dags/dataproc_spark_dag.py
[2022-04-29 04:41:10,623] {processor.py:171} INFO - Processing /opt/airflow/dags/dataproc_spark_dag.py took 0.568 seconds
